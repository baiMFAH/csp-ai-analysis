{"appName":"journalclub.io","session":{"userId":false,"userRole":false,"userPermissions":false,"membershipStatus":false,"loggedIn":false,"userEmail":false,"loginType":false},"pricing":{"individual":{"monthly":14.99,"yearly":89.94},"team":{"monthly":49,"yearly":499,"bundle":799}},"episodes":[{"title":"Robotic Paper Wrapping by Learning Force Control","description":"Now imagine trying to teach a robot to do the same thing. Every step, every move, every subtle nuance of the procedure. Suddenly, what seemed simple becomes a nightmare of edge cases. Apply too much force and the paper tears. Too little, and you get wrinkles. Move too fast and the paper shifts out of position. The robot will need to seamlessly transition between different types of control, sometimes prioritizing precise positioning, other times focusing on force application,  all while adapting to different materials and box sizes.","sample":true,"doi":"10.1109/ACCESS.2025.3606495","short":"robotic-paper-wrapping","released":"October 23rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Robotic Paper Wrapping","carousels":["Robotics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"robotic-paper-wrapping-by-learning-force-control"},{"title":"Well-Being of the Baltic Herring and Bycatch Fish Species from FAO Major Fishing Areas 27 According to Microplastic Pollution","description":"They needed to dissolve the fish’s biological tissues while preserving the plastic particles. They used a potassium hydroxide solution for that, a strong base that breaks down proteins and other organic compounds but leaves synthetic polymers intact. Once that was over, they sent the samples through an extremely fine mesh filter, then dug into the process of identifying the plastic bits. This is, oddly enough, largely a manual process, tiny piece by tiny piece.","sample":true,"doi":"10.3390/ani15162381","short":"baltic-herring-microplastics","released":"October 22nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Microplastics and Fish","carousels":["Ecology","Oceanography","Sustainability","Agriculture","Animals"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"well-being-of-the-baltic-herring-and-bycatch-fish-species-from-fao-major-fishing-areas-27-according-to-microplastic-pollution"},{"title":"Secure and efficient ownership verification for deduplicated cloud computing systems","description":"When a new file is ingested, the server recognizes its digital fingerprint and says \"I already have that one\", no need to store another. Your storage quota still gets used, of course, and you still pay for the storage. But behind the scenes, there's only one actual copy of the file, with multiple pointers to it. You can see why this is great for cloud providers. Storage costs stay as low as possible, and bandwidth is lower than it would otherwise be, backup times shrink, and best of all: they get to charge multiple users for something they only actually did for one of them. And in theory, it’s fine for everyone.","sample":true,"doi":"10.1186/s13677-025-00743-y","short":"ownership-verification","released":"October 21st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Secure Ownership Verification","carousels":["Cloud Computing","Security","Distributed Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"secure-and-efficient-ownership-verification-for-deduplicated-cloud-computing-systems"},{"title":"The Mediating Effect of Social Connectedness in the Relationship Between K-Pop Fandom Identity and Mental Health","description":"Does identifying as part of a K-Pop fandom make people feel happier and more satisfied with their lives? Does it help shield them from depression? And if those effects exist, are they explained by the social connections fans form with one another, or is some other psychological mechanism at work?","sample":true,"doi":"10.1177/21582440251369989","short":"k-pop-mental-health","released":"October 20th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"K-Pop Fandom Mental Health","carousels":["Social Science","Congnitive Science","Psychology","Sociology","Media Studies"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-mediating-effect-of-social-connectedness-in-the-relationship-between-k-pop-fandom-identity-and-mental-health"},{"title":"Improving test suite generation quality through machine learning-driven boundary value analysis","description":"Let’s say you’re building a simple web app. A user can sign up or log in, do some stuff, and log off. Nothing fancy. Right now you’re working on the signup form. When a user chooses their password, you need to validate it (on the backend) against your company’s requirements. It must be at least a certain minimum length, not exceed a maximum length, contain certain types of characters, avoid other disallowed character types, avoid repeating or sequential characters, etc.","sample":true,"doi":"10.1016/j.array.2025.100496","short":"improving-test-suite-generation","released":"October 19th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Test Suite Generation","carousels":["Testing","Continuous Integration","CI"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"improving-test-suite-generation-quality-through-machine-learning-driven-boundary-value-analysis"},{"title":"Ultrasound system for precise neuromodulation of human deep brain circuits","description":"Imagine that you're a neurosurgeon, and you’re trying to treat a patient with severe depression. Your target is a tiny brain structure buried deep in the skull, smaller than a grape. Your only options are to either drill through the skull and insert electrodes, or give up on precision entirely and just use drugs instead. The issue is that the drugs will affect the whole brain. Neither option is ideal. But what if there was a third way? What if you could reach that deep brain structure without breaking the skin, and target it with precision?","sample":true,"doi":"10.1038/s41467-025-63020-1","short":"ultrasound-neuromodulation","released":"October 18th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Ultrasound Neuromodulation","carousels":["Medicine","Cognitive Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"ultrasound-system-for-precise-neuromodulation-of-human-deep-brain-circuits"},{"title":"Fast and fair randomized wait-free locks","description":"Imagine a group of philosophers seated around a table. There is one chopstick placed between each pair of people. Not a pair of chopsticks, just one stick. So it goes person > stick > person > stick, etc.  Each person alternates between thinking and eating. They eat a little bit, they think a little bit, they eat a little bit, they think a little bit. But in order to eat, they need two chopsticks: the one to their left and the one to their right.","sample":true,"doi":"10.1007/s00446-024-00474-4","short":"wait-free-locks","released":"October 17th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Wait-Free Locks","carousels":["Distributed Systems","Parallel Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fast-and-fair-randomized-wait-free-locks"},{"title":"Interoception and dissociation in migraine: a case-control study of chronic and episodic subtypes","description":"The ‘prediction error’ concept is crucial to understanding today's research, so let's unpack it. Your brain is a prediction machine, it’s constantly generating expectations about incoming sensory information based on past experience. When you walk up stairs, your brain predicts that your heart rate will increase and you'll feel slightly out of breath. When these predictions match the actual signals from your body, everything feels normal. But when there's a mismatch between prediction and reality, you get a prediction error signal that helps your brain update its models. There are two types of interoceptive prediction errors that we can measure.","sample":true,"doi":"10.3389/fneur.2025.1643260","short":"migraines-interoception-dissociation","released":"October 16th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Chronic vs Episodic Migraines","carousels":["Medicine","Cognitive Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"interoception-and-dissociation-in-migraine-a-case-control-study-of-chronic-and-episodic-subtypes"},{"title":"Fault Injection Evaluation with Statistical Analysis","description":"Imagine that you're working on a new chip. It’s not a general-purpose processor, it’s built for a specific purpose and use case: cryptography. It accelerates encryption, decryption, and key generation directly in hardware, instead of relying on software routines (which are slower). If you can get this right, the use cases abound: everything from securing mobile payments, to protecting cloud servers, to safeguarding embedded devices and medical equipment, to securing the Internet of Things.","sample":true,"doi":"10.46586/tches.v2025.i4.215-253","short":"fault-injection-evaluation","released":"October 15th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fault Injection Evaluation","carousels":["Security","Hardware"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fault-injection-evaluation-with-statistical-analysis"},{"title":"Association between shift work and brain age gap: a neuroimaging study using MRI-based brain age prediction algorithms","description":"First, let's talk about what these researchers were actually measuring. The brain age “gap” is the difference between your chronological age and your \"predicted brain age\" based on MRI scans. Researchers train machine learning models on brain scans from thousands of healthy people. These models learn to predict someone's age just by looking at their brain structure. When you feed a new brain scan into these models, they spit out a predicted age. So, if the model says your brain looks 45 but you're only 40, you have a brain age gap of five years.","sample":true,"doi":"10.3389/fnagi.2025.1650497","short":"shift-work-brain-age","released":"October 14th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Shift-Work and Your Brain","carousels":["Medicine","Health","Sleep Science","Sociology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"association-between-shift-work-and-brain-age-gap-a-neuroimaging-study-using-mri-based-brain-age-prediction-algorithms"},{"title":"LightEdit: Textual Image Editing with Lightweight Stable Diffusion","description":"Image editing used to be the exclusive domain of professionals. If you wanted to modify, airbrush, or enhance an image, you didn’t just need a program, you needed skills. Swapping objects, changing backgrounds, these things were difficult to do. Now? Not so much. With the emergence of text-to-image diffusion models, particularly Stable Diffusion, that's all changed. Now anyone can type \"make this dog wear a hat\" and get surprisingly good results. But there's a catch. These models are massive. Stable Diffusion packs over 800 million parameters, and the iterative nature of diffusion models means you need multiple forward passes to generate a single image. That translates to serious computational requirements, long inference times, and hardware that most people don't have sitting on their desk.","sample":true,"doi":"10.1109/ACCESS.2025.3606427","short":"textual-image-editing","released":"October 13th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Lightweight Diffusion Model","carousels":["Diffusion Models","Generative AI"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"lightedit-textual-image-editing-with-lightweight-stable-diffusion"},{"title":"Driving Toward Carbon Neutrality in the United States: Do Artificial Intelligence Shocks, Energy Policy Uncertainty, Green Growth, and Regulatory Quality Matter?","description":"Most environmental studies assume that technology has a simple, one-directional relationship with emissions. Either a technology is good for the environment or it's bad, and the effect stays consistent. But in this study, the authors suspected (correctly) that AI is different. That it can simultaneously help and hurt the environment in ways that a traditional analysis can miss. To capture this complexity, they used a statistical approach that treats AI's environmental impact like a two-sided coin. Instead of looking for a single average effect, their method separately tracks instances where AI development reduces emissions and instances where it increases emissions. This approach reveals patterns that simple correlation analysis would completely overlook. Think of it like trying to measure the net effect of a new highway. Sometimes highways reduce emissions by improving traffic flow and reducing congestion. But sometimes they increase emissions by encouraging more people to drive longer distances. Traditional analysis would just look at the average effect across all highways. But this decomposition approach treats congestion reduction and induced demand as separate phenomena that need to be measured independently.","sample":true,"doi":"10.1177/21582440251359735","short":"carbon-neutrality-ai","released":"October 12th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"AI vs Carbon Neutrality","carousels":["Sustainability","Climate Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"driving-toward-carbon-neutrality-in-the-united-states-do-artificial-intelligence-shocks-energy-policy-uncertainty-green-growth-and-regulatory-quality-matter"},{"title":"Token Probabilities to Mitigate Large Language Models Overconfidence in Answering Medical Questions: Quantitative Study","description":"When an LLM generates a response, they're not just spitting out words. Under the hood, they're running a process that assigns probabilities to every possible word or symbol that they might produce next. So when you give it a multiple-choice question, the model has to choose between specific answer tokens. The internal probability it assigns to its chosen answer is a window into how certain the model actually is, based on its training and the patterns it learned. But here's the issue: this internal mathematical certainty is actually completely separate from what the model says about its own confidence when asked. In this study they’re comparing and contrasting two things: how confident the model truly is vs how confident it says that it is. That was why they needed to stick with models that provided access to their internal probability calculations. Without that, they wouldn’t be able to make those comparisons.","sample":true,"doi":"10.2196/64348","short":"llm-overconfidence","released":"October 11th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"LLM Overconfidence","carousels":["Large Language Models","Model Training"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"token-probabilities-to-mitigate-large-language-models-overconfidence-in-answering-medical-questions-quantitative-study"},{"title":"Single-Night Sleep Extension Enhances Morning Physical and Cognitive Performance Across Time of Day in Physically Active University Students: A Randomized Crossover Study","description":"To take measurements, the authors used wrist actigraphy devices. These work like activity trackers. They continuously monitor movement patterns to determine when someone is asleep versus awake. It uses accelerometers to detect the movements that occur during different sleep stages, then applies algorithms to translate movement data into sleep metrics. These measurements are designed (in theory) to eliminate the reliability issues that come with self-reported sleep data. Though it's worth noting that actigraphy can sometimes misclassify quiet wakefulness as sleep. That is: the device might not know the difference between zoning-out watching TV or actually taking a nap.","sample":true,"doi":"10.3390/life15081178","short":"single-night-sleep","released":"October 10th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"An Extra Hour of Sleep","carousels":["Medicine","Sleep","Athletics","Cognitive Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"single-night-sleep-extension-enhances-morning-physical-and-cognitive-performance-across-time-of-day-in-physically-active-university-students-a-randomized-crossover-study"},{"title":"Self-Supervised Masked Deep Embeddings for Dental Caries Detection","description":"In medical imaging, labeled datasets are often limited. You can't just scrape millions of dental X-rays from the internet like you could with cat photos. And once you have the images, they need to be annotated by a qualified professional. This is time-consuming and costly, and creates a problem for traditional deep learning approaches (that require vast amounts of labeled data to perform well). The solution lies in self-supervised learning, specifically a technique called masked image modeling. Picture it like this:  you're teaching a model to recognize dental features by showing them X-ray images with certain patches covered up, then asking them to predict what should be in those hidden areas. By learning to fill in the blanks, the model develops a deep understanding of dental anatomy and pathology without needing explicit labels for every single feature.","sample":true,"doi":"10.1109/ACCESS.2025.3606811","short":"dental-caries-detection","released":"October 9th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Dental Cavity Detection","carousels":["Medicine","Dentistry","Imaging","Medical Imaging","Computer Vision","Machine Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"self-supervised-masked-deep-embeddings-for-dental-caries-detection"},{"title":"Emotional dynamics and engagement cycles in swiping dating apps: An agent-based modeling approach","description":"The core idea here is that ‘swiping apps’ expose users to high volumes of what the authors call “subtle/implicit rejection\". Unlike face-to-face dating scenarios where rejection might be rarer and more explicit, swiping apps deliver rejection constantly but ambiguously. Previous research has shown that rejection is psychologically distressing (as you’d expect). But swiping apps turn up the velocity. You get rejected, then immediately have to evaluate someone else, then potentially face more rejection, all within a few seconds.","sample":true,"doi":"10.1016/j.chbr.2025.100775","short":"emotional-dynamics-dating-apps","released":"October 8th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Dating App Engagement Cycles","carousels":["Romance","Social Sciences","Psychology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"emotional-dynamics-and-engagement-cycles-in-swiping-dating-apps-an-agent-based-modeling-approach"},{"title":"Massively parallel computation in a heterogeneous regime","description":"Let’s say the problem is some kind of travelling-salesman. Your system is going to approximate a solution with something like an MST heuristic (a minimum spanning tree). You spin up the machines and run the algorithm across your cluster. And now you’re sitting and waiting through round after round of communication because no single VM can hold enough data to make real progress. Every partial result has to be passed around, merged, and checked for consistency before the next step can begin. That constant back-and-forth introduces latency, and the synchronization barriers mean the slowest node drags down the whole process. In other words, you’re paying a huge time penalty not for the math itself, but for the cost of stitching all the pieces back together across the network.","sample":true,"doi":"10.1007/s00446-025-00479-7","short":"massively-parallel-computation","released":"October 7th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Massively Parallel Computation","carousels":["Distributed Computering","Parallel Programming","High Performance Computing","HPC","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"massively-parallel-computation-in-a-heterogeneous-regime"},{"title":"Non-invasive vagus nerve stimulation is associated with the reduction in persistent post-concussion symptoms: an observational study","description":"The vagus nerve is like your body's built-in anti-inflammatory highway. It runs from your brainstem down through your neck and into your chest and abdomen, carrying signals that help regulate everything from your heart rate to your digestive system. And when you stimulate the vagus nerve, it activates what researchers call the \"cholinergic anti-inflammatory pathway.\"","sample":true,"doi":"10.3389/fneur.2025.1642034","short":"vagus-nerve-concussions","released":"October 6th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Traumatic Brain Injuries","carousels":["Medicine","Cognitive Science","Neurology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"non-invasive-vagus-nerve-stimulation-is-associated-with-the-reduction-in-persistent-post-concussion-symptoms-an-observational-study"},{"title":"Co-DeepNet: A Cooperative Convolutional Neural Network for DNA Methylation-Based Age Prediction","description":"It's a system where two convolutional neural networks take turns training on a dataset, sharing knowledge with each other at regular intervals. The result? They can make predictions that outperform single CNNs while using fewer computational resources. On today's episode we’re going to walk through how this cooperative learning actually works, why it's more effective than traditional approaches, and what the results tell us about the future of efficient neural network design. Let's dive in.","sample":true,"doi":"10.1049/cit2.70026","short":"co-deep-net","released":"October 5th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Cooperative Deep Neural Network","carousels":["Convolutional Neural Networks","Model Training"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"co-deepnet-a-cooperative-convolutional-neural-network-for-dna-methylation-based-age-prediction"},{"title":"Artificial intelligence-assisted academic writing: recommendations for ethical use","description":"What makes this paper interesting is that they didn't just write guidelines, they practiced what they preached. They actually used ChatGPT to help them write parts of the article, and then documented exactly how they used it and what they learned from the process. And yes, it’s very meta. They used an LLM to help them write a paper about how to use LLMs to help you write papers. Inception.","sample":true,"doi":"10.1186/s41077-025-00350-6","short":"ai-assisted-academic-writing","released":"October 4th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Ethical LLM Usage","carousels":["Education"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"artificial-intelligence-assisted-academic-writing-recommendations-for-ethical-use"},{"title":"Macroswarm: A field-based compositional framework for swarm programming","description":"The system models the swarm as what researchers call an augmented event structure, where each event represents a round of three sub-events in a loop: sense-compute-interact. This loop is performed by a specific device at a specific point in time and space. In fact, it’s performed by every device, all at once. Each device: senses the environment, gathers messages from neighbors, computes new values and decides on actions, then interacts by sending messages and performing actuations.","sample":true,"doi":"10.46298/LMCS-21(3:13)2025","short":"macroswarm-aggregate-computing","released":"October 3rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Aggregate Computing for Swarms","carousels":["Robotics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"macroswarm-a-field-based-compositional-framework-for-swarm-programming"},{"title":"The Opinion of a Digital Influencer and the Investment Decision When Accounting Information is Available","description":"How much influence do “influencers” actually have? Can they sway public opinion about a product? Can they get you to purchase something you would otherwise never consider buying? Can they affect how you think about and perceive a company, or fundamentally affect its financial position? Can they move the markets? Or, are they essentially just spokespeople? No more persuasive than any other talking-head would be, and only as influential as the script they happen to be reading? Where’s the line? Where does promotion end and influence start? And is there really a difference?","sample":true,"doi":"10.1177/21582440251369597","short":"influencer-opinions","released":"October 2nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Digital Influencers","carousels":["Social Sciences","Social Media","Advertising","Marketing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-opinion-of-a-digital-influencer-and-the-investment-decision-when-accounting-information-is-available"},{"title":"Multi-step partitioning combined with SOM neural network-based clustering technique effectively improves SAT solver performance","description":"SAT solvers (that is: Boolean Satisfiability Problem solvers) are getting slower. At least in absolute terms, that is. Why? Because of the insane problems we've started asking them to solve. As integrated circuits get more complex and software systems get bigger, we've started asking these solvers to chew through exponentially larger search spaces, and to work on problems that we would have previously considered “intractable”.","sample":true,"doi":"10.7717/peerj-cs.3076","short":"som-neural-network","released":"October 1st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"SAT solver performance","carousels":["Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multi-step-partitioning-combined-with-som-neural-network-based-clustering-technique-effectively-improves-sat-solver-performance"},{"title":"Private cloud bespoke orchestrator: techniques for constructing and operating bespoke-private cloud virtual machine environments for cloud users","description":"Public clouds are great for getting started quickly, but they come with vendor lock-in, significant cost, and limited control. Private clouds give you more control and potentially lower long-term costs, but they're expensive to start, and complex to build and maintain. The sweet spot that's emerged over the last few years is the hybrid cloud model. You keep sensitive workloads (or any workload that some regulator is telling you that you can’t run on a public cloud) on your private cloud. And you use the public clouds for everything else, including temporary capacity spikes and specialized services. To make this work effectively, and to have a seamless handoff between the workloads running on either side of the fence, you need a solid foundation. Ideally one that doesn't require a team of infrastructure specialists to maintain.","sample":false,"doi":"10.1186/s13677-025-00760-x","short":"private-cloud-bespoke-orchestrator","released":"September 30th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Private Cloud Orchestrator","carousels":["Cloud Computing","Private Clouds","System Architecture"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"private-cloud-bespoke-orchestrator-techniques-for-constructing-and-operating-bespoke-private-cloud-virtual-machine-environments-for-cloud-users"},{"title":"Comparative evaluation of encoding techniques for workflow process remaining time prediction for cloud applications","description":"The authors are surveying the available options and benchmarking them against each other. They evaluated five different event encoding techniques, and combined them with nine deep learning models. Their goal wasn’t to invent another model, but to find out which representations of workflow events actually lead to the most accurate time predictions.","sample":false,"doi":"10.1186/s13677-025-00763-8","short":"remaining-time-prediction","released":"September 29th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Remaining Time Prediction","carousels":["Time Series Forecasting","Temporal Analysis"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"comparative-evaluation-of-encoding-techniques-for-workflow-process-remaining-time-prediction-for-cloud-applications"},{"title":"A leave-one-out algorithm for contribution analysis in component network meta-analysis","description":"Welcome to the messy world of component network meta-analysis. In traditional network meta-analysis (NMA), you're comparing complete treatments against each other. But component network meta-analysis (CNMA) is different because you’re figuring out individual contributions, and that is mathematically brutal. In regular NMA, you can trace evidence paths through a network of studies. You can say, \"Study X compared Treatment 1 to Treatment 2, and Study Y compared Treatment 2 to Treatment 3, so we can make indirect comparisons between Treatment 1 and Treatment 3.\" It's like connecting dots on a map. But in CNMA, those clean pathways disappear. When treatments share overlapping components, it gets messier, and blurrier, because you get what the authors call \"latent connections\" between treatments. A comparison between \"A+B\" and \"A+C\" tells you something about the difference between components B and C, even though no study directly compared B to C. And these implicit comparisons (this extra, cloudy set of information) make it very difficult to trace where a given outcome is actually coming from.","sample":false,"doi":"10.1186/s12874-025-02619-w","short":"leave-one-out-algorithm","released":"September 28th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Leave One Out Algorithm","carousels":["Algorithms","Meta Analysis","Systematic Review"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-leave-one-out-algorithm-for-contribution-analysis-in-component-network-meta-analysis"},{"title":"Improved RT-DETR Network for High-Quality Defect Detection on Digital Printing Fabric","description":"The core challenge is around getting computer vision to work in extremely nuanced and complex conditions. Digitally printed fabrics can have intricate, busy patterns. So it can be very hard for AI systems to distinguish between an intentional design element and an actual defect. Imagine looking at a fabric with flowers, swirls, and geometric patterns all mixed together. How can you train a computer to recognize that one line is out of place, or one specific color blob shouldn't be there? The authors’ solution is based on something called an RT-DETR (a Real-Time Detection Transformer). Think of it like a pattern recognition system that doesn't just look at individual pixels, but understands the relationships between different parts of an image. Traditional computer vision models struggle with fabric inspection because they rely heavily on local features. The RT-DETR approach is different. It actually uses a transformer architecture (like large language models do), but instead of understanding relationships between words in a sentence, it's understanding relationships between different regions of an image. This allows it to spot inconsistencies that would be invisible to other systems.","sample":false,"doi":"10.1080/15440478.2025.2476634","short":"improved-rt-detr","released":"September 27th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Real-Time Detection Transformer","carousels":["Transformers","Textiles","Manufacturing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"improved-rt-detr-network-for-high-quality-defect-detection-on-digital-printing-fabric"},{"title":"DAUD: A data driven algorithm to find discrete approximations of unknown continuous distributions","description":"It’s 1809, and Carl Friedrich Gauss is hard at work. He’s trying to figure out how to predict the paths of celestial bodies. How stars, galaxies, planets, asteroids and the like move across the sky. Astronomers of the day had plenty of measurements but they were noisy and full of mistakes, and because of these mistakes nobody could agree on the “true” orbit of anything. Gauss had an idea. Instead of treating all the measurement-errors as random chaos, he assumed that the mistakes followed a smooth, symmetric law. That is: small errors were more common than large ones, and extreme deviations were vanishingly rare. With this conceptual plot of how errors were distributed in the data, he couldn’t necessarily say which individual measurement was wrong or by how much, but he could characterize how the entire basket of observations was off in aggregate. This allowed him to apply the method of least squares, minimizing the squared deviations across all measurements, to recover the most likely “true” values hidden beneath the surface. The signal in the noise. Out of this reasoning came the curve we now call the Gaussian, or normal distribution. A bell-shaped line that rises gently in the middle and tapers at the edges. For the first time, it offered a way to make sense of messy data, to find order in apparent randomness. And over time, it became one of the most influential concepts in mathematics & statistics, showing up in physics, economics, psychology, and nearly every field that deals with uncertainty. Without the normal distribution, we wouldn’t have a common understanding of risk in finance, error in engineering, significance in science, or even what it means for a measurement to be “average”. ","sample":false,"doi":"10.1016/j.softx.2025.102281","short":"daud-algorithm","released":"September 26th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Non-Gaussian Distributions","carousels":["Data Science","Statistics","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"daud-a-data-driven-algorithm-to-find-discrete-approximations-of-unknown-continuous-distributions"},{"title":"Wearable Device for Continuous and Real-Time Monitoring of Human Sweat Sodium","description":"The authors have developed a wearable system that can continuously monitor sodium levels in your sweat as you exercise. In fact, they’ve built a complete platform for this: a custom microfluidic chip that handles sweat collection, a miniaturized potentiostat for electrochemical measurements, and wireless connectivity to stream the data to your phone.","sample":false,"doi":"10.3390/s25113467","short":"wearable-sodium","released":"September 25th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Real-Time Sweat Monitoring","carousels":["Fitness","Exercise","Health","Medical"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"wearable-device-for-continuous-and-real-time-monitoring-of-human-sweat-sodium"},{"title":"AI-Driven Nudge Optimization: Integrating Two-Tower Networks and Multi-Armed Bandit With Behavioral Economics for Digital Banking Campaign","description":"In this paper, the authors take the principles of behavioral economics and build a recommendation system around them. A system that doesn’t just predict what you might want, but actively guides you there: framing and pitching the products in the way most likely to convince you. And timing the pitch for the moment it knows you are most susceptible to influence.  On today’s episode, we'll walk through how they did it. We'll see how they combined two-tower neural networks with multi-armed bandit algorithms, and synthesized them into a system that learns and adapts in real-time. A system that continuously crafts, reformulates and deploys the perfect nudge at the perfect moment.","sample":false,"doi":"10.1109/ACCESS.2025.3584648","short":"nudge-optimization","released":"September 24th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Nudge Optimization","carousels":["Optimization","Finance","Banking"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"ai-driven-nudge-optimization-integrating-two-tower-networks-and-multi-armed-bandit-with-behavioral-economics-for-digital-banking-campaign"},{"title":"Optimization of fuzzy bottleneck cost transportation models in the decision framework of congruence modulo technique","description":"Your challenge is to solve this routing and optimization problem such that you end up with the best worst-case scenario. The issue is, traditional optimization methods struggle when you can't pin down exact values for your constraints. As I said earlier, you’re dealing with nothing but uncertainty today. And that’s an issue. Linear programming, for example, is the go-to method for transportation problems, but it requires precise input values. Goal programming can handle multiple objectives, but still needs crisp numbers. Branch and bound algorithms can find optimal solutions but they become computationally intractable when you introduce uncertainty. That is: the search space explodes exponentially.","sample":false,"doi":"10.1016/j.aej.2025.07.002","short":"fuzzy-bottleneck","released":"September 23rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fuzzy Bottleneck Cost Optimization","carousels":["Algorithms","Optimization"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"optimization-of-fuzzy-bottleneck-cost-transportation-models-in-the-decision-framework-of-congruence-modulo-technique"},{"title":"Evaluation of Prompt Engineering on the Performance of a Large Language Model in Document Information Extraction","description":"Data extraction seems easy and straightforward, until you try it at scale. Because it’s only at scale that all the corner cases and variations, and version-changes and schema updates start to reveal themselves. For example: imagine that your task is to build a system that can pull data from a pile of invoices. But that pile is heterogenous, no two invoices are exactly alike. At the bottom of one invoice it says “Amount Due” The bottom of another says “Total”. A third says “Final Cost - Unpaid” at the top, and the fourth just has an unlabeled line item below a table.","sample":false,"doi":"10.3390/electronics14112145","short":"prompt-engineering","released":"September 22nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Prompt Engineering","carousels":["Large Language Models"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"evaluation-of-prompt-engineering-on-the-performance-of-a-large-language-model-in-document-information-extraction"},{"title":"4D trajectory lightweight prediction algorithm based on knowledge distillation technique","description":"What do air traffic control systems do, exactly? Well, broadly, their mandate is to route planes around each other safely. In practice, this often means needing to not-only plot where a plane is, but predict where it’s going to be, and when it’s going to get there. This is inherently a 4D trajectory prediction problem. The four dimensions being longitude, latitude, altitude, and time. And as air traffic density continues to grow worldwide, the computational demands of this kind of real-time prediction are pushing existing systems to their breaking point.","sample":false,"doi":"10.3389/fnbot.2025.1643919","short":"4d-trajectory","released":"September 21st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Knowledge Distillation","carousels":["Algorithms","Model Training","Transportation"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"4d-trajectory-lightweight-prediction-algorithm-based-on-knowledge-distillation-technique"},{"title":"Dynamic scheduling strategies for cloud-based load balancing in parallel and distributed systems","description":"If you’re running a large cluster of interconnected cloud services, a systemic failure probably won’t start with a ‘crash’. There will be no loud explosion or dramatic boom. Not at the early stages of the problem anyway. Initially, all you’ll hear is a faint whine. One node, struggling to keep its head above water. It could be a webserver, or a database, or a queue, or a cache, or a block store…whatever your bottleneck (the weakest part of your system) happens to be. You’ll notice it hiccuping, and sweating. You’ll see its performance slowly degrading, and becoming less predictable, as the machine, little by little, gets completely overwhelmed. Then finally, minutes, or hours, or weeks later, it goes down. Taking who-knows-what with it along the way.","sample":false,"doi":"10.1186/s13677-025-00757-6","short":"dynamic-scheduling-strategies","released":"September 20th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Cloud-Based Load Balancing","carousels":["System Architecture","Cloud Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"dynamic-scheduling-strategies-for-cloud-based-load-balancing-in-parallel-and-distributed-systems"},{"title":"Old MacDonald and His Hackable Smartphone Application: A Security and Privacy Analysis of Android Agriculture Applications","description":"Today we're diving into a comprehensive security analysis of Android agricultural applications. We'll look at what makes farming apps so vulnerable, why attackers might target them, and what the implications are for our critical infrastructure. These authors showed that while farmers are increasingly relying on smartphone applications to run their operations, these apps are riddled with security vulnerabilities. The authors found that every single application they analyzed contained at least three known security flaws.","sample":false,"doi":"10.1109/ACCESS.2025.3584673","short":"old-macdonald-hackable-smartphone","released":"September 19th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Hackable Android Applications","carousels":["Security","Agriculture"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"old-macdonald-and-his-hackable-smartphone-application-a-security-and-privacy-analysis-of-android-agriculture-applications"},{"title":"Analysis of the Navigation of Magnetic Microrobots through Cerebral Bifurcations for Targeted Drug Delivery","description":"Ischemic strokes happen when a blood clot blocks an artery in the brain, cutting off oxygen and nutrients to downstream brain tissue. It's one of the leading causes of death worldwide, and its incidence has been trending upwards for decades. In other words: they’ve been a problem for a long time, and are becoming a larger and larger problem every year. When doctors try to treat these kinds of strokes, they typically use thrombolytic agents: drugs that dissolve clots. The problem is, these drugs have to be injected systemically, so the medication gets diluted throughout your entire bloodstream instead of going directly to where it's needed. Only about 20% of stroke cases respond to this kind of treatment. In many other cases, the clots are too big to dissolve in time, and doctors can't increase the dosage of the agent because these drugs are toxic in and of themselves. They can cause serious side effects, including dangerous bleeding. The last thing they want to do is take a patient who needs their help and introduce a life-threatening condition they didn’t come in with.","sample":false,"doi":"10.1002/aisy.202400993","short":"cerebral-bifurcations","released":"September 18th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Magnetic Microrobots","carousels":["Nanotechnology","Microtechnology","Nanorobots","Robotics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"analysis-of-the-navigation-of-magnetic-microrobots-through-cerebral-bifurcations-for-targeted-drug-delivery"},{"title":"Exploiting Multitask Deep Learning to Identify Multiple Heavy Metal Contamination at Large Scales","description":"They’ve developed a multitask deep learning system that can simultaneously detect multiple heavy metals in soil using visible and near-infrared spectroscopy. And critically: it scales. As part of this study, they applied this technique across the entire European continent to create the first comprehensive map of manganese, chromium, and cobalt contamination at that scale. Let’s dive in. Heavy metals are exactly what they sound like: metallic elements that are dense and often toxic to living organisms. Unlike organic pollutants that eventually break down, heavy metals are accumulative and nondegradable. Once they're in the soil, they're there to stay. They can contaminate crops, enter the food chain, and pose serious risks to human health.","sample":false,"doi":"10.1002/aisy.202500469","short":"multitask-deep-learning","released":"September 17th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Multitask Deep Learning","carousels":["Deep Learning","Reinforcement Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"exploiting-multitask-deep-learning-to-identify-multiple-heavy-metal-contamination-at-large-scales"},{"title":"Exploring cognitive presence patterns in GenAI-integrated six-hat thinking technique scaffolded discussion: an epistemic network analysis","description":"We normally think about LLMs (and other AI tools) as equalizers and normalizers. They’re, ostensibly, supposed to help the lower-performing students raise their output to match the more talented kids. Right? Well, no. It doesn’t appear that way at all. This paper is arguing that the real effect is the opposite. Their data is showing that these tools are acting not as an equalizer, but as a cognitive amplifier. They don’t just make everything and everyone better. For each individual they make both your existing strengths and your existing weaknesses louder. Effectively exacerbating specific achievement gaps, not closing them.","sample":false,"doi":"10.1186/s41239-025-00545-x","short":"six-hat-thinking","released":"September 16th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Cognitive Presence Patterns","carousels":["Large Language Models"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"exploring-cognitive-presence-patterns-in-genai-integrated-six-hat-thinking-technique-scaffolded-discussion-an-epistemic-network-analysis"},{"title":"Energy Efficient VM Selection Using CSOA‐VM Model in Cloud Data Centers","description":"The authors developed a system called CSOA-VM that uses an optimization algorithm to make smarter decisions about which VMs to place where, and when to move them around. Under testing, their approach managed to reduce energy consumption slightly while cutting down on SLA violations. But before we dive into their solution, let's talk about why this problem is such a big deal in the first place.","sample":false,"doi":"10.1049/cit2.70018","short":"energy-efficient-vm-selection","released":"September 15th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Energy Efficient VM Selection","carousels":["Virtual Machines","Virtualization","Algorithms","Containers"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"energy-efficient-vm-selection-using-csoavm-model-in-cloud-data-centers"},{"title":"Comprehensive Assessment of Electric Vehicle Charging Impact on Distribution Networks: Integrating Diversity in Fleet and Electricity Tariffs","description":"Those local distribution transformers are the key here. Each one typically serves anywhere from a few dozen to a few hundred homes. They're rated for a certain maximum load, and if that load gets exceeded for too long, they can overheat and fail. This is expensive to fix and leaves people without power. Now, here's the thing about how people use electricity. There's a daily pattern called the \"load curve.\" Most of the day, usage is relatively low. But around 6 PM, when people get home from work, start cooking dinner, turn on the TV, and run their appliances, there's a big spike in demand. This is called the \"evening peak.\"","sample":false,"doi":"10.1109/ACCESS.2025.3584326","short":"ev-charging-impact","released":"September 14th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Electric Vehicle Charging Impact","carousels":["Transportation","Electric Vehicles","Smart Grid","Electricity"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"comprehensive-assessment-of-electric-vehicle-charging-impact-on-distribution-networks-integrating-diversity-in-fleet-and-electricity-tariffs"},{"title":"DBF-Net: A Deep Bidirectional Fusion Network for 6D Object Pose Estimation with Sparse Linear Transformer","description":"This is the problem of 6D object pose estimation. Determining not just where an object is located in 3D space, but also how it's rotated. That's 3 dimensions for position: x, y, and z. And 3 more dimensions for orientation: pitch, yaw, and roll. Get this wrong, and your robot either misses the object entirely or mangles it with a poorly-angled grip.","sample":false,"doi":"10.1002/aisy.202401001","short":"deep-bidirectional-fusion","released":"September 13th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Deep Bidirectional Fusion","carousels":["Deep Learning","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"dbf-net-a-deep-bidirectional-fusion-network-for-6d-object-pose-estimation-with-sparse-linear-transformer"},{"title":"User migration in the Twitter diaspora","description":"While everyone was busy arguing about what Twitter was becoming, researchers were quietly tracking something much more objective. They were watching the data. Specifically, they were tracking who was leaving Twitter, where they were going, and most interestingly, whether (or not) their influence was following them to their new digital homes.","sample":false,"doi":"10.1140/epjds/s13688-025-00552-y","short":"twitter-diaspora","released":"September 12th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Twitter Diaspora","carousels":["Social Networking","Social Media"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"user-migration-in-the-twitter-diaspora"},{"title":"A Systematic Literature Review on Large Language Models Applications in Computer Programming Teaching Evaluation Process","description":"Today we're diving into a systematic mapping study that examines how LLMs are currently being applied to programming-education assessment. The authors analyzed a few dozen studies across multiple years to understand what's working, what isn't, and where this field is headed. What they found reveals a fundamental shift in how we think about teaching people to code.","sample":false,"doi":"10.1109/ACCESS.2025.3584060","short":"llms-for-teaching","released":"September 11th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"LLMs for Programming Education","carousels":["Education","Large Language Models","LLMs"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-systematic-literature-review-on-large-language-models-applications-in-computer-programming-teaching-evaluation-process"},{"title":"Developing a tourism circuit around a brownfield destination: a framework based on analytic hierarchy process and weighted Shapley value","description":"The authors have developed a framework for creating tourism “circuits” that extend visitor stays and distribute economic benefits across multiple locations. Instead of showing-up and leaving, this framework encourages tourists to explore nearby sites, spend more time in the area, and engage with a wider range of local experiences. The impact is a longer stay, higher spending, and more balanced growth across the region. The research comes from the Ramanathapuram district in Tamil Nadu, India, where nearly 23 million tourists visit each year and head to the famous religious sites. The problem is, only just-over 300,000 make it to the other culturally significant temples and landmarks in the same district. The authors’ solution is a two-step mathematical framework: first, they use multi-criteria decision analysis to prioritize strategies for extending tourist stays, then they apply cooperative game theory to determine how government subsidies should be allocated across underdeveloped sites to handle increased visitor demand.","sample":false,"doi":"10.1080/29966892.2025.2459401","short":"brownfield-destination","released":"September 10th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Analytic Hierarchy Process","carousels":["Tourism","Data Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"developing-a-tourism-circuit-around-a-brownfield-destination-a-framework-based-on-analytic-hierarchy-process-and-weighted-shapley-value"},{"title":"Advancing human activity recognition with quaternion-based recurrent neural networks","description":"The year was 1843, and William Rowan Hamilton had a problem. He had already tamed the complexities of complex numbers, which could describe motion and transformations in two dimensions. But what about the 3rd dimension? He longed for a similar system that could handle three-dimensional space. And he wrestled with it for years, trying in vain to extend the rules of numbers into higher dimensions. The breakthrough came while he was out on a walk along Dublin’s Royal Canal. Legend has it that he carved the equation.","sample":false,"doi":"10.1080/00051144.2025.2480419","short":"human-activity-recognition","released":"September 9th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Quaternion based Recurrent Neural Networks","carousels":["3D Mapping","Fitness Tracking","Artificial Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"advancing-human-activity-recognition-with-quaternion-based-recurrent-neural-networks"},{"title":"Few-Shot Optimization for Sensor Data Using Large Language Models: A Case Study on Fatigue Detection","description":"The few-shot learning problem is everywhere. You see it in medical diagnostics and fraud detection. You see it when a manufacturing engineer tries to spot early signs of equipment failure and when a cybersecurity analyst tries to spot a new malware strain. You see it in industrial fault monitoring, and speech recognition, and crop disease detection, and astronomy. In the real world, you just don't always have massive labeled datasets. Sometimes all you’ve got is a handful of examples...but...you still need to make it work.","sample":false,"doi":"10.3390/s25113324","short":"few-shot-optimization","released":"September 8th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Few Shot Optimization","carousels":["Large Language Models","Optimization"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"few-shot-optimization-for-sensor-data-using-large-language-models-a-case-study-on-fatigue-detection"},{"title":"Milgram’s experiment in the knowledge space: individual navigation strategies","description":"This study takes inspiration from Stanley Milgram’s famous “small world” experiment from the 1960s. In it, participants tried to get a letter to a stranger in another city by sending it only to people they knew personally (through their social network). Milgram wanted to measure how connected people actually were. The result, that it took about six handoffs on average, gave rise to the idea of “six degrees of separation.” In this study, the researchers moved that concept into the digital realm: instead of passing letters through friends-of-friends, participants had to navigate from one Wikipedia page to another using only links. What they discovered challenges how we think about both digital literacy and human cognition.","sample":false,"doi":"10.1140/epjds/s13688-025-00558-6","short":"milgrams-experiment","released":"September 7th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Milgram's Experiment","carousels":["Social Networking","Sociology","Cognitive Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"milgrams-experiment-in-the-knowledge-space-individual-navigation-strategies"},{"title":"Enhancing Robustness in Feature Importance Methods with NAFIC and CESHAP for Improved Interpretability","description":"The steel industry is particularly brutal for machine learning models. It's one of the most energy-intensive sectors on the planet, and every inefficiency in the production process translates directly into significant cost and environmental impact. When you're dealing with blast furnaces, material feed rates, and complex chemical reactions, the data is inherently noisy, multi-faceted, and full of intricate feature interactions. Traditional explainability methods like SHAP and Permutation Feature Importance (PFI) weren't really designed for this kind of environment.","sample":false,"doi":"10.1080/08839514.2025.2515062","short":"enhancing-robustness-nafic-and-ceshap","released":"September 6th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Feature Importance Methods","carousels":["Model Training","Feature Selection"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"enhancing-robustness-in-feature-importance-methods-with-nafic-and-ceshap-for-improved-interpretability"},{"title":"Imageless optical navigation system is clinically valid for total knee arthroplasty","description":"A key component of this procedure is something called coronal alignment. After the doctor has made the cuts, but before they install the implants, they’ll need to align the joint components along the mechanical axis of your leg. This is tough. It requires the doctor to visualize internal angles while holding guides and cutting tools precisely. This is typically done with image-based navigation systems or mechanical alignment guides. But the overall difficulty (and importance) of coronal alignment mean that many researchers are looking for ways to do it better. To achieve perfect alignment without needing more advanced imaging. CT scans and X-rays work, but they’re expensive. They take time and can expose the patient to unnecessary radiation. So if you can build a tool or system that can avoid them, you might be able to make surgeries faster, safer, and more accessible. That’s where today’s paper comes in.","sample":false,"doi":"10.1080/24699322.2025.2466424","short":"imageless-optical-navigation","released":"September 5th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Total Knee Arthroplasty","carousels":["Medical","Surgery"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"imageless-optical-navigation-system-is-clinically-valid-for-total-knee-arthroplasty"},{"title":"Deep Learning vs. Machine Learning for Intrusion Detection in Computer Networks: A Comparative Study","description":"Traditional rule-based systems are only good at checking for the threats they've seen before. Check for someone pinging this port in this specific way. Look out for URLs that embed would-be SQL injections in the query string, etc. But what happens when the attacker does something new? When the behavior simply doesn’t look like anything the system has been built to detect. This is the challenge being tackled in today's paper. The authors are trying to determine if deep-learning models might be the answer here. Is it possible that they’ll be able to pick up the slack, and detect novel attack patterns that rule-based systems might have missed? On today’s episode we’ll walk through how they conducted their analysis, and the results they obtained","sample":false,"doi":"10.3390/app15041903","short":"deep-learning-vs-machine-learning","released":"September 4th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Intrusion Detection Comparison","carousels":["Security"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"deep-learning-vs-machine-learning-for-intrusion-detection-in-computer-networks-a-comparative-study"},{"title":"The secret behind instant messaging: video identification attack against complex protocols","description":"This is where side-channel attacks come into play. Instead of breaking the encryption directly, these attacks analyze the patterns and characteristics of encrypted traffic to infer what's happening underneath. In the case of video streaming platforms like YouTube or Netflix, researchers have already shown that you can identify which videos people are watching by analyzing encrypted traffic patterns. These platforms use something called DASH (Dynamic Adaptive Streaming over HTTP), which breaks videos into segments and transmits them at variable bitrates. Each video has a unique \"fingerprint\" based on how these segments are sized and sequenced. So even when they’re encrypted, you can still see the size and timing patterns of the data chunks, and that's enough to identify specific videos.","sample":false,"doi":"10.1186/s42400-024-00300-1","short":"video-identification-attack","released":"September 3rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Video Identification Attacks","carousels":["Security"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-secret-behind-instant-messaging-video-identification-attack-against-complex-protocols"},{"title":"Unsupervised detection of coordinated information operations in the wild","description":"Here's the thing about CIOs: they're designed to blend in. The whole point is to look authentic. The Russian Internet Research Agency, for example, made up only less than 1% of all election-related tweets during the 2016 U.S. election. This isn’t quite a needle-in-a-haystack scenario, but it’s still a formidable problem. If you’re deliberately trying to find and identify these types of attacks, you’re going to find two orders of magnitude more noise than signal. Making matters worse, there are often multiple operations running simultaneously. During the 2017 BLM protests, for example, both Russian and Iranian operations were active at the same time, each with their own goals and tactics. So you're not just looking for one set of bots pushing one kind of narrative, you're sifting through an unknown number of operations at any given time.","sample":false,"doi":"10.1140/epjds/s13688-025-00544-y","short":"coordinated-information-operations","released":"September 2nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Coordinated Information Operations","carousels":["Media","Social Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"unsupervised-detection-of-coordinated-information-operations-in-the-wild"},{"title":"Knowledge-Based Planning for Human-Robot Collaborative Tasks","description":"Traditional robot programming is like writing a detailed script for every possible situation. \"If you see a bolt at coordinates X,Y,Z, pick it up using grip strength N, then move to position A,B,C.\" It works fine for repetitive tasks in controlled environments, but it falls apart the moment anything changes. What if the bolt is in a slightly different position? What if there's a new type of part? What if the human worker needs the robot to adapt its sequence based on what they're currently doing?","sample":false,"doi":"10.1109/ACCESS.2025.3583469","short":"knowledge-based-planning","released":"September 1st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Human-Robot Collaboration","carousels":["Robotics","Task Planning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"knowledge-based-planning-for-human-robot-collaborative-tasks"},{"title":"Ctta: a novel chain-of-thought transfer adversarial attacks framework for large language models","description":"What makes this a real attack vector isn’t that someone would sit down and sabotage their own prompt, but that many LLM workflows involve reasoning over text written by other people. If your model is summarizing customer reviews, analyzing patient notes, or extracting insights from contracts, those inputs may come from untrusted or even adversarial sources. A CTTA adversary doesn’t need to change your instruction prompt, they only need to submit or embed a carefully perturbed text record into the data stream. Because the model is then asked to “think step by step” about that record, the poisoned phrasing nudges its reasoning off course. The dangerous part is that the corrupted output doesn’t just affect the attacker’s own request: it shows up in analytics dashboards, decision-support tools, or automated reports that other users or decision-makers rely on. In this way, a single malicious input can silently distort the model’s reasoning for everyone else downstream, making CTTA a collective rather than just a personal risk.","sample":false,"doi":"10.1186/s42400-024-00338-1","short":"chain-of-thought-transfer","released":"August 31st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Chain of Thought Attacks","carousels":["Security","Large Language Models"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"ctta-a-novel-chain-of-thought-transfer-adversarial-attacks-framework-for-large-language-models"},{"title":"Temporal dynamics of the friendship paradox in a smartphone communication network","description":"In his book The Tipping Point, Malcolm Gladwell describes the three types of people you need to get a movement or a phenomenon to “tip.” That is, to get it to break out of a subculture and into the mainstream. Mavens, who accumulate and share knowledge. Salesmen, who persuade and influence others. Connectors, who know lots of people and link different social groups together. That last group, connectors, is what we're talking about today. Imagine that you and all your friends are \"nodes\" in a graph. If you have a friendship with someone, that friendship itself is an \"edge\" connecting you two. As you zoom out from the graph you see an interconnected web of friendships and friend-groups. Now imagine that, out of a few hundred nodes, there are a couple nodes with far more edges leading towards them. For every friendship you have, they might have 10. These are the connectors. The social butterflies. The popular kids. We call them high-degree nodes. The virtue of their extreme connectedness means that their very existence creates a statistical phenomenon called the Friendship Paradox.","sample":false,"doi":"10.1007/s41109-025-00710-1","short":"the-friendship-paradox","released":"August 30th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"The Friendship Paradox","carousels":["Social Sciences","Social Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"temporal-dynamics-of-the-friendship-paradox-in-a-smartphone-communication-network"},{"title":"Pattern-Based Feature Extraction for Improved Deep Learning in Financial Time Series Classification","description":"Time series data is inherently noisy, non-stationary, and locally unpredictable. But traders still need to make directional calls. So they turn to indicators like moving averages, Bollinger Bands, or MACD. And more recently, deep learning and sequence models like LSTM and GRU have been used to learn richer representations directly from the market data. This is a promising direction, for sure, but in practice these models often hit a wall. They’re handed data without context, and expected to find structure in patterns that were never explicitly described. OHLCV data captures price activity, but it doesn’t say much about how prices moved, what shapes they traced, how sharp the turns were, or how compressed the swings were. And when markets are moving fast, those shapes matter. Two 5% moves can have completely different meanings depending on how they got there. Without explicit signals to guide them, models end up modeling noise. What they’re missing is a mechanism for extracting structured, geometry-aware features from the raw price movements. Features that can compress complex temporal patterns into learnable signals.","sample":false,"doi":"10.1109/ACCESS.2025.3584251","short":"pattern-based-feature-extraction","released":"August 29th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Pattern-Based Feature Extraction","carousels":["Model Training","Feature Extraction","Time Series Forecasting","Finance","Trading","Economics","Deep Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"pattern-based-feature-extraction-for-improved-deep-learning-in-financial-time-series-classification"},{"title":"AKG-VO: Adaptive Keyframe Generation Method for Improving Visual Odometry in Autonomous Vehicles","description":"In Visual Odometry (VO), instead of using wheel sensors, the vehicle uses cameras to track how the scene around it changes from frame to frame. It estimates its own motion by analyzing how objects and features move in the environment. The car basically watches the world go by, then deduces how it must be moving through that world. This involves detecting visual features (like corners, blobs, or textured patches) in one frame, then finding where those same features appear in the next. Once these correspondences are established, the system estimates the relative motion between the frames. This often involves computing the essential or fundamental matrix, decomposing it into rotation and translation components, and using triangulation to infer 3D structure.","sample":false,"doi":"10.1002/aisy.202401119","short":"adaptive-keyframe-generation","released":"August 28th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Adaptive Keyframe Generation","carousels":["Autonomous Driving","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"akg-vo-adaptive-keyframe-generation-method-for-improving-visual-odometry-in-autonomous-vehicles"},{"title":"Recent Advances in Reinforcement Learning for Chemical Process Control","description":"Control systems are dynamic and continuous. Operators must control variables like temperature, pressure, concentration, and flow rate by adjusting actuators (eg: valves, or pumps, or heaters). The goal for any operator is to maintain the system’s desired operating conditions in the face of disturbances, nonlinearities, delays, and constraints. And they need to do this all while optimizing for throughput, energy use, and emissions. Given the importance, scale, and sensitivity of these systems, control architectures have to be reliable, interpretable, and robust.","sample":false,"doi":"10.3390/pr13061791","short":"chemical-process-control","released":"August 27th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Chemical Process Control","carousels":["Manufacturing","Chemistry","Supply Chain","Operations","Chemical Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"recent-advances-in-reinforcement-learning-for-chemical-process-control"},{"title":"Unseen: Advancing Digital Accessibility with Binaural Audio Technology in an Immersive Gaming Prototype","description":"For most 3D games, vision isn’t just part of the experience, it is the experience. The entire interface is built around it. Movement, interaction, feedback, and even storytelling are overwhelmingly visual. For blind and visually impaired players, this presents a near-total barrier to entry. You’re not just missing a few graphics. You’re missing the map, the Heads-Up Display, the cues that tell you where to go, what you’ve found, and what’s happening in the world around you. And while some mainstream games have certainly made some strides towards accessibility (offering features like screen reader support, audio menus, or controller vibration feedback) these adaptations tend to patch the edges, not solve the core problem. The player might be able to navigate a menu, but when the game drops them into a dynamic 3D environment, there’s no equivalent to spatial awareness, visual targeting, or ambient orientation. The player isn’t missing tools, they’re missing affordances without which, the sensory logic of the game breaks down. And that’s the central challenge the authors of today’s paper are trying to tackle.","sample":false,"doi":"10.5753/jis.2025.4439","short":"binaural-audio","released":"August 26th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Binaural Audio","carousels":["Signal Processing","Audio Processing","User Experience","Game Development"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"unseen-advancing-digital-accessibility-with-binaural-audio-technology-in-an-immersive-gaming-prototype"},{"title":"Perception and Precision: How VST and OST Headsets Influence Task Execution","description":"In a VST system, the user never sees the real world directly. Instead, the headset uses one or more forward-facing RGB cameras (typically positioned near eye level) to continuously capture the external environment. These camera feeds are sent through an image processing pipeline that may include distortion correction, color balancing, depth estimation, and pose tracking. Virtual content is then rendered into the same space using 3D engines, and the composited output is displayed on internal near-eye screens (typically OLED or LCD panels). What this means, practically, is that your entire visual field, including what would otherwise be raw, unaided vision, is now a digital reconstruction of the world. The system has full control over the pixels, allowing for very tight integration of virtual and physical elements, as well as visual effects like occlusion or global relighting. However, this full-pipeline approach introduces a measurable delay, because the physical light rays that would normally reach your retina must first pass through a camera sensor, travel through a software stack, and finally be emitted by a display panel. That end-to-end latency is usually in the range of 20 to 50 milliseconds, depending on frame rate, encoding pipeline, sensor speed, and whether motion prediction is used to compensate. Even with low-latency optimizations, that delay can disrupt fast visuomotor coupling, especially during quick eye movements or rapid head turns. Additionally, because the image is generated from stereo cameras mounted a few centimeters apart on the headset shell (not from your actual eye position) parallax errors can emerge when interacting with objects at arm’s length. This makes fine-grained depth judgment more difficult. Additionally, most VST systems are limited in dynamic range and focus flexibility: unlike the human eye, which can adaptively accommodate to nearby or distant objects, most camera lenses are fixed-focus and tuned for a depth of field optimized for mid-range vision. This can make close-up content look subtly blurred or unnatural. Finally, VST systems typically restrict peripheral vision because the rendered image field is constrained by the display optics, which in turn can limit ambient spatial awareness and increase cognitive load in tasks requiring precise motor control.","sample":false,"doi":"10.5753/jis.2025.5921","short":"vst-ost-headsets","released":"August 25th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"VST vs OST Headsets","carousels":["Augmented Reality","Virtual Reality"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"perception-and-precision-how-vst-and-ost-headsets-influence-task-execution"},{"title":"Modeling supply chain risk events by considering their contributing events: a systematic literature review","description":"Supply chain disruptions don’t happen in isolation. They ripple. Some are triggered internally (like forecasting errors), others come from outside (like geopolitical conflict or natural disasters). But, importantly, most disruptions don’t start at the moment they become visible. They build slowly, unevenly, from smaller incidents. A missed quality check, a delayed customs clearance, a misread weather forecast. These are called contributing events, upstream conditions that increase the likelihood of downstream risk. The disruption itself is called the risk event, the early tremors are the contributors. And that distinction (between root conditions and final outcomes) is exactly where many current models fall short.","sample":false,"doi":"10.1080/17517575.2025.2472303","short":"supply-chain-risk-events","released":"August 24th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Supply Chain Risk Events","carousels":["Manufacturing","Logistics","Supply Chain","Operations"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"modeling-supply-chain-risk-events-by-considering-their-contributing-events-a-systematic-literature-review"},{"title":"Augmentation of Semantic Processes for Deep Learning Applications","description":"At its core, BPM is about formalizing the recurring tasks an organization performs, and turning them into structured models. Models that define who does what, in what order, using what kind of data. These models are often drawn up using BPMN diagrams or Petri nets. BPMN diagrams look like flowcharts. They’re designed to be intuitive for business analysts. Petri nets are a more mathematical modeling tool that represents processes as a network of places, transitions, and tokens. These are used for more formal analysis.","sample":false,"doi":"10.1080/08839514.2025.2506788","short":"augmentation-of-semantic-processes","released":"August 13th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Business Process Models","carousels":["Process Models","Deep Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"augmentation-of-semantic-processes-for-deep-learning-applications"},{"title":"Multi strategy Horned Lizard Optimization Algorithm for complex optimization and advanced feature selection problems","description":"The horned lizard is such an odd specimen that it has inspired its own optimization algorithm. Aptly named the Horned Lizard Optimization algorithm (HLOA). And in today's paper, the authors try to improve on it. Their version, called the Multi-strategy Horned Lizard Optimization Algorithm (mHLOA), adds a Local Escaping Operator, Orthogonal Learning, and RIME-based diversification in an attempt to escape local optima and improve convergence. On today’s episode we’ll walk through how traditional HLOA works, its shortcomings, and what mHLOA does differently. Let’s jump in. First, let's talk about the types of problems that HLOA is designed to solve. Let's say you have a massive dataset with hundreds of features, and you want to build a predictive model. For example, you have a dataset of customer shopping habits and you want a model that can predict which products someone is likely to buy next.","sample":false,"doi":"10.1186/s40537-025-01205-7","short":"horned-lizard-optimization","released":"August 3rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Horned Lizard Optimization","carousels":["Algorithms","Optimization"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multi-strategy-horned-lizard-optimization-algorithm-for-complex-optimization-and-advanced-feature-selection-problems"},{"title":"A Pipeline for Automating Emergency Medicine Documentation Using LLMs with Retrieval Augmented Text Generation","description":"Imagine that you're a doctor working in an Emergency Room. A few minutes ago, two patients came in, one with severe chest pain, the other with a broken rib. You managed to stabilize them both, and sent the latter off to get an X-ray. Now you've got a patient who appears to have had a stroke, and you're working to assess her and get her up to neuro for a CT scan. At the same time, you're fielding updates from an inbound ambulance. They've got a gunshot victim, and they'll be here in 30 seconds. To handle all of this in real time, you need 8 arms, and the ability to multitask like a pro. But you're handling it, you're getting it all done. But oh... right... there's one other thing. Everything you're doing needs to be documented. Every symptom, every vital, every medication, every procedure, every response from the patient. It all needs to be written down, in detail, in real time, with clinical (and legal) precision. In emergency medicine, documentation isn’t just a bureaucratic task, it’s a vital part of the care process. The chart becomes the official record of what happened, what was observed, and what decisions were made. It has to be complete, it has to be accurate, and it must be done on time.","sample":false,"doi":"10.1080/08839514.2025.2519169","short":"emergency-medicine-documentation","released":"July 29th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Automating ER Documentation","carousels":["Medicine","Automation","Large Language Models","Nursing","Hospital Administration"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-pipeline-for-automating-emergency-medicine-documentation-using-llms-with-retrieval-augmented-text-generation"},{"title":"What is the State of the Art on UX Data Visualization? A Systematic Mapping of the Literature","description":"At the domain level, the focus is on identifying the application context and the target user group. This includes understanding the goals of the visualization from the perspective of the stakeholders. Such as whether it's intended for UX researchers, software developers, or end users. Domain-level reasoning ensures that the visualization is not being designed in a vacuum, it ties the design to real-world use cases and user needs. The next level is Data Task Abstraction, which is actually two different parts: data abstraction and task abstraction. Data abstraction involves deciding how to represent the raw domain data in a format suitable for visualization. For example, this could be turning clickstream logs into event sequences, or survey responses into ordinal values. Task abstraction refers to what the user is meant to accomplish with the visualization. Is it meant for exploring patterns, comparing values, filtering, identifying outliers, or tracking changes over time?","sample":false,"doi":"10.5753/jis.2025.4487","short":"ux-data-visualization","released":"July 28th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"UX Data Visualization","carousels":["UX","Design","User Experience","UX Research"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"what-is-the-state-of-the-art-on-ux-data-visualization-a-systematic-mapping-of-the-literature"},{"title":"Large Language Models With Contrastive Decoding Algorithm for Hallucination Mitigation in Low‐Resource Languages","description":"In the summer of 2024, Nand Mulchandani, the Chief Technology Officer of the CIA, was on the interview circuit. He had an important message for the public, and was telling anyone that would listen. Large Language Models, he said, should be treated as \"your crazy, drunk friend\". He was referring, broadly, to LLMs propensity to “hallucinate”. As he told a reporter from AP: \"Remember that these AI-based systems are probabilistic in nature, so they are not precise (They are prone to fabrication). So for creative tasks like art, poetry, and painting these systems are excellent. But I wouldn’t yet use these systems for doing precise math or designing an airplane or skyscraper - in those activities 'close enough' doesn’t work.\"","sample":false,"doi":"10.1049/cit2.70004","short":"hallucination-mitigation","released":"July 31st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"LLM Hallucination","carousels":["Large Language Models","LLMs"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"large-language-models-with-contrastive-decoding-algorithm-for-hallucination-mitigation-in-lowresource-languages"},{"title":"Using similarity network analysis to improve text similarity calculations","description":"The Universal Sentence Encoder provides a strong baseline with its ability to encode sentences into fixed-length embeddings. This makes it particularly effective for capturing semantic similarity in a scalable way. USE is available in two versions: one based on a deep averaging network (DAN), and another using a Transformer architecture. They’re both designed to produce sentence embeddings that capture semantic content effectively. Regardless of the version you use, its architecture facilitates efficient processing of large volumes of text while ensuring that resultant embeddings retain contextually relevant semantic features. BERT offers heightened sensitivity to context through a bidirectional training mechanism. By pre-training transformers on a large corpus and fine-tuning them on downstream tasks, BERT generates contextual embeddings that reflect more nuanced semantic relationships. This model is particularly adept at understanding the meaning of words in context, producing embeddings that reveal intricate semantic connections between phrases and sentences.","sample":false,"doi":"10.1007/s41109-025-00699-7","short":"similarity-network-analysis","released":"July 23rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Text Similarity Calculations","carousels":["Natural Language Processing","Large Language Models","Encodings"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"using-similarity-network-analysis-to-improve-text-similarity-calculations"},{"title":"Uncovering causal graphs in air traffic control communication logs for explainable root cause analysis","description":"In this paper, \"communication logs\" aren’t a chat history, or a text thread. That term refers specifically to machine-generated records that capture the state and behavior of individual software components within the overall ATC (air traffic control) system. These messages do not cover the verbal exchanges between human air traffic controllers and pilots. These logs are emitted by distributed servers that perform functions like radar tracking, flight plan processing, weather data integration, or inter-sector coordination. Each log entry typically records a timestamp, a subsystem identifier, and a status indicator such as “ERROR,” “FAIL,” “STOPPED,” or “DISCONNECTED.” These logs do not contain high-level operational messages like \"Aircraft X cleared for takeoff\" or really anything human readable. But, they’re also not general-purpose system logs like the type you’d see on a webserver. They are very specific. They’re focused on reporting the internal state transitions of individual components and the events that affect them. So you can expect to see a log when a subsystem goes offline, when it fails to receive a message, or when it enters a degraded mode. And importantly: these logs reflect when and how components react, not necessarily interact.","sample":false,"doi":"10.1080/00051144.2025.2518794","short":"air-traffic-control-logs","released":"July 22nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"ATC Root Cause Analysis","carousels":["Transportation","Graphs","Data Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"uncovering-causal-graphs-in-air-traffic-control-communication-logs-for-explainable-root-cause-analysis"},{"title":"A Rule-Based Method for Enhancing Burst Tolerance in Stateful Microservices","description":"Stateful microservices hold onto session-related data. So ensuring consistent performance means more intensive and fine-grained resource management. When subjected to bursts, they must continue to process incoming requests, manage data caching, and maintain user session integrity. A failure anywhere in this chain can lead to performance bottlenecks, increased latency, and ultimately, a failure to meet service-level objectives (SLOs). So how do people normally handle this? Well, a common approach is simply to overprovision your resources. Spin up more than you need now, and ideally more than you’d need even in a reasonable burst. By having additional resources on standby, you’re raising the likelihood that you’ll be able to handle peak loads when they come. Now obviously, this approach has its costs. Maintaining idle resources impacts operating expenses and increases the carbon footprint of your system. And that’s even the case when the system is underutilized. Having it sit idle doesn’t mean it isn’t burning through power and racking up the charges.","sample":false,"doi":"10.3390/electronics14142752","short":"microservices-burst-tolerance","released":"July 21st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Microservice Burst Tolerance","carousels":["Microservices","System Architecture","Scaling","System Design"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-rule-based-method-for-enhancing-burst-tolerance-in-stateful-microservices"},{"title":"Optimization Algorithms for Cable Fault Localization and Assessment in Smart Power Systems","description":"The authors are focused on localizing faults in power cables, detecting them, and assessing their type and severity. They begin with frequency-domain reflectometry (FDR), a tool for identifying impedance anomalies. But FDR on its own can struggle with subtle defects or signal attenuation over long distances. So they propose a new algorithm that combines soliton-based modulation, attenuation compensation, and a Chebyshev window filter to enhance spatial resolution and polarity recognition. The result is a fault localization system that can not just spot where something went wrong, but how badly. A critical step towards grid reliability. On today’s episode we’re going to walk through their process and their findings. Let’s jump in. Detecting cable faults is harder than it sounds. High-voltage cables often have low-impedance pathways, which complicate the early detection. Traditional techniques like Time Domain Reflectometry (TDR) detect faults based on the reflection of signals from impedance mismatches. But, they fall short when trying to identify fault types beyond open circuits, short circuits, and faults with low impedance changes.","sample":false,"doi":"10.1109/ACCESS.2025.3586719","short":"cable-fault-localization","released":"July 20th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Cable Fault Localization","carousels":["Algorithms","Smart Grids"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"optimization-algorithms-for-cable-fault-localization-and-assessment-in-smart-power-systems"},{"title":"LS-YOLO: A lightweight, real-time YOLO-based target detection algorithm for autonomous driving under adverse environmental conditions","description":"Since its debut in 2015, the YOLO (You Only Look Once) family of algorithms has taken over the field of computer vision. And for good reason. When they first came out, the underlying idea was revolutionary: by framing detection as a single-pass regression problem, YOLO was able to achieve both speed and accuracy. And it did this in an accessible package. YOLO didn’t require a custom pipeline, you didn’t have to stitch together region proposals, or perform complex post-processing, or even have access to a massive compute cluster to use it. You could build a model, add some labeled images to fine-tune it, and be up and running with a decent detector fairly quickly.","sample":false,"doi":"10.1109/ACCESS.2025.3586599","short":"ls-yolo","released":"July 19th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"LS-YOLO for Autonomous Driving","carousels":["Autonomous Driving","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"ls-yolo-a-lightweight-real-time-yolo-based-target-detection-algorithm-for-autonomous-driving-under-adverse-environmental-conditions"},{"title":"Optimal performance design of bat algorithm: An adaptive multi-stage structure","description":"The core of the issue is in how BA balances exploration and exploitation. In its default form, the algorithm transitions too quickly into exploitation, favoring the refinement of existing candidate solutions rather than continued exploration of new regions. This causes it to settle into suboptimal solutions, with little capacity to recover. The loudness and pulse rate mechanisms, which are intended to regulate this balance, often prove too coarse or rigid to adapt dynamically to the needs of the search process. As a result, while BA may initially approach a promising solution quickly, its performance plateaus and deteriorates as diversity within the population collapses. Attempts to improve this behavior, such as by adjusting inertia or embedding mutation strategies, have seen incremental success, but no single mechanism has fully resolved the issue.","sample":false,"doi":"10.1049/cit2.12377","short":"optimal-bat-algorithm","released":"July 18th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Multi-Stage Bat Algorithm","carousels":["Algorithms","Optimization"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"optimal-performance-design-of-bat-algorithm-an-adaptive-multi-stage-structure"},{"title":"Aspen Open Jets: unlocking LHC data for foundation models in particle physics","description":"What makes FTL distinctive is how it leverages transfer learning. The encoder is first trained on large volumes of synthetic data generated by high-fidelity simulations, such as those produced by something called the GTC (the Gyrokinetic Toroidal Code). After this initial pretraining phase, the decoder is selectively fine-tuned using a smaller, more targeted set of real or nonlinear simulation data that includes temporally correlated plasma dynamics. This bifurcated strategy enables FTL to learn general spatial features broadly, while still adapting to specific nonlinear behaviors relevant to real-world instability prediction. The system’s design reflects a balance between generalization and specificity. During pretraining, the encoder learns to identify and encode the underlying geometry and spatial mode structures present across a wide range of plasma states. These are treated as \"static snapshots\", meaning they don’t contain time-sequenced information but represent individual frames of possible plasma configurations.","sample":false,"doi":"10.1088/2632-2153/ade58f","short":"physics-foundation-models","released":"July 17th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Foundation Model for Physics","carousels":["Physics","Autoencoders","Transfer Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"aspen-open-jets-unlocking-lhc-data-for-foundation-models-in-particle-physics"},{"title":"Lightweight ECG signal classification via linear law-based feature extraction","description":"The word electrocardiogram literally means “electric heart drawing.” It comes from the Greek roots electro- (referring to electricity), cardio- (heart), and -gram (a written or recorded trace). The term captures exactly what Einthoven achieved: a visible recording of the heart’s electrical signals, drawn in real time as they pulse through the body. More than a century later, the ECG (or EKG as it’s sometimes abbreviated) is one of the most widely used diagnostic tools in medicine. And the machine looks a lot different now. It has shrunk from taking up most of a room, to fitting on a chip inside a smartwatch. Advances in electronics, signal processing, and machine learning have also transformed how we collect, interpret, and act on ECG data. These days we have real-time monitoring and early detection of heart conditions on a global scale. But challenges remain. Many of the algorithms that process this data still depend on giant labeled datasets, lots of compute, or opaque decision-making processes. These are barriers that limit their deployment in low-resource settings or critical-care scenarios. ","sample":false,"doi":"10.1088/2632-2153/ade6c3","short":"lightweight-ecg-classification","released":"July 16th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Linear Law Feature Extraction","carousels":["Model Training","Feature Extraction"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"lightweight-ecg-signal-classification-via-linear-law-based-feature-extraction"},{"title":"Empirical Analysis of Data Sampling-Based Decision Forest Classifiers for Software Defect Prediction","description":"Traditional SDP models face three main types of challenges that limit their effectiveness in the real-world: class imbalance, poor generalization, and scalability. Class imbalance arises because defective modules typically represent a small fraction of the overall codebase, leading models to be biased toward the majority (non-defective) class. Generalization is an issue because models trained on specific projects or releases often fail to perform well when applied to new datasets. This can be due to overfitting or inadequate feature representation. Scalability is a concern because many machine learning algorithms degrade in performance or become computationally expensive when confronted with large, high-dimensional metric datasets. In this paper, the authors propose a solution that addresses all three of these concerns. They've built a decision forest-based ensemble framework that integrates cost-sensitive learning, attribute penalization, and functional modeling. It addresses class imbalance by combining SMOTE with cost-sensitive classifiers. It fixes generalization issues by using homogeneous ensemble techniques. And it improves scalability with lightweight decision tree variants that can be parallelized and tuned efficiently across large datasets. On today’s episode, we’re going to walk through how their system works: from the core decision forest models (CS-Forest, FPA, and Functional Trees), to the ensemble methods that amplify them, to the preprocessing techniques like SMOTE that make them robust to imbalance. Let’s jump in.","sample":false,"doi":"10.3390/software4020007","short":"software-defect-prediction","released":"July 15th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Software Defect Prediction","carousels":["Continuous Integration","Quality Assurance"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"empirical-analysis-of-data-sampling-based-decision-forest-classifiers-for-software-defect-prediction"},{"title":"Encrypted Search Method for Cloud Computing Data Under Attack Based on TF-IDF and Apriori Algorithm","description":"The authors propose a hybrid encrypted search framework that combines an improved TF-IDF weighting scheme with semantic keyword expansion using the Apriori algorithm. They introduce two methods, MKSE and SEMSS, that not only preserve data confidentiality in the cloud but also enable ranked, multi-keyword search with high recall and efficient performance. On today’s episode, we’ll walk through the core architecture of these methods, examine how they obscure keyword indices to resist attacks, and explore how semantic expansion boosts search completeness, without ever decrypting the data.","sample":false,"doi":"10.1080/08839514.2024.2449303","short":"encrypted-search-tfidf","released":"July 14th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Encrypted Search","carousels":["Encryption","Search","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"encrypted-search-method-for-cloud-computing-data-under-attack-based-on-tf-idf-and-apriori-algorithm"},{"title":"Genome editing for sustainable agriculture in Peru: advances, potential applications and regulation","description":"The power of CRISPR lies in what happens next. The cell responds to the break by activating one of two natural DNA repair pathways: non-homologous end joining (NHEJ) or homology-directed repair (HDR). NHEJ is error-prone and often results in small insertions or deletions, which can knock out a gene by disrupting its reading frame. HDR, on the other hand, uses a repair template to precisely modify the DNA sequence, enabling the introduction of specific mutations or corrections. In agricultural applications, this allows scientists to disable susceptibility genes, enhance stress tolerance, modify metabolic pathways, or improve nutritional content, without inserting foreign DNA. This is what sets CRISPR apart from traditional GMOs. Transgenic approaches typically involve inserting an entire gene (often from a different species) into the host genome, and this insertion is usually random. By contrast, CRISPR targets specific sites, enabling precise control over both the location and nature of the genetic change. CRISPR edits can be achieved using transgene-free methods. Instead of integrating editing machinery into the genome, researchers can introduce ribonucleoprotein (RNP) complexes directly into plant cells. These RNPs perform the edit and then degrade, leaving no foreign genetic material behind.","sample":false,"doi":"10.3389/fgeed.2025.1611040","short":"peru-genome-editing","released":"July 13th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"CRISPR in Peruvian Agriculture","carousels":["Agriculture","Genetics","Genomics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"genome-editing-for-sustainable-agriculture-in-peru-advances-potential-applications-and-regulation"},{"title":"Multistable Physical Neural Networks","description":"PNNs offer a radical alternative. By embedding computation directly into matter, using physical elements like fluid chambers, resistive networks, or mechanical springs, they collapse the boundary between memory and logic, between device and algorithm. The system doesn’t simulate learning. It learns by physically changing its structure, by flowing differently, by settling into one of many stable configurations. And that makes them uniquely suited for edge environments where power is limited, latency must be minimal, and robustness isn’t optional. These are arenas like soft robotics, medical implants, or adaptive materials. In those domains, a PNN isn’t just a novel idea…it might be the only practical path forward. In this paper, the authors dive into the mechanics and potential of PNNs. And on today’s episode we’re going to go along for the ride. We'll talk about how these networks are built, how they store memory, how they’re trained to perform tasks, and how they physically compute. We'll see how bistability enables information retention and how flow dynamics guide the system into stable states. And lastly we'll talk about the future, where this technology might be going, what's on the distant horizon, and what's actually already here.","sample":false,"doi":"10.1002/aisy.202400694","short":"physical-neural-networks","released":"July 12th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Multistable Physical Neural Networks","carousels":["Artificial Neural Networks","Hardware"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multistable-physical-neural-networks"},{"title":"An enhanced Walrus Optimizer with opposition-based learning and mutation strategy for data clustering","description":"The Improved Walrus Optimizer (IWO) upgrades the original in two ways. First, it introduces opposition-based learning (OBL), a strategy that doesn’t just rely on random guesses but actively evaluates “mirror” solutions on the other side of the search space. By comparing a candidate solution with its opposite, the algorithm can discover promising regions that would have otherwise been ignored, accelerating convergence without sacrificing diversity. Second, it adds a mutation search strategy (MSS), which introduces targeted, controlled random changes to existing candidates. This helps prevent the population from clustering too quickly around suboptimal solutions and maintains exploration pressure throughout the run.","sample":false,"doi":"10.1016/j.array.2025.100409","short":"walrus-optimizer","released":"July 11th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Enhanced Walrus Optimizer ","carousels":["Algorithms","Optimization"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-enhanced-walrus-optimizer-with-opposition-based-learning-and-mutation-strategy-for-data-clustering"},{"title":"Improving the Fast Fourier Transform for Space and Edge Computing Applications with an Efficient In-Place Method","description":"In 1807, Joseph Fourier, a little known mathematician, submitted a manuscript to the French Academy. In it, he proposed that any complex temperature distribution, no matter how jagged or irregular, could be expressed as a sum of simple sine and cosine waves. His colleagues were skeptical, to say the least. The idea that discontinuous or arbitrary functions could be represented using infinite trigonometric series was controversial, even radical. Lagrange and Laplace, two towering figures of the time, were certainly unconvinced. But Fourier persisted, and in 1822, his ideas were published as The Analytical Theory of Heat. That book became the foundation of what we now call Fourier analysis.","sample":false,"doi":"10.3390/software4020011","short":"improving-fft","released":"July 10th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Improving the Fast Fourier Transform","carousels":["Algorithms","Edge Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"improving-the-fast-fourier-transform-for-space-and-edge-computing-applications-with-an-efficient-in-place-method"},{"title":"Implementation of a Biologically Inspired Responsive Joint Attention System for a Social Robot","description":"You’ve undoubtedly heard of “self-attention”, the ability for a model to weigh and relate different parts of its own input sequence to one another. It’s the thing transformers (and therefore large language models) are so good at. Joint attention by contrast is the ability for two agents to coordinate their focus on a shared object or event. It’s a social-cognitive skill rather than a computational one, rooted not in internal alignment, but in shared external reference. Where self-attention is introspective, (examining internal relationships within a single stream of data), joint attention is interactive, requiring alignment between two different streams: the attentional state of one individual and the signals of another. In self-attention, a model learns to ask: \"Which parts of this sentence help me understand this word?\" In joint attention, a robot asks: \"Where is this person looking? What are they pointing at? What should I focus on to stay aligned with them?\" One is about internal coherence; the other is about social coherence.","sample":false,"doi":"10.1002/aisy.202400650","short":"joint-attention-system","released":"July 9th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Joint Attention System","carousels":["Robotics","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"implementation-of-a-biologically-inspired-responsive-joint-attention-system-for-a-social-robot"},{"title":"Fairness in Federated Learning: Trends, Challenges, and Opportunities","description":"Federated learning is a paradigm shift. Let’s say you have a handful of institutions, and they each have data. They need to keep their data separate, and secret. But, they, collectively, would love to use a model that was trained on all of their data at once. But they can’t move their data to any central location to train such a model, that would violate their silo-requirements. With Federated learning, instead of moving data to the model, you move the model to the data. Each institution does just a piece of the work. It trains the model locally on its own private dataset, and only shares the model updates with the rest of the group, never the raw data. These updates are then aggregated into a global model, allowing collaboration without sacrificing privacy. Decentralization at its finest.","sample":false,"doi":"10.1002/aisy.202400836","short":"federated-learning-fairness","released":"July 8th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fairness in Federated Learning","carousels":["Model Training","Federated Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fairness-in-federated-learning-trends-challenges-and-opportunities"},{"title":"Development of a cost-effective high-throughput mid-density 5K genotyping assay for germplasm characterization and breeding in groundnut","description":"Genomic tools enable plant breeders to select for desirable traits with a level of speed and precision that isn’t possible with traditional selective breeding programs. In the case of the peanut, conventional breeding approaches have historically struggled with low selection efficiency, long generation cycles, and phenotypic ambiguity. The advent of high-throughput genotyping platforms has changed that. By leveraging genome-wide molecular markers, breeders can now track the inheritance of specific alleles, assess genetic diversity, and make data-driven decisions at early stages of selection, even before phenotypes are visible.","sample":false,"doi":"10.1002/tpg2.70019","short":"germplasm-genotyping","released":"July 7th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Peanut Genotyping","carousels":["Genetics","Agriculture"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"development-of-a-cost-effective-high-throughput-mid-density-5k-genotyping-assay-for-germplasm-characterization-and-breeding-in-groundnut"},{"title":"An Unsupervised Fake News Detection Framework Based on Structural Contrastive Learning","description":"Architecturally, this system is a twin-network setup. It's inspired by bootstrap-based self-supervised learning methods like BYOL. These are training frameworks that learn useful representations without labels by encouraging two differently augmented views of the same input to produce similar outputs. They work by using a slowly updated target network to provide stable training targets for an online network that is optimized directly. The author's system is similar in the way that it uses two networks with shared architecture but different update schedules and trains one to match the other across augmented views of the same data.","sample":false,"doi":"10.1186/s42400-024-00342-5","short":"fake-news-contrastive-learning","released":"July 6th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Structural Contrastive Learning","carousels":["Media","Communications","News","Deep Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-unsupervised-fake-news-detection-framework-based-on-structural-contrastive-learning"},{"title":"Dataset Dependency in CNN-Based Copy-Move Forgery Detection: A Multi-Dataset Comparative Analysis","description":"Block-matching works by dividing the image into overlapping blocks or segments, typically of a fixed size, and scanning for duplicated blocks across the image. The similarity between blocks is measured using the sum of squared differences (SSD) or normalized cross-correlation (NCC). For this technique, the chosen block size is everything. Large blocks might overlook small duplications, while smaller blocks can become computationally expensive and may lead to higher false-positive rates due to image noise or slight variations. Block-matching works a lot of the time, but it struggles with forgeries that involve complex transformations like scaling, rotation, or distortion, as these transformations disrupt the block uniformity that this technique relies upon.","sample":false,"doi":"10.3390/make7020054","short":"copy-move-forgery","released":"July 5th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Copy-Move Forgery","carousels":["Security","Generative AI","Convolutional Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"dataset-dependency-in-cnn-based-copy-move-forgery-detection-a-multi-dataset-comparative-analysis"},{"title":"FPGA-accelerated SpeckleNN with SNL for real-time X-ray single-particle imaging","description":"FPGAs (field-programmable gate arrays) are hardware devices that can be reconfigured at the logic level. Unlike CPUs, which follow a fixed instruction set, or GPUs, which execute many threads across fixed pipelines, an FPGA is essentially a blank slate. You define how data moves through it, what logic gates get activated, in what order, and at what clock rates. This means you can tailor it precisely to the needs of your algorithm: no extra baggage, no general-purpose overhead. And because you’re operating at the circuit level, you can squeeze out latency and power savings that conventional processors simply can’t match.","sample":false,"doi":"10.3389/fhpcp.2025.1520151","short":"fpga-accelerated-speckle","released":"July 4th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"FPGA Accelerated SpeckleNN","carousels":["Physics","Particle Physics","FPGAs"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fpga-accelerated-specklenn-with-snl-for-real-time-x-ray-single-particle-imaging"},{"title":"Innovative Approaches to the Use of Artillery in Wildfire Suppression","description":"Their idea was straightforward: when a bomb detonates, the explosion rapidly displaces and consumes the surrounding oxygen. This starves the target fire of the oxygen it needs, and extinguishes it. The area they tried it on just happened to be an old firing range, so they thought this was a perfect opportunity to try this out. It’s an area that was made to be blown up anyway, so why not? It was an interesting theory…and, surprisingly, it worked.","sample":false,"doi":"10.3390/fire8060232","short":"fire-artillery","released":"July 3rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Artillery in Wildfire Suppression","carousels":["Wildfire","Firefighting","Military"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"innovative-approaches-to-the-use-of-artillery-in-wildfire-suppression"},{"title":"An efficient video slice encryption scheme and its application","description":"Since I-frames are self-contained, they’re ideal points to begin new slices. In the authors’ system, each slice starts at an I-frame and includes the frames that depend on it (typically a group of P and B-frames) up until the next I-frame. This makes the slice both playable and logically independent from the rest of the video. Once the slicing is done, each segment is encrypted individually using a different key. To ensure every slice gets its own unique key, the system uses a process, based on slice metadata (information that describes each slice), such as its location in the video, its version number, and a hash value of its contents. This ensures that even if two slices are similar, they will still be encrypted differently (because the keys are different). The metadata for each slice also includes information needed to put the video back together in the correct order. That being said, the metadata is not actually stored openly, it’s encrypted and protected just like the slices.","sample":false,"doi":"10.1186/s42400-024-00334-5","short":"video-slice-encryption","released":"July 2nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Video Slice Encryption","carousels":["Multimedia","Video Streaming","Encryption","Security"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-efficient-video-slice-encryption-scheme-and-its-application"},{"title":"Service function tree mapping of microservices on resource-constrained fog networks","description":"But, processing all that data, and doing it in near-real time, takes not just physical sensor infrastructure, but fog computing nodes deployed at the edge, and a microservice-based architecture mapped optimally to the physical resources. And that’s what this paper is about. In it, the authors propose a mixed-integer linear programming (MILP) approach to optimally map Service Function Tree based microservices onto fog networks in construction settings, enabling latency-aware, resource-constrained, and sensor-proximity-sensitive event detection during operations like concrete pouring. This is what modern construction looks like. Yes, it’s still hardhats and toolbelts of course. But it's also algorithms and data lakes. Models and statistics. This paper pulls back the veil of what some of the most technology-forward construction companies are putting in place, and how they’re reducing waste and optimizing their processes.","sample":false,"doi":"10.1186/s13677-025-00750-z","short":"service-function-tree","released":"July 1st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Service Function Tree Mapping","carousels":["Microservices","IoT","Internet of Things","IIoT","Edge Computing","Fog Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"service-function-tree-mapping-of-microservices-on-resource-constrained-fog-networks"},{"title":"HIPR: Hardware IP Protection through Low-Overhead Fine-Grain Redaction","description":"You see, if you’re in the semiconductor industry, you more than likely have a global supply chain. Sure, your designs are perfected over here, but only with help from consultants who are from somewhere else. And the fabrication happens in a third place, using machines from fourth place…and the packaging happens in a fifth place…then of course the testing and assembly happen somewhere else entirely. So no: locking down your IP doesn’t mean just giving your team Yubikeys and calling it a day. Your intellectual property is passing through dozens of hands, and being seen by hundreds of eyes. Chips are complex, and a successful product launch is partially the result of the work of thousands of people who you’ll never meet and have no access to.","sample":false,"doi":"10.46586/tches.v2025.i3.781-805","short":"hardware-ip-protection","released":"June 30th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Hardware IP Protection","carousels":["Manufacturing","Computer Chips","Computing Hardware"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"hipr-hardware-ip-protection-through-low-overhead-fine-grain-redaction"},{"title":"A SWIN-based vision transformer for high-fidelity and high-speed imaging experiments at light sources","description":"This dilemma is often called the \"spatio-temporal contradiction.\" Essentially, achieving very high temporal resolution (that is: capturing events at incredibly fast time scales) often comes at the expense of spatial resolution, meaning that the images produced may be blurry or lack sufficient detail to be truly useful. Conversely, focusing on high spatial resolution, tends to reduce the temporal resolution, leading to an under-sampling of fast-changing events. This is not just a superficial dilemma, but a fundamental limitation imposed by the current detector and imaging technologies.","sample":false,"doi":"10.3389/fhpcp.2025.1537080","short":"swin-vision-transformer","released":"June 29th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"SWIN Vision Transformer","carousels":["Computer Vision","Transformers"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-swin-based-vision-transformer-for-high-fidelity-and-high-speed-imaging-experiments-at-light-sources"},{"title":"Human joint motion data capture and fusion based on wearable sensors","description":"That’s why people keep trying to make wearable sensors work. Inertial Measurement Units, or IMUs, are cheap, lightweight, and unobtrusive. A Micro-Electro-Mechanical (MEMS) based sensor that combines a gyroscope, accelerometer, and magnetometer costs just a few bucks. Stick one to each limb, and in theory, you can reconstruct the body’s posture in 3D. No cameras. No markers. Just raw sensor data fused together to generate joint angles and segment orientations. It’s the ideal solution for remote monitoring and real-time tracking…that is…if you can make the data reliable.","sample":false,"doi":"10.1007/s43684-025-00098-w","short":"human-joint-motion","released":"June 28th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Join Motion Capture","carousels":["Computer Vision","Wearables","Motion Capture"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"human-joint-motion-data-capture-and-fusion-based-on-wearable-sensors"},{"title":"An information theoretic limit to data amplification","description":"In the early 2000s, as the Large Hadron Collider was being planned and built, one of the biggest engineering bottlenecks wasn’t constructing the accelerator, it was simulating what would happen when it turned on. Reportedly, full Monte Carlo simulations of the particle collisions were so computationally expensive that they consumed half the available CPU time at the facility. And that was before the real data even started flowing. Since then, the physics community has turned to generative models, especially GANs, to produce synthetic events instead. Unlike Monte Carlo methods, which simulate every physical interaction from first principles, a trained GAN can skip the physics and sample directly from the learned distribution, generating events in milliseconds instead of minutes. But that kind of use-case raises a question: how many synthetic events can you generate before the outputs stop being faithful to the original distribution? This generation of synthetic samples beyond the original training set (the act of producing more data than you started with) is called amplification. So the underlying question is: Can you really amplify a dataset by a factor of 100 without compromising its integrity? Is there any limit to amplification or can it be done forever?","sample":false,"doi":"10.1088/2632-2153/add78d","short":"data-amplification-limit","released":"June 27th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Data Amplification","carousels":["Model Training","Information Theory"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-information-theoretic-limit-to-data-amplification"},{"title":"Radiographic prediction model based on X-rays predicting anterior cruciate ligament function in patients with knee osteoarthritis","description":"The ACL is often treated as a binary variable in surgical planning: either intact or torn. But in patients with end-stage knee osteoarthritis, that distinction isn't enough. What actually matters is whether the ligament is functionally competent. That is, can it still stabilize the tibia under load. And that’s not something most imaging tools are built to answer. MRI can show gross morphological changes, but its signal is confounded by degenerative remodeling, fluid artifacts, and partial volume effects. It can report a ligament as \"torn\" when it's merely degenerated, or as \"intact\" when it’s functionally lax. In other words, MRI is sensitive to structure, but not to performance. That matters because treatment decisions hinge on functional status. The clinical pathway diverges depending on whether the ACL is still doing its job. In particular, surgeons deciding between UKA and TKA need to know if the ACL is viable. UKA preserves both cruciate ligaments and requires an intact kinematic chain. If the ACL is compromised, UKA is contraindicated. In those cases, TKA is the default. Getting this wrong leads to failed implants, revisions, and poor outcomes.","sample":false,"doi":"10.1186/s42492-025-00195-w","short":"radiographic-prediction","released":"June 26th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Predicting ACL Function","carousels":["Physical Therapy","Medicine","Arthritis"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"radiographic-prediction-model-based-on-x-rays-predicting-anterior-cruciate-ligament-function-in-patients-with-knee-osteoarthritis"},{"title":"Photograph-based machine learning approach for automated detection and differentiation of aerial blight disease in soybean crops","description":"The labels (for each category) were assigned manually. But to be clear, this is weakly labeled data with class boundaries that are inherently fuzzy. Some conditions, like insect damage versus early-stage Rhizoctonia, share a lot of features. Others, like the multi-disease class, are purposefully ambiguous. And that ambiguity carries through to training, so any model working on this dataset will have to deal with imprecision not just in the image quality, but in the ground truth itself. The dataset also reflects a natural class imbalance. Rhizoctonia is the dominant disease in the region and appears more frequently in the data than the others. Rarer classes like bacterial pustules and viral diseases have fewer examples. This imbalance is not corrected with oversampling or synthetic expansion at this stage. It is left intact during collection to reflect realistic deployment distributions.","sample":false,"doi":"10.1186/s40537-025-01191-w","short":"aerial-soybean-blight","released":"June 25th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Aerial Blight Disease","carousels":["Agriculture","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"photograph-based-machine-learning-approach-for-automated-detection-and-differentiation-of-aerial-blight-disease-in-soybean-crops"},{"title":"A Finger Vein Recognition Model Based on Kolmogorov-Arnold Networks","description":"From a modeling perspective, finger vein recognition is tough. The signal is buried in noise. The lighting conditions vary. The infrared images can be blurry or off-angle. Traditional approaches relied on handcrafted features (HOGs, LBPs, Gabor filters). Then deep learning arrived, and convolutional architectures became the new default. CNNs like InceptionV3 and EfficientNet now dominate this space. They work reasonably well, but they're also limited in an important way: they assume a fixed functional structure. Each layer uses a predefined activation function, and the weights are learned in that fixed context. That’s fine for many tasks. But if the structure of the input data is highly nonlinear, or if small perturbations in the input space translate into large, non-uniform shifts in the output, those assumptions start to break down.","sample":false,"doi":"10.2478/acss-2025-0008","short":"finger-vein-recognition","released":"June 24th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Finger Vein Recognition","carousels":["Medicine","Computer Vision","Cardiovascular Disease"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-finger-vein-recognition-model-based-on-kolmogorov-arnold-networks"},{"title":"Scoop: An Optimization Algorithm for Profiling Attacks against Higher-Order Masking","description":"The authors of this paper argue that the plateau isn’t just an incidental nuisance. It’s a structural weakness in the optimization process. Standard methods like SGD and Adam aren’t built for the geometry of this problem. So the authors introduce something called Scoop, a new optimizer tailored specifically for this attack setting. On today’s episode, we’ll start by unpacking the plateau effect a bit more, and explore why it gets worse as masking order increases. Then we’ll walk through the core design of Scoop, including its use of second-order curvature, sparse mirror descent, and a new variant of the Hutchinson estimator. Let’s dive in.","sample":false,"doi":"10.46586/tches.v2025.i3.56-80","short":"scoop-algorithm","released":"June 23rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Scoop Optimization Algorithm","carousels":["Algorithms","Security"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"scoop-an-optimization-algorithm-for-profiling-attacks-against-higher-order-masking"},{"title":"Tag Replication and Status Bits Encoding for Enhancing Cache Metadata Reliability","description":"Let’s talk about how a typical CPU cache works. When a processor accesses memory, it doesn’t go straight to DRAM, it first checks the on-chip caches. They are built from fast SRAM and hold recently used data. L1 (Level 1) caches are the smallest and fastest, sitting closest to the execution pipeline. L2 and L3 caches are larger but slower, buffering accesses further away from the core. Each cache is divided into lines, and each line holds a block of memory along with a small set of control information. That control information is what enables the cache to decide whether it contains the data being requested and whether that data is still valid. It’s also what ensures that modified data eventually makes its way back to main memory. Without it, the cache is just a fast but blind scratchpad.","sample":false,"doi":"10.1155/jece/5008986","short":"status-bits-encoding","released":"June 22nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Status Bits Encoding","carousels":["Computing Hardware","Caching"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"tag-replication-and-status-bits-encoding-for-enhancing-cache-metadata-reliability"},{"title":"Multifeature Fusion for Enhanced Content-Based Image Retrieval Across Diverse Data Types","description":"If you’ve ever uploaded an image to a search-engine to look for similar images, that’s called CBIR: content-based image retrieval. It’s a broad term for anytime you’re taking a piece of media, and using it as the query to find other pieces of media. CBIR…is, well…harder than it might look. Despite decades of published benchmarks, modern CBIR systems still tend to underperform when they’re deployed in scenarios that deviate even slightly from lab conditions. If the lighting changes, if the image has mild occlusion, if the query sample is compressed or low resolution, or if the database contains too many near-duplicates, retrieval precision often collapses. Worse, even when a system performs well on average, the outliers can still be unpredictable and costly. Take for example medical diagnostics or legal forensics where the wrong retrieval result can lead to serious issues. Again these systems are easy to demo in a lab, but hard to trust in the wild.","sample":false,"doi":"10.1155/jece/3889925","short":"enhanced-image-retrieval","released":"June 21st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Content-Based Image Retrieval","carousels":["Search","Similarity Search","Datastores"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multifeature-fusion-for-enhanced-content-based-image-retrieval-across-diverse-data-types"},{"title":"A Graph Representation Learning-Based Method for Event Prediction","description":"That’s what event prediction really is. It’s not just a downstream classification task, or a fancy variant of time series forecasting. It’s a structural problem. Events don’t exist in isolation. They influence each other, build on each other, and often unfold according to implicit rules or scripts. Modeling that structure requires more than just feeding sequences into a transformer or training a Markov model on co-occurrence counts. You need a representation that captures both semantics and connectivity. You need to model what an event means, and also how it fits into the broader lifecycle of the system it's embedded in.","sample":false,"doi":"10.1049/ise2/9706647","short":"graph-event-prediction","released":"June 20th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Graph Representation Learning","carousels":["Graphs","Time Series Forecasting"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-graph-representation-learning-based-method-for-event-prediction"},{"title":"An Approach using Skeleton-based Representations and Neural Networks for Yoga Pose Recognition","description":"Their pipeline begins with a clear decision: strip away everything that doesn’t help the model reason about human pose. That means discarding RGB pixel information and focusing solely on skeletal keypoints. To do that, the authors rely on MoveNet, a real-time pose estimation model developed by Google Research. It detects 17 anatomical landmarks per frame, each consisting of x and y coordinates, along with a confidence score. These keypoints correspond to major joints like the wrists, elbows, shoulders, hips, knees, and ankles.","sample":false,"doi":"10.2478/acss-2025-0009","short":"yoga-pose-recognition","released":"June 19th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Yoga Pose Prediction","carousels":["Computer Vision","Sports","Yoga"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-approach-using-skeleton-based-representations-and-neural-networks-for-yoga-pose-recognition"},{"title":"Explainable autoencoder for neutron star dense matter parameter estimation","description":"This is a well-known bottleneck in neutron star research. Gravitational wave events have opened up a new observational channel, but turning those observations into meaningful constraints on nuclear matter requires some way to navigate this problem. Traditional techniques approach this by sampling from parameterized equation-of-state families and running forward simulations, rejecting configurations that do not match observed data. That works, but it is slow, non-differentiable, and hard to scale. More recent approaches have turned to machine learning as a way to learn a fast, differentiable mapping between observables and microphysical parameters. But even there, most of the progress has been made with black-box models that offer little visibility into how their predictions are structured internally.","sample":false,"doi":"10.1088/2632-2153/add3bd","short":"neutron-star","released":"June 18th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Neutron Star Estimation","carousels":["Explainability","Astrophysics","Physics","Autoencoders"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"explainable-autoencoder-for-neutron-star-dense-matter-parameter-estimation"},{"title":"Predicting Software Perfection Through Advanced Models to Uncover and Prevent Defects","description":"Let’s say you’re getting ready to push a release to production. This update isn’t a total rewrite. But it does include a refactor of the app’s billing logic, a rework of how errors propagate through the streaming pipeline, and a couple hundred lines of test coverage. So far, your CI is green, your integration tests are passing, everything’s been through two rounds of code review, and all the stakeholders have signed off. But still, you’re terrified to push that release button. You know from experience, that no matter how careful you are, bugs still ship. It’s inevitable. So the real question is not whether you’ve tested your code, or whether someone else has reviewed your code. It’s whether your CI flow is giving you the right signals. Historically, you’ve leaned on coverage reports, cyclomatic complexity, and static analyzers. But none of those are in the prediction business.","sample":false,"doi":"10.1049/sfw2/8832164","short":"predicting-perfection","released":"June 17th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Predicting Software Perfection","carousels":["Testing","Continuous Integration","CI"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"predicting-software-perfection-through-advanced-models-to-uncover-and-prevent-defects"},{"title":"Optimal spectroscopic measurement design: Bayesian framework for rational data acquisition","description":"That man’s name was Thomas Bayes. The theorem is known as Bayes’ theorem, and the broader field is called Bayesian inference. Bayesian logic is now a mathematical framework for reasoning under uncertainty. It starts with an initial belief about the world, called a prior, and then updates that belief as new evidence comes in. The update follows a specific rule (Bayes’ theorem), which adjusts how plausible each possible explanation is based on how well it predicts the observed data. The result is a new belief, called a posterior, that reflects both your prior assumptions and the new information. This approach is useful when data is limited, noisy, or expensive to collect, because it lets you formally combine existing knowledge with fresh observations in a consistent way.","sample":false,"doi":"10.1088/2632-2153/add0f6","short":"spectroscopic-measurement","released":"June 16th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Bayesian Framework for Spectroscopes","carousels":["Data Science","Optimization","Physics","Light","Electromagnetic Spectrum"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"optimal-spectroscopic-measurement-design-bayesian-framework-for-rational-data-acquisition"},{"title":"Hive: A secure, scalable framework for distributed Ollama inference","description":"For the uninitiated: Ollama is a lightweight local runtime for large language models. It's used by developers and researchers to run open-source LLMs on their own machines without needing cloud infrastructure. It's particularly useful because it abstracts away the complexity of model loading, inference, and environment setup, giving you a simple API to interact with. In this paper, they’re building this system specifically for Ollama deployments. So now let’s dig into why that kind of thing is needed at all. Let’s say you’re a technical lead at a research center. You’ve got GPUs scattered across three or four locations: some in old lab machines behind university firewalls, some in newer workstations on a different LAN, and maybe a couple of cloud VMs running spot instances. You’ve standardized on Ollama as your runtime. For most teams, it’s an easy way to spin up models like LLaMA, Mistral, or Gemma without needing to wrangle Docker, Hugging Face weights, or low-level serving infrastructure. But as soon as you move beyond a single machine, the cracks start to show. You’ve got a number of different nodes, but can’t load-balance across them. You can’t target different models based on availability. You can’t scale a workload elastically. And unless you’re willing to hand out public IPs or maintain your own VPN mesh, there’s no safe or scalable way to unify all your Ollama instances into a single inference endpoint.","sample":false,"doi":"10.1016/j.softx.2025.102183","short":"distributed-ollama","released":"June 15th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Distributed Ollama","carousels":["Large Language Models","LLMs","NLP"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"hive-a-secure-scalable-framework-for-distributed-ollama-inference"},{"title":"Data-driven analysis of hysteresis and stability in perovskite solar cells using machine learning","description":"To evaluate performance of a PSC, or any other photovoltaic, you measure a device’s JV curve, which is short for current-density-versus-voltage. This curve is produced by sweeping an external voltage across the device and measuring the resulting current density under illumination. This gives you the short-circuit current, open-circuit voltage, fill factor, and ultimately, power conversion efficiency. In an ideal situation (on a perfect device), the JV curve is stable and consistent regardless of how you measure it. But that’s not the case with PSC. They exhibit a phenomenon called hysteresis, where the shape of the JV curve depends on the direction or speed of the voltage sweep you perform. So, if you measure the curve from the bottom to the top, that is: from 0 to the open-circuit voltage (this is called a “forward scan”), you’ll get one reading. If you then measure it again the opposite way, from the top to the bottom (this is called a “backward scan”) you’ll get a different reading. This mismatch is hysteresis.","sample":false,"doi":"10.1016/j.egyai.2025.100503","short":"perovskite-solar-cells","released":"June 14th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Perovskite Solar Cells","carousels":["Energy Science","Photovoltaics","Solar Power","Materials Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"data-driven-analysis-of-hysteresis-and-stability-in-perovskite-solar-cells-using-machine-learning"},{"title":"Self-conditioned diffusion with gradient manipulation for longitudinal MRI imputation","description":"Longitudinal MRI is different. Instead of one scan per patient, you get a sequence: multiple scans of the same patient collected over time. Typically months or years apart. This lets you observe anatomical progression: how brain structures evolve as a disease advances, or how they respond to treatment. It opens the door to predictive modeling tasks like estimating disease trajectory, identifying early signs of degeneration, or simulating treatment outcomes. But…it comes at a cost: longitudinal data is much harder to collect. It requires consistent follow-up protocols, patient retention, and longer time horizons.","sample":false,"doi":"10.1016/j.patter.2025.101212","short":"self-conditioned-diffusion","released":"June 13th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Self-Conditioned Diffusion","carousels":["Diffusion","Medicine","Generative AI","Model Training"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"self-conditioned-diffusion-with-gradient-manipulation-for-longitudinal-mri-imputation"},{"title":"Enhanced small-scale APT knowledge graph embedding via spatio-temporal attribute reasoning and adversarial negative sampling","description":"This is exactly the situation that knowledge graph embedding (KGE) was supposed to help with. Model your incidents as a graph, fill in the gaps with link prediction, and voila! You’ve got a framework for anticipatory defense. At least, that was the theory. In practice, it falls apart as soon as you point it at what we call: Advanced Persistent Threats, or APTs. APTs are long-running, coordinated cyberattacks typically carried out by state-actors, state-backed actors or just highly-resourced, highly-organized adversaries. These kinds of attacks move slowly, and methodically. They pivot across systems, and stay hidden for weeks or months. The techniques they use are subtle, the artifacts are inconsistent, and the available data around them is scarce. We don’t actually know very much about them because most of the data that exists is never shared publicly. KGE needs that data to make decisions.","sample":false,"doi":"10.1016/j.array.2025.100404","short":"apt-knowledgegraph","released":"June 12th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Knowledge Graph Embedding","carousels":["Temporal Analysis","Graphs"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"enhanced-small-scale-apt-knowledge-graph-embedding-via-spatio-temporal-attribute-reasoning-and-adversarial-negative-sampling"},{"title":"Application of Lightweight Target Detection Algorithm Based on YOLOv8 for Police Intelligent Moving Targets","description":"To make any of this possible, they need you to build the core processing components. A computer vision system that processes the live-feeds from the cameras in the room, detects the presence, motion, and actions of the officers, and sends triggers to the rest of the system to adjust the scenario on-demand. Here’s the hard part: your system can’t run in the cloud. It needs to run on-premise, ideally on whatever compute the department has available. Could be a laptop, could be a tablet, could be an old server in a closet. But it just needs to work regardless, and do it under latency constraints. Naturally, you turn to the YOLO family of models. V8 in particular seems like it promises a good trade-off: better accuracy, faster inference, and cleaner training behavior than its predecessors. But in practice, trying to embed YOLOv8 onto lower-powered devices or consumer-grade machines has some issues:","sample":false,"doi":"10.1049/cdt2/9984821","short":"yolov8-for-police","released":"June 11th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Target Detection Algorithm","carousels":["Computer Vision","Policing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"application-of-lightweight-target-detection-algorithm-based-on-yolov8-for-police-intelligent-moving-targets"},{"title":"Caloric restriction exacerbates renal post-ischemic injury and fibrosis by modulating mTORC1 signaling and autophagy","description":"Differentiated cells in the organs busily go about their jobs, silently regulated by complex molecular mechanisms called pathways. Pathways can be focused around specific biomolecules and how they act on other molecules to give cells instructions to do things like replicate, make proteins, or self destruct. For example, some biomolecules kick into action when the organ is stressed, and turn on mechanisms engaged in cellular repair, while others may stop, or turn off certain cellular functions before they get out of hand. One such function is autophagy, a cell’s breakdown and reabsorption of damaged components. If these mechanisms are compromised, then the tissue could face further damage like fibrosis and overactive autophagy. The authors were particularly interested in the mTORC1 pathway, which is centered around a complex molecule that controls cell growth functions and has a big impact on renal tubule repair and control of autophagy.","sample":false,"doi":"10.1016/j.redox.2025.103500","short":"mtorc1-signaling","released":"June 10th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Caloric Restriction and Renal Injury","carousels":["Medicine","Chronic Disease","Kidney Disease"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"caloric-restriction-exacerbates-renal-post-ischemic-injury-and-fibrosis-by-modulating-mtorc1-signaling-and-autophagy"},{"title":"Domain-informed CNN architectures for downscaling regional wind forecasts","description":"In weather forecasting, the foundation of the field is something called Numerical Weather Prediction, or NWP. NWP simulates the evolution of the atmosphere over time, using the laws of physics; that is: fluid dynamics, thermodynamics, and radiation models. It takes in the current state of the atmosphere from observations, then integrates the equations forward to produce future states. NWP is the global standard for everything from hurricane prediction to daily weather apps, and it’s only possible by way of massive supercomputers that crunch through billions of variables across global grids, all day long. But there’s a tradeoff inherent in these systems. The finer the spatial resolution, the more compute it takes to run. Because of this, global NWP models are typically limited to grid resolutions around 10 to 30 kilometers. That’s pretty coarse. You can’t resolve wind patterns around mountain ridges, or the land-sea gradients that matter in coastal areas. And you definitely can’t resolve wind flows at the scale of individual wind turbines. If you need to predict the unique weather that is only occurring around a specific set of turbines, you need another option.","sample":false,"doi":"10.1016/j.egyai.2025.100485","short":"regional-wind-forecasts","released":"June 9th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Regional Wind Forecasts","carousels":["Numerical Weather Prediction","Temporal Analysis","Climate Science","Convolutional Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"domain-informed-cnn-architectures-for-downscaling-regional-wind-forecasts"},{"title":"Intravenous vs. Oral Dose Comparison of Pain Relief Combinations - Enantiomers, Metabolite, Linearity: A Pharmacokinetics Randomized Clinical Trial","description":"All of these effects have a dose-dependent relationship. This means that these are more likely to occur the higher the dose is. This is why, if the pain persists, it is better to add a medication that acts on a different physiological pathway, rather than to keep increasing the dose of the one that you are on. Another bonus of combination pain management is that you can achieve the desired effect with lower-than-normal doses. But why take two different tablets when you can take one? There are plenty of fixed-dose combination (FDC) pain medications available. FDC means that the two medications are in the same tablet (or any other formulation) in a fixed ratio. This is also useful because, like I just said, you won’t always have to take the normal or full dose, so the FDC can contain lower doses of each medication and will therefore produce fewer side effects.","sample":false,"doi":"10.3390/ph18030331","short":"intravenous-vs-oral-dose","released":"June 8th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Pain Relief Combinations","carousels":["Medicine","Pharmacology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"intravenous-vs-oral-dose-comparison-of-pain-relief-combinations---enantiomers-metabolite-linearity-a-pharmacokinetics-randomized-clinical-trial"},{"title":"Multimodal scene recognition using semantic segmentation and deep learning integration","description":"This kind of situation isn’t just a fluke. It’s part of the challenge of autonomous navigation. RGB-only vision systems consistently underperform in real-world environments when that environment is poorly lit, occluded, or structurally ambiguous. Even strong models like ResNet, Vision Transformers, or CNN-LSTM hybrids have a key limitation: they lack spatial reasoning. Flat 2D image features don’t carry information about depth discontinuities or object proximity. The model can’t tell whether a shape is a shadow, an opening, or a missing wall. And no amount of data augmentation fixes that.","sample":false,"doi":"10.7717/peerj-cs.2858","short":"multimodal-scene-recognition","released":"June 7th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Multimodal Scene Recognition","carousels":["Deep Learning","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multimodal-scene-recognition-using-semantic-segmentation-and-deep-learning-integration"},{"title":"Emotion recognition with a Randomized CNN-multihead-attention hybrid model optimized by evolutionary intelligence algorithm","description":"This paper proposes a different route. Instead of trying to train ever-larger models, the authors decouple the front-end feature extractor from the rest of the learning system. They use a Randomized CNN (a model with fixed convolutional weights) to reduce training complexity and inference overhead. Then, they plug that into a transformer-based attention mechanism to recover lost accuracy through improved temporal reasoning. Finally, they tune the entire pipeline using a metaheuristic optimizer.","sample":false,"doi":"10.1016/j.array.2025.100401","short":"cnn-multihead-attention","released":"June 6th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Emotion Recognition","carousels":["Convolutional Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"emotion-recognition-with-a-randomized-cnn-multihead-attention-hybrid-model-optimized-by-evolutionary-intelligence-algorithm"},{"title":"Predicting the Trends of the Egyptian Stock Market Using Machine Learning and Deep Learning Methods","description":"In this paper, the authors attempt to see if any of the common machine-learning / deep-learning architectures are actually useful in a situation like this. They run a side-by-side comparison of Random Forest, KNN, AdaBoost, SVM, ANN, RNN, and LSTM. The point of this paper isn't to introduce a new model. It's to get a performance benchmark across methods, on a real-world dataset that hasn't already been saturated by research attention. On today’s episode we’ll see which models performed best, and why some of the expected winners fell a bit short. Let’s dive in.","sample":false,"doi":"10.21608/cjmss.2024.320645.1077","short":"egyptian-stocks","released":"June 5th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Egyptian Stock Market","carousels":["Temporal Analysis","Time Series Forecasting","Finance","Stock Market"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"predicting-the-trends-of-the-egyptian-stock-market-using-machine-learning-and-deep-learning-methods"},{"title":"Human-in-the-loop control strategy for IoT-based smart thermostats with Deep Reinforcement Learning","description":"Let’s talk about thermostats. Not the Nest-style things you see mounted on the wall in America. I mean real thermostats. Thermostatic radiator valves; TRVs. If you spend some time in Europe, and especially if you go to an office building while you’re there, that’s what you’re going to see. They are mechanical devices that look like a dial, and they control the flow of hot water into radiator tubes that are often mounted on a wall. In much of the world this has been the default heating solution for decades. In their basic form, TRVs are cheap, reliable, and independent.","sample":false,"doi":"10.1016/j.egyai.2025.100490","short":"smart-thermostats","released":"June 4th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"HITL Thermostats","carousels":["Alternative Energy","Human In the Loop","Energy Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"human-in-the-loop-control-strategy-for-iot-based-smart-thermostats-with-deep-reinforcement-learning"},{"title":"Enhancing the Nutritional Quality of Low-Grade Poultry Feed Ingredients Through Fermentation: A Review","description":"Cross disciplinary medical research has shown that chronic inflammation is on the rise, and one particular area of the body has been gaining attention. The gut. Gut inflammation has been linked with cardiovascular disease, cancer, diabetes, auto-immune disorders, and even mental health. As researchers explore the gut and its microenvironment to understand how these links work, they are also looking for ways to combat the persistence of inflammation. Fermentation and the probiotic effects of fermented foods have led to promising insights in both fighting inflammation and understanding the intricate molecular and chemical relationships that make the gut work. At the core of these relationships are a wide variety of microbes that are gaining increased attention for their roles in creating and maintaining healthy guts.","sample":false,"doi":"10.3390/agriculture15050476","short":"poultry-feed","released":"June 3rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fermentation of Poultry Feed","carousels":["Medicine","Gut Health","Microbiome","Agriculture"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"enhancing-the-nutritional-quality-of-low-grade-poultry-feed-ingredients-through-fermentation-a-review"},{"title":"Data imputation in large and small‐scale spatiotemporal time series gaps using BackForward Bi‐LSTM","description":"Most of the legacy approaches to trajectory imputation come from two camps: deterministic interpolators and deep learning-based predictors. The earliest techniques used curve fitting to estimate vessel positions between sparse observations. Hermite Cubic Spline interpolation was the first major method adopted by fisheries researchers. It leverages vessel speed and heading to generate smooth arcs between points, and it saw widespread use in European monitoring systems. Around the same time, Russo et al. built a variant using Catmull-Rom splines, adding heuristics for external forces like sea drift and wind. These methods were conceptually simple and computationally cheap. But they broke down in two specific scenarios: when the vessel made a sharp turn, or when its behavior changed in a non-smooth way, such as pausing near a transshipment site or re-entering port. In these cases, spline-based trajectories either over-smoothed or misrepresented the vessel’s operational mode.","sample":false,"doi":"10.1186/s40537-025-01163-0","short":"data-imputation","released":"June 2nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"BackForward Bi‐LSTM","carousels":["Temporal Analysis","LSTM","Transportation"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"data-imputation-in-large-and-smallscale-spatiotemporal-time-series-gaps-using-backforward-bilstm"},{"title":"Nonlinear Variation Decomposition of Neural Networks for Holistic Semiconductor Process Monitoring","description":"We’ll start by looking at the basics of Variation Decomposition, the role Linear Variation Decomposition plays in predicting Artificial Neural Network (ANN) models, and a solution that is able to provide neural network predictions within nonlinear models. To start, we need to clear up the relationship between semiconductor manufacturing and neural networks. In the case of semiconductors, engineers care about the chip’s Figure of Merit (FoM). A performance metric like speed, energy efficiency, or, in the case of this study, the Power-Delay Product (PDP). This figure reflects how much power a circuit consumes to perform a task, and lower is better.","sample":false,"doi":"10.1002/aisy.202300920","short":"nonlinear-variation-decomposition","released":"June 1st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Nonlinear Variation Decomposition","carousels":["Manufacturing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"nonlinear-variation-decomposition-of-neural-networks-for-holistic-semiconductor-process-monitoring"},{"title":"Akka as a tool for modeling and managing a smart grid system","description":"The solution they create uses Akka, a platform designed specifically for building distributed applications on the JVM. On today’s episode we’ll start by breaking down why distributed energy systems pose such a difficult architectural challenge. Then we’ll look at how Akka’s actor model gives system builders a way to encode asynchronous coordination, fault isolation, and hierarchical supervision directly into the structure of the runtime. We’ll walk through the specific mechanisms the authors used to simulate self-balancing grids, how they modeled nodes, managed local state, and coordinated redistribution without a central controller. Let’s jump in.","sample":false,"doi":"10.55056/jec.822","short":"akka-smart-grid","released":"May 31st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Akka for Smart Grids","carousels":["Distributed Computing","Distributed Systems","Microservices"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"akka-as-a-tool-for-modeling-and-managing-a-smart-grid-system"},{"title":"A Commit Classification Framework Incorporated With Prompt Tuning and External Knowledge","description":"Existing commit classification systems are overcomplicated, under-generalized, and too dependent on brittle output heads and high-volume labeled data. They don’t compose well across tasks, they don’t degrade gracefully when inputs are missing, and they certainly don’t make it easy to extend classification schemes as requirements evolve. That's the gap that the authors of today’s paper are trying to address. How? By proposing a new framework that classifies Git commits using prompt-tuned language models. On today’s episode we’re going to walk through their proposal: a generative alternative to the usual discriminative classifiers. One that doesn’t require a softmax head, doesn’t depend on a large labeled corpus, and still outperforms existing baselines in both binary and multiclass tasks. The authors’ new system is called IPCK. It stands for: Incorporating Prompt tuning for Commit classification with external Knowledge. The entire","sample":false,"doi":"10.1049/sfw2/5566134","short":"commit-classification","released":"May 30th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Commit Classification","carousels":["Software Engineering","Continuous Integration"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-commit-classification-framework-incorporated-with-prompt-tuning-and-external-knowledge"},{"title":"Sustainable Smart Irrigation System (SIS) using solar PV with rainwater harvesting technique for indoor plants","description":"First, the solar panel. The authors opted for a small one: at just 30W this monocrystalline photovoltaic panel was installed at a 15-degree tilt angle. This panel was chosen based on the energy requirements of all the other components in the system to optimize for efficiency. The authors analyzed the load of each system component: the Arduino Uno, soil moisture sensors, ultrasonic sensor, Global System for Mobile Communications (GSM) module, and DC water pump. They calculated a daily energy consumption of 22.71Wh and determined that with Malaysia's average sun-hours of 4.69 hours per day and accounting for a 50% buffer, they needed a minimum PV size of 7.26W. The 30W panel they chose provided ample headroom for operation even under suboptimal weather conditions. The power management system included a Maximum Power Point Tracker (MPPT) with a rated current of 7.8A, which optimizes the charging process by finding the ideal voltage-current point","sample":false,"doi":"10.1371/journal.pone.0316911","short":"sustainable-smart-irrigation","released":"May 29th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Smart Irrigation System","carousels":["Agriculture","Energy Science","Irrigation","Conservation"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"sustainable-smart-irrigation-system-sis-using-solar-pv-with-rainwater-harvesting-technique-for-indoor-plants"},{"title":"Singing to speech conversion with generative flow","description":"Today we’ll look at why sung text is so much harder to work with than spoken text and why this matters in the field of Automatic Speech Recognition. We’ll then learn how researchers are attempting to tackle this problem by developing a deep-learning based system for Singing-to-Speech conversion or S2S. Automatic Speech Recognition (ASR) is the use of machine learning to transcribe text from recordings of the human voice. When this technology is applied to song, it is referred to as Automatic Lyric Transcription (ALT). In comparison with speech, singing usually contains wider variation in pitch, duration, and timbre. Singing can also cause substantial changes in pronunciation. This increased variation means that you need more complex models and larger data sets to transcribe it. In today’s article, the authors propose an entirely new task, Singing-to-Speech (S2S), that may act as a bridge between song and text. Their goal was not to create something","sample":false,"doi":"10.1186/s13636-025-00400-x","short":"singing-to-speech","released":"May 28th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Singing to Speech Conversion","carousels":["Audio Processing","Natural Language Processing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"singing-to-speech-conversion-with-generative-flow"},{"title":"AI-Driven Real-Time Monitoring of Ground-Nesting Birds: A Case Study on Curlew Detection Using YOLOv10","description":"On today’s episode we are going to look at how researchers are using YOLOv10 for real-time monitoring of ground nesting birds to help them improve conservation efforts. We will first briefly talk about the challenges involved in curlew conservation. Next, we will dive into how the authors leveraged AI for camera trap image processing in real time with YOLOv10 and the Conservation AI platform. We will first break down what is different about the tenth version of YOLO. After that, we will talk about the workflow the authors used for this project, and how it turned out in the field. As the human world develops and expands, wild animals are pushed into smaller and smaller areas, or lose their habitat altogether. Ground nesting birds, like curlews, are particularly sensitive to this loss of habitat because they need wide open areas to nest. Additionally, if they are really concentrated in small areas, it is much easier for predators to","sample":false,"doi":"10.3390/rs17050769","short":"yolov10-curlews","released":"May 27th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"YOLOv10 for Conservation","carousels":["Conservation","Ecology","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"ai-driven-real-time-monitoring-of-ground-nesting-birds-a-case-study-on-curlew-detection-using-yolov10"},{"title":"Alpha-synuclein knockout impairs melanoma development and alters DNA damage repair in the TG3 mouse model","description":"In today's paper, the authors are fighting against Parkinson’s Disease related melanomas, to see if eliminating one protein, alpha-synuclein, could stop tumor growth. On today's episode, we’ll explore the relationship between Parkinson’s Disease and skin cancer, the molecular pathways surrounding alpha-synuclein that researchers tested, and what they learned about the treatment of both diseases. Let’s start with the connection between Parkinson’s and melanoma to set the stage. Parkinson’s Disease is a neurological condition that impacts memory and motor function. On a cellular level, Parkinson's involves the degeneration and eventual cell death of neurons, hence the loss of abilities controlled by the nervous system. The disease may share some of the same pathogenic characteristics of melanoma. Melanomas are cancerous growths of the melanin producing cells in the epidermis called melanocytes. The relation between these two diseases is so strong","sample":false,"doi":"10.3389/fonc.2025.1554059","short":"alpha-synuclein","released":"May 26th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Alpha-Synuclein Knockout","carousels":["Oncology","Genetics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"alpha-synuclein-knockout-impairs-melanoma-development-and-alters-dna-damage-repair-in-the-tg3-mouse-model"},{"title":"Graph visualization efficiency of popular web-based libraries","description":"On today’s episode, we’re taking a deeper look at performance unpredictability in graph visualization tools. We’ll follow along with the authors of this paper as they design a shootout between several different popular libraries, to determine which ones are (and are not) built for scale. We’ll see how they set up their benchmarking framework, how they ran their tests, and what results they obtained. Let’s dive in. In principle, modern web-based libraries like D3.js, ECharts.js, and G6.js make graph visualization accessible. They abstract away layout algorithms, handle DOM updates, and offer high-level APIs to plot diagrams with minimal boilerplate. But under the hood, they’re a bit of a rat’s nest. They wrap a tangle of layout routines, physics simulations, and rendering methods (SVG, Canvas, WebGL) that each scale in very different ways. The result is that, for many developers, these libraries have trouble scaling. When you outgrow the size and","sample":false,"doi":"10.1186/s42492-025-00193-y","short":"graph-visualization-efficiency","released":"May 25th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Graph Visualization Efficiency","carousels":["Front End","Web Development","JavaScript"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"graph-visualization-efficiency-of-popular-web-based-libraries"},{"title":"Data stream mining techniques for real‐time monitoring and control of smart power grids in Kenya: challenges and opportunities","description":"On today’s episode, we’re going deep-dive on this Kenyan case study, and take a deeper look at their national power grid. In this paper, the authors analyzed how data stream mining is being used in the wild. We’re going to walk through the pieces they found. We’ll see how fault detection and load balancing work when your sensor coverage is sparse and your compute is at the edge. We’ll see how predictive models like LSTMs and reinforcement learning are being used to stabilize the grid that includes intermittent renewables, and we’ll break down the architectural tradeoffs in scaling stream processing under severe bandwidth and infrastructure constraints. Let’s dive in. We need to start with what’s already deployed. As of now, data stream mining is not being used in its full form. Instead, the dominant approach is a patchwork of reactive telemetry, basic threshold-based alerts, and event logging, supported by limited deployments of smart meters and","sample":false,"doi":"10.1007/s43926-025-00146-0","short":"data-stream-mining","released":"May 24th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Data Stream Mining","carousels":["Energy Science","Smart Grids","Data Mining"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"data-stream-mining-techniques-for-realtime-monitoring-and-control-of-smart-power-grids-in-kenya-challenges-and-opportunities"},{"title":"Frequency-informed transformer for real-time water pipeline leak detection","description":"The traditional approach to vibration-based leak detection typically starts with raw sensor data collected over time. From there, the pipeline proceeds through several handcrafted steps: First, apply denoising or smoothing filters. Second, convert the signal to the frequency domain using a Fourier or wavelet transform. Third, manually select frequency bands that are assumed to correlate with leak signatures. And finally, pass extracted features into a classifier. These classifiers are usually either simple decision trees, rule-based systems, or shallow neural nets. The immediate problem with this approach is that it assumes prior knowledge about which parts of the spectrum matter. In practice, not all leaks sound the same. Their frequency peaks vary depending on pipe material, pressure, leak type, and environmental noise. Hard-coding those frequency bands means tuning the system for one condition and hoping it generalizes to others. Unfortunately","sample":false,"doi":"10.1007/s43684-025-00094-0","short":"pipeline-leak","released":"May 23rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Pipeline Leak Detection","carousels":["Transformers","City Planning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"frequency-informed-transformer-for-real-time-water-pipeline-leak-detection"},{"title":"Urban sentiment mapping using language and vision models in spatial analysis","description":"City planners have always struggled with understanding how people feel about their environments. Sure, there are surveys, interviews, and field observations, but these methods often fall short. They’re slow, limited in scope, and often fail to reflect the everyday experiences of real people across a city. There have been attempts to close this gap in the past. But their methods often relied on small datasets, simplistic tools, and manual analysis. The result is a blurry picture that lacks fine-grained emotional detail. That’s exactly what researchers are trying to solve. For this they designed a two-phase system: Phase 1: They used a large language model to analyze Instagram captions and determine the corresponding sentiment within that area. Phase 2: They used computer vision tools to analyze the corresponding street view imagery around each post. That way, they could directly correlate how people felt with what those places actually looked like.","sample":false,"doi":"10.3389/fcomp.2025.1504523","short":"urban-sentiment-mapping","released":"May 22nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Urban Sentiment Mapping","carousels":["City Planning","Sentiment Analysis","Natural Language Processing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"urban-sentiment-mapping-using-language-and-vision-models-in-spatial-analysis"},{"title":"A lightweight vulnerability detection method for long smart contracts based on bimodal feature fusion","description":"The authors propose a lightweight vulnerability detection system designed specifically to handle long smart contracts. It uses a hierarchical attention network and processes both source code and opcode in tandem. On today’s episode, we’re going to find out how they built it, and whether or not it works better than the alternatives. Most of the smart contract detection tools fall into two camps: Traditional static analyzers. Newer deep learning approaches like BiLSTM-based classifiers. Or CNN-GRU hybrids. Both categories have shown promise in finding basic bugs in short contracts. But once you cross the threshold into long contracts, especially those exceeding 500-1000 tokens of source, the failure modes start stacking up fast. Why? Because traditional tools rely heavily on symbolic execution, taint tracking, or rigid pattern matching. Symbolic execution in particular tends to run into the path explosion problem. Every conditional branch multiplies","sample":false,"doi":"10.1186/s42400-024-00332-7","short":"long-smart-contracts","released":"May 21st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Smart Contract Vulnerabilities","carousels":["Security","Blockchain","Crypto","Smart Contracts"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-lightweight-vulnerability-detection-method-for-long-smart-contracts-based-on-bimodal-feature-fusion"},{"title":"Fast autoscaling algorithm for cost optimization of container clusters","description":"Here’s the issue: ILP has a scaling ceiling. As the number of container classes, VM types, and applications increases, the size of the optimization problem explodes. Each container can fit in multiple VMs. Each VM can host multiple container combinations. And when you allow for both horizontal and vertical scaling, the variable count rapidly outpaces what most solvers can handle in real time. Even with carefully engineered simplifications, these systems eventually break down. In larger deployments, or in clusters with short scheduling windows, the solver either fails to converge or exceeds memory limits. So that’s the problem facing these researchers. Even if your workload forecasts are perfect, and your autoscaler has a rich inventory of resource types to choose from, you still have to solve the container-to-machine assignment problem in a matter of seconds. If you can’t, your autoscaler can’t act in time. That means wasted capacity, missed SLAs","sample":false,"doi":"10.1186/s13677-025-00748-7","short":"fast-autoscaling-clusters","released":"May 20th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Container Autoscaling","carousels":["Containers","System Architecture","Scaling"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fast-autoscaling-algorithm-for-cost-optimization-of-container-clusters"},{"title":"Signal-averaged electrocardiography as a noninvasive tool for evaluating the ventricular substrate in patients with nonischemic cardiomyopathy: reassessment of an old tool","description":"The electrocardiogram, abbreviated as ECG or EKG, is one of these tools. You know, the electrodes on your chest to measure your heart’s electrical activity? The peaks and valleys of the familiar waveform generated from ECG contain information about how each region of the heart is performing. Well, what if those electrodes on your chest could determine the location of a heart problem that hasn't even happened yet? Enter Signal Averaged Electrocardiography (SAECG), a specialized analysis of multiple ECG waveforms used to detect electrical conductivity in the ventricles of the heart. It’s non-invasive, easy to set up, and a powerful tool for assessing the risk of ventricular arrhythmia (VA). Already used as an early detection tool for patients with high VA risk, could this simple procedure make more invasive diagnostic methods unnecessary? In this paper, the authors propose the use of Signal Averaged Electrocardiography as a replacement for more","sample":false,"doi":"10.3389/fcvm.2024.1306055","short":"saecg-repurpose","released":"May 19th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Signal Averaged Electrocardiography","carousels":["Medicine","Cardiovascular Disease"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"signal-averaged-electrocardiography-as-a-noninvasive-tool-for-evaluating-the-ventricular-substrate-in-patients-with-nonischemic-cardiomyopathy-reassessment-of-an-old-tool"},{"title":"A Data-Driven Methodology for Quality Aware Code Fixing","description":"The authors present a system that makes specific, testable, and measurable code recommendations. Not to help you write code that works, but to help you write code that’s better than what’s already there. Quality-aware. Functionally equivalent. Syntactically similar. Backed by metrics. And ready to drop into production. On today’s episode we’ll take a good look at what they built, and how they did it. We’ll start by looking at why today’s automated tooling falls short. Then we’ll break down the architecture of the new system. You’ll learn how the authors constructed a corpus of annotated snippets, how they calculated both functional and syntactic similarity, and how they used clustering to make the system scalable.","sample":false,"doi":"10.1049/sfw2/4147669","short":"quality-aware-code-fixing","released":"May 18th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Quality Aware Code Fixing","carousels":["Software Engineering","Continuous Integration"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-data-driven-methodology-for-quality-aware-code-fixing"},{"title":"Designing Microservices Using AI: A Systematic Literature Review","description":"The age of “Vibe Coding” has arrived. Whether we like it or not. If you’re unfamiliar with that term, consider yourself fortunate to be so insulated from programmer meme culture. It’s a term that held virtually no meaning a few years ago, and today is a common expression. So what does it mean? Vibe Coding is a verb, It’s the act of using LLMs and other A.I.-powered code-completion tools less like they’re a helper, and more like they’re the lead dev. It’s almost an inversion of control: you’re no longer using the A.I. when you get stuck, you’re using it all the time, by default. And it’s only when something doesn’t work as expected, or the system needs direction or course-correction, that you need to step in and help. The first few times I heard the term it was used in a derogatory way; saying someone was “vibe coding” their product was not a compliment. But in less than a year, that connotation has shifted, hard. Recently, even Garry Tan, the","sample":false,"doi":"10.3390/software4010006","short":"vibe-coding-microservices","released":"May 17th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Vibe Coding Microservices","carousels":["System Architecture","Vibe Coding","Cloud Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"designing-microservices-using-ai-a-systematic-literature-review"},{"title":"Making JavaScript Render Decisions to Optimize Security-Oriented Crawler Process","description":"Imagine that you’re running a small security startup. You offer fully automated vulnerability scanning for websites. Small businesses come to your site, sign up, put in their domain name, and you run continuous scans of their site to check for any issues. And it’s not just a one-time scan: the idea is, every time they push a change to production, your entire suite of scans runs over and over again. It’s a valuable service, and you can charge a decent price for it. But there’s an issue: as you scale up, adding bigger and bigger clients, your server-bills are starting to get a little out of hand. Why? One word: JavaScript. You’ve got a bot (a scraper) that is continuously fetching pages from your client’s sites and scanning them for vulnerabilities. But, many of the inputs (and outbound links) your scanner needs to test do not actually appear in the raw HTML. Those elements are added to the DOM at runtime by JavaScript. This means, they","sample":false,"doi":"10.1109/ACCESS.2024.3481646","short":"javascript-render-decisions","released":"May 16th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Security Oriented Crawlers","carousels":["Security","Web Development"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"making-javascript-render-decisions-to-optimize-security-oriented-crawler-process"},{"title":"Enhanced Binary Kepler Optimization Algorithm for effective feature selection of supervised learning classification","description":"Many metaheuristics draw their metaphors from nature. Some pretend to be bees. Some pretend to be wolves. This one pretends to be a planet. The Kepler Optimization Algorithm (KOA) already existed prior to this paper. It’s a physics-inspired method that simulates planetary motion as a way to guide candidate solutions through the search space. Specifically, it’s built around Kepler’s three laws of orbital mechanics (which describe how the planets orbit around the sun). The key idea is that each solution is treated as a \"planet\" orbiting around the current global best, which acts as the \"sun.\" The metaphor isn’t just for show. Each of the algorithm’s internal update rules (its position, velocity, eccentricity, gravitational pull) maps directly to a component of Keplerian physics. These constructs define how solutions evolve over time. Each candidate solution starts as a point in the search space with a randomly initialized","sample":false,"doi":"10.1186/s40537-025-01125-6","short":"enhanced-binary-kepler","released":"May 15th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Enhanced Binary Kepler Optimization","carousels":["Algorithms","Model Training","Feature Selection"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"enhanced-binary-kepler-optimization-algorithm-for-effective-feature-selection-of-supervised-learning-classification"},{"title":"Agentic Workflows for Improving Large Language Model Reasoning in Robotic Object-Centered Planning","description":"In this paper, the baseline approach that they’re comparing against uses a single-step LLM prompt. It includes the full semantic map in JSON format and a natural language query, and it returns a ranked list of object identifiers. In practice, this approach works fine on simple queries, especially those that require direct string matches or category lookups. But its performance drops quickly when the query introduces ambiguity, requires reasoning about object function, or includes negative logic. Since it’s a single-step there’s no iterative feedback, no correction step, and no filtering mechanism beyond what the LLM does implicitly. As the map size increases, performance actually degrades further. This is due to context length saturation and the LLM's tendency to focus on early or late parts of the prompt, ignoring the middle. This is (more or less) the core technical limitation that the authors are trying to solve. The challenge is","sample":false,"doi":"10.3390/robotics14030024","short":"agentic-workflow-llms","released":"May 14th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Agentic Workflows for Robots","carousels":["Robotics","Agents","Large Language Models"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"agentic-workflows-for-improving-large-language-model-reasoning-in-robotic-object-centered-planning"},{"title":"Effectiveness of training under stress in immersive VR: an investigation of firefighter performance, gaze entropy, and pupillometry","description":"This study was designed to go well beyond a simple accuracy test. The authors split their measurements into three main categories: task performance, eye movement data, and subjective psychometric evaluations. Together, these provided a multilayered picture of how stress impacts learning and retrieval in a simulated emergency. Let’s start with performance. Each participant was asked to memorize and then execute the shutdown sequence. The researchers captured two main metrics: the number of valves closed in the correct order (sequence accuracy) and the time it took to complete the task (operation time). Because not everyone finished all eight steps, they normalized performance using “operation time per correct valve,” which adjusts for partial completions and allows a clean comparison across users with different accuracy levels. Then came the gaze data. The eye tracker recorded eye movements at 90 Hz. From this, the researchers computed gaze","sample":false,"doi":"10.3389/frvir.2025.1542507","short":"vr-training-stress","released":"May 13th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"State Dependent Learning in VR","carousels":["Virtual Reality"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"effectiveness-of-training-under-stress-in-immersive-vr-an-investigation-of-firefighter-performance-gaze-entropy-and-pupillometry"},{"title":"A B-Spline Function Based 3D Point Cloud Unwrapping Scheme for 3D Fingerprint Recognition and Identification","description":"What’s a B-spline? B-splines are piecewise polynomial functions that can flexibly approximate smooth curves by stitching together low-degree polynomials across defined intervals, controlled by a set of points called knots. Unlike simple polynomials, B-splines provide local control (adjusting one segment doesn’t distort the entire curve) which makes them ideal for modeling complex shapes like biometric surfaces. The process starts by slicing the point cloud in the Y-direction, which corresponds to the length of the finger. Each slice is one point thick. Within each slice, the Z values of the points (which represent height above the sensor plane) are fitted to a B-spline curve. Think of this like laying a flexible ruler across the surface of the slice. This curve becomes a smooth local baseline. Then, the algorithm subtracts the Z value of the curve from each point’s Z value, normalizing away the global shape of the finger while keeping the","sample":false,"doi":"10.1109/OJCS.2025.3559975","short":"3d-fingerprints","released":"May 12th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"B-Spline Curve Fitting","carousels":["Point Clouds","3D Mapping"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-b-spline-function-based-3d-point-cloud-unwrapping-scheme-for-3d-fingerprint-recognition-and-identification"},{"title":"Electronic nose and machine learning for modern meat inspection","description":"In this paper the authors are trying something different. They’re taking a commercially available metal-oxide gas sensor array (the \"electronic nose”) and combining it with a classification pipeline built from 60 extracted signal features and a high-performing ensemble model. Their goal is to detect the presence of urine-related odor signatures in raw pig meat, with high accuracy, in real time, without human sensory judgment. In other words, they’re proposing a digital protocol that could “smell” a piece of pork, and tell you if it’s contaminated with urine. If it works well enough, it could, in theory, eventually replace (or at least augment) the nose of a human inspector. Let’s flush out more of the technical problem-space, then explore what the authors built, how it works, and whether or not it is effective. There are a number of current lab-based methods to analyze odor. This includes gas chromatography-mass spectrometry (GC-MS), surface","sample":false,"doi":"10.1186/s40537-025-01151-4","short":"electronic-nose","released":"May 11th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Electronic Nose","carousels":["Agriculture","Robotics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"electronic-nose-and-machine-learning-for-modern-meat-inspection"},{"title":"Detecting sarcasm in user-generated content integrating transformers and gated graph neural networks","description":"The core issue is that sarcasm is adversarial. It intentionally subverts expected word-sentiment mappings. That undermines everything from rule-based sentiment taggers to deep neural nets trained on bag-of-words or static embeddings. Even high-capacity models can trip up when the contradiction requires reasoning across distant tokens or detecting an emotional inversion not explicitly stated in the input. You can’t resolve sarcasm by looking at one word in isolation. You need to track how its meaning shifts relative to the structure and emotional trajectory of the whole sentence. To make matters worse, sarcasm doesn’t always look the same. In some cases it’s overt, with strong lexical contrast: “I just love being stuck in traffic.” In others, it’s subtle or context-dependent: “Wonderful timing, as always.” In any given statement the sarcastic cue might come from a sentiment reversal, a syntactic mismatch, or a clash between formality","sample":false,"doi":"10.7717/peerj-cs.2817","short":"detecting-sarcasm","released":"May 10th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Sarcasm Detection","carousels":["Natural Language Processing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"detecting-sarcasm-in-user-generated-content-integrating-transformers-and-gated-graph-neural-networks"},{"title":"Reflective error: a metric for assessing predictive performance at extreme events","description":"If you're evaluating a regression model, especially in environmental modeling or scientific computing, you’re probably reaching for root mean squared error (RMSE), or maybe R-squared. These are the default metrics. They’re implemented in every major ML library. They're what you log during training, what you use in your plots, and what you hand over to stakeholders as a measure of how “good\" the model is. But, as I mentioned above, there's a blind spot. RMSE tells you the magnitude of your model’s average deviation, but it’s insensitive to where those deviations occur in the distribution. Whether your model is consistently off in the tails, or only makes small errors in the mode, RMSE will often return the same score. That’s a problem if your application actually cares about getting the extremes right. Take flood prediction, for example. Missing the routine streamflow by a few percent is tolerable. Missing the flood crest by the same","sample":false,"doi":"10.1017/eds.2025.16","short":"reflective-error","released":"May 9th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Reflective Error","carousels":["Data Science","Statistics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"reflective-error-a-metric-for-assessing-predictive-performance-at-extreme-events"},{"title":"A privacy-compliant approach to responsible dataset utilization for vehicle re-identification","description":"The idea behind vehicle Re-ID (v-ReID) is fairly straightforward: given a query image of a vehicle, the system needs to find other instances of the same vehicle across different camera feeds. It’s a retrieval problem. The catch is that it has to work in unconstrained environments: different lighting, different viewpoints, and different cameras. Most modern approaches lean heavily on deep learning, particularly convolutional neural networks and, more recently, transformer variants. And like any deep learning setup, these models are only as good as the data they’re trained on. Which brings us to the real problem: the datasets. Two of the most widely used benchmarks in the space are, as I mentioned, VeRi-776 and VehicleID. Both are large-scale, both publicly available, and both considered standard references for training and evaluating these kinds of models. But neither one was designed with privacy, ethics, or dataset hygiene in mind. In VehicleID, for example","sample":false,"doi":"10.48130/dts-0024-0019","short":"privacy-compliant-vehicle-reid","released":"May 8th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Vehicle Re-Identification","carousels":["Transportation","Civil Engineering","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-privacy-compliant-approach-to-responsible-dataset-utilization-for-vehicle-re-identification"},{"title":"FPGA-Based Realization of Intelligent Escalator Controller Using Artificial Neural Network","description":"the problem they are solving is narrow but not trivial: build a real-time controller with no operating system. No microcontroller. Just a feed-forward neural net burned into silicon. Let’s walk through the structure of the neural network they built to handle the task. The input to the network consists of four binary signals. Each corresponds to one of the four stair-steps in the prototype escalator. These are hard-wired signals coming from discrete infrared sensors mounted at each step. Each signal is either high (occupied) or low (empty), giving us a total input space of 16 unique combinations. These four binary inputs feed directly into the input layer of the neural network. The input layer consists of 4 neurons. These feed into a single hidden layer containing 10 neurons. The hidden layer uses the satlins activation function, a symmetric saturated linear function with output constrained between -1 and +1. Satlins behaves similarly to tansig or","sample":false,"doi":"10.1155/jece/7567924","short":"fpga-escalator","released":"May 7th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"FPGA Escalator","carousels":["Robotics","Automation","Microcontrollers"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fpga-based-realization-of-intelligent-escalator-controller-using-artificial-neural-network"},{"title":"Advancing Forex prediction through multimodal text-driven model and attention mechanisms","description":"Let’s say you’re building an algorithmic trading system for the FOREX (FX) market. Not equities, not crypto, but currency pairs. You’re not aiming for long-term macroeconomic positioning, and you’re not doing high-frequency tick-level scalping either. You’re somewhere in the middle. You want to make short-term directional forecasts, ideally within a 24-hour window. And to do that, your system needs to integrate two very different kinds of signals: quantitative market data, and qualitative news sentiment. So which area do you start with, quantitative or qualitative? Maybe you reach for a moving average crossover strategy with RSI filters (quantitative). Maybe you take headlines from Reuters and Bloomberg and feed them into a sentiment classifier (qualitative). Usually one or the other, not both. Most models treat technical analysis and sentiment analysis as separate paths. Separate inputs. Separate tasks. Even in research, the common approach is","sample":false,"doi":"10.1016/j.iswa.2025.200518","short":"advancing-forex-prediction","released":"May 6th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"FOREX prediction","carousels":["Finance","Economics","Time Series Forecasting"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"advancing-forex-prediction-through-multimodal-text-driven-model-and-attention-mechanisms"},{"title":"Spatial identification of manipulable objects for a bionic hand prosthesis","description":"Your primary input signal is EMG (electromyography), gathered from the terminal-end of the user’s limb. But if you’ve worked with EMG before, you know the limits. It’s noisy, it’s variable, and it’s ambiguous. A single muscle firing pattern can mean different things depending on context. One user might flex to grab a doorknob, another to grasp a cup. The signals are biologically real but semantically weak. That’s your problem-space: intention recognition. If you misclassify the user’s intent, the hand grabs the wrong way. If the grip doesn't match the object, the fingers slip, or the object is crushed, or the hand locks into an unusable position. Or worse. And in a constrained embedded environment, you don’t have the luxury of adding lidar, tactile arrays, or high-res cameras. What you need is a second signal. Something fast, cheap, and good enough. Not perfect classification, just something that gives your system enough context to","sample":false,"doi":"10.35784/acs_6867","short":"bionic-spatial-identification","released":"May 5th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Spatial Identification for Bionic Hands","carousels":["Computer Vision","Robotics","Medicine","Signal Processing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"spatial-identification-of-manipulable-objects-for-a-bionic-hand-prosthesis"},{"title":"Reconstructing unreadable QR codes: a deep learning based super resolution strategy","description":"Today’s paper focuses not on better code generation, or improvements to physical printing, but on the computational recovery of unreadable QR codes, after the damage is done. The authors ask a series of questions: When a QR code scan fails, can we use deep learning-based super-resolution to reconstruct a version of the image that can be decoded? And if so, which model works best, under which conditions, and with what tradeoffs? These questions aren’t new. But the experimental setup in this paper is different from most prior work. Instead of just generating synthetic low-res QR codes and testing on them, the authors collected over four thousand real-world scanned QR codes that had failed to decode in the wild. These aren’t academic edge cases; they are representative of the actual failure points in deployed systems. The authors also included an additional ~3,000 simulated QR codes that couldn’t be read by either OpenCV’s traditional","sample":false,"doi":"10.7717/peerj-cs.2841","short":"unreadable-qr-codes","released":"May 4th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Reconstructing QR Codes","carousels":["Computer Vision","Logistics","Operations"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"reconstructing-unreadable-qr-codes-a-deep-learning-based-super-resolution-strategy"},{"title":"Network level spatial temporal traffic forecasting with Hierarchical Attention LSTM","description":"Many engineers have tried to solve this problem with Graph Neural Networks, which encode spatial layout well but often struggle with temporal hierarchy unless you bolt on additional modules. Others have used LSTM variants instead, but those models fall short when they’re built on flat or stacked architectures that can’t differentiate between short-term blips and long-term trends. Most existing approaches operate on a fixed temporal scale and shallow memory structure, which limits their ability to spot the kinds of emerging disruptions that matter most in live deployments. What we’re looking at today is a different approach. A hierarchical LSTM architecture that uses attention pooling at multiple levels to selectively compress and propagate relevant features from lower layers to higher ones. The goal isn’t just more depth, it’s better abstraction. The idea is to build temporal representations that become more informative and more","sample":false,"doi":"10.48130/dts-0024-0021","short":"spatiotemporal-traffic-forecasting","released":"May 3rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Spatiotemporal Traffic Forecasting","carousels":["Temporal Analysis","LSTM","Transportation"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"network-level-spatial-temporal-traffic-forecasting-with-hierarchical-attention-lstm"},{"title":"FLASC: a flare-sensitive clustering algorithm","description":"If you have a cluster that internally branches, like a Y-shape or a starburst, traditional clustering methods will treat the entire structure as a single monolithic group. They will not tell you that some data points are headed down one evolutionary path while others are diverging down another. You can’t rely on density gaps to separate these subpopulations because the branches are connected by continuous paths of relatively high density. From the point of view of the clustering algorithm, it is just one big happy family. In practice, this is a real limitation. Branching structures inside clusters show up across a wide range of domains: in biological cell development, in customer behavior modeling, in physical system transitions, and in process drift analysis. If your clustering pipeline cannot detect internal branches, you are leaving valuable information on the table. You might miss critical subgroups, misinterpret the shape of your data","sample":false,"doi":"10.7717/peerj-cs.2792","short":"flare-sensitive-clustering","released":"May 2nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Flare Sensitive Clustering","carousels":["Algorithms","Data Science","Data Wrangling"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"flasc-a-flare-sensitive-clustering-algorithm"},{"title":"A YOLOv8-CE-based real-time traffic sign detection and identification method for autonomous vehicles","description":"Previous generations of traffic sign detection methods, especially those relying on traditional machine vision techniques like color thresholding or shape analysis, fail almost completely under variable real-world conditions. Even modern deep learning models struggle. When the environment degrades, or when the signs are too small relative to the input resolution, detection confidence collapses. Worse, the latency of a full YOLOv8 pipeline, even in its smallest variant, is often outside the margin of what is acceptable on a low-end embedded platform without heavy optimization. All of this creates a hard technical bottleneck. You need a model that can not just classify but also localize small objects precisely and do it fast. You need robustness across weather, lighting, and motion artifacts. And you need to achieve all of that without blowing through your compute or energy budgets. Enter YOLOv8n. \"n\" stands for \"nano\". It is the smallest","sample":false,"doi":"10.48130/dts-0024-0009","short":"traffic-sign-detection","released":"May 1st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Traffic Sign Detection","carousels":["Autonomous Driving","Computer Vision","Convolutional Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-yolov8-ce-based-real-time-traffic-sign-detection-and-identification-method-for-autonomous-vehicles"},{"title":"Enhancing intrusion detection systems: Innovative deep learning approaches using CNN, RNN, DBN and autoencoders for robust network security","description":"Traditional intrusion detection systems are falling behind. Most of the methods that are widely deployed today are based on static signatures, predefined rules, or fixed heuristics. That means that these systems can recognize the threats that they’ve seen before, but struggle with new, evolving, or intentionally obfuscated attacks. The result is an ever-widening gap between the cat and the mouse…between the sophistication of cyberattacks and the capabilities of the systems that are supposed to be able to catch them. This gap is not theoretical. It is operational. Attackers are increasingly relying on polymorphic techniques, multi-stage intrusions, and evasion strategies that allow them to slip past conventional IDS (Intrusion Detection) defenses undetected. Organizations that depend on static rule-based systems are, arguably, operating with non-trivial blind spots in their security posture. And as networks scale in size, complexity","sample":false,"doi":"10.35784/acs_6667","short":"enhancing-intrusion-detection","released":"April 30th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Enhanced Intrusion Detection","carousels":["Security","Deep Learning","Convolutional Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"enhancing-intrusion-detection-systems-innovative-deep-learning-approaches-using-cnn-rnn-dbn-and-autoencoders-for-robust-network-security"},{"title":"Digital twins: Recent advances and future directions in engineering fields","description":"The paper outlines a core distinction that matters a lot here: causal vs acausal simulation tools. If your background is in control systems or robotics, you're probably familiar with Simulink and other causal modeling environments. These work fine when the inputs and outputs are unidirectional and the dependency graph is acyclic. But try to model a heat pump or a power grid and you’ll quickly run into problems. Algebraic loops. Implicit dependencies. Simulation blowups. In those scenarios, acausal tools like Modelica, which describe systems through declarative physical equations, are not just better, they’re required. You don’t specify the order of operations. The solver figures that out based on the system structure. This enables simulation of truly interconnected systems where component boundaries don’t map cleanly onto function calls or data flows. Real-time updates mean the simulation layer can't be slow. You’re not running this","sample":false,"doi":"10.1016/j.iswa.2025.200516","short":"digital-twins-engineering","released":"April 29th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Digital Twins: Recent Advances","carousels":["Digital Twins","Modeling","Manufacturing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"digital-twins-recent-advances-and-future-directions-in-engineering-fields"},{"title":"Agentic AI: Autonomous Intelligence for Complex Goals—A Comprehensive Survey","description":"Let’s start by diving in to the more expanded definition that the authors put forward to separate classical AI from Agentic AI: Unlike classical AI, which typically operates within tightly bounded task definitions, Agentic AI systems are expected to manage goals that are either loosely specified or that require dynamic reinterpretation based on new information. Unlike generative AI, which can synthesize novel content but remains largely passive in its output generation (responding rather than initiating), Agentic AI models are goal-driven. They initiate plans, reallocate resources, and modify strategies without needing external prompts at every decision point. The authors explicitly set Agentic AI apart from earlier paradigms by focusing on three properties: autonomy, adaptability, and goal-centered operation. Autonomy here does not merely mean the ability to function without direct supervision. It refers to the system's ability to define","sample":false,"doi":"10.1109/ACCESS.2025.3532853","short":"agentic-ai-complex-goals","released":"April 28th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Agentic A.I. (Autonomous Agents)","carousels":["Autonomous Agents","Deep Learning","Robotics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"agentic-ai-autonomous-intelligence-for-complex-goalsa-comprehensive-survey"},{"title":"Time Series Forecasting Using Recurrent Neural Networks Based on Recurrent Sigmoid Piecewise Linear Neurons","description":"Today we’re going to dig into one of those new advancements. A new recurrent neuron architecture designed specifically for this problem space: the Recurrent Sigmoid Piecewise Linear (RSPL) neuron. We’re going to walk through the core technical motivation behind it, the structural differences compared to LSTM and GRU neurons, and how it manages to deliver better stability and lower error variance with fewer parameters. We will step through the experimental setup that was used to benchmark RSPL against traditional recurrent cells and examine the results in detail. Let’s dive in. To date, the dominant technical paradigm for handling time-dependent prediction tasks has long been recurrent neural networks (RNNs), particularly variants like Long Short-Term Memory networks (LSTMs) and Gated Recurrent Units (GRUs). These latter two architectures were designed to address some of the shortcomings of vanilla RNNs, but they introduced problems of their","sample":false,"doi":"10.1080/08839514.2025.2490057","short":"rnn-time-series-forecasting","released":"April 27th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Recurrent Sigmoid Piecewise Linear Neurons","carousels":["Temporal Analysis","Time Series Forecasting","Recurrent Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"time-series-forecasting-using-recurrent-neural-networks-based-on-recurrent-sigmoid-piecewise-linear-neurons"},{"title":"The evolution of the cold chain logistics vehicle routing problem: a bibliometric and visualization review","description":"Within cold-chain logistics there are several sub-fields, competencies and core problem spaces. One of the key challenges is the vehicle routing problem (VRP). In classical logistics, VRP is already a hard enough challenge: select an efficient set of delivery paths while minimizing distance, time, or cost, all under basic operational constraints. But cold chain logistics does not operate under \"basic\" conditions. Here, routing is a first-class determinant of whether the cargo even survives the trip. Every minute a shipment of pharmaceuticals, food, or other perishables spends outside a strict temperature band directly impacts product viability, regulatory compliance, and bottom-line profitability. As a result, the cold chain logistics vehicle routing problem (CCVRP) forces a fundamental rethink of the assumptions underlying traditional VRP approaches. And that is what today’s paper is all about.","sample":false,"doi":"10.48130/dts-0024-0010","short":"coldchain-logistics-routing","released":"April 26th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Cold-Chain Vehicle Routing","carousels":["Logistics","Transportation","Operations"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-evolution-of-the-cold-chain-logistics-vehicle-routing-problem-a-bibliometric-and-visualization-review"},{"title":"LViT-Net: a domain generalization person re-identification model combining local semantics and multi-feature cross fusion","description":"Traditional re-identification (ReID) pipelines typically lean on deep convolutional neural networks (CNNs). These models are optimized to pick up discriminative features: shoe color, bag shape, body proportions. That works well in a closed-world setting where training and test data share statistical structure. But in cross-domain scenarios, those features often stop being discriminative. A white shirt under one camera becomes pale blue under another. A red bag in sunlight might wash out under shade. Inter-class similarity and intra-class variability shoot up. The features the model thought were useful become liabilities. One direction the field took was to emphasize global semantic representations. Vision Transformers (ViTs), with their large receptive fields and self-attention mechanisms, excel here. By modeling long-range dependencies, ViTs can learn more abstract representations that generalize better across","sample":false,"doi":"10.1186/s42492-025-00190-1","short":"domain-generalization-person-reid","released":"April 25th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Person Re-Identification (ReID)","carousels":["Computer Vision","Vision Transformers","Transformers"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"lvit-net-a-domain-generalization-person-re-identification-model-combining-local-semantics-and-multi-feature-cross-fusion"},{"title":"Transfer learning nonlinear plasma dynamic transitions in low dimensional embeddings via deep neural networks","description":"In plasma physics, especially in the context of magnetic confinement fusion, these transitions aren’t anomalies. They’re fundamental. Understanding when and why they happen is the difference between a stable burn and a serious disruption. A tokamak, in particular, is a nonlinear system, and the instabilities that arise (fishbones, sawtooth oscillations, neoclassical tearing modes, internal kinks) aren’t just passive diagnostics of a failing state. They’re actually active participants in the degradation and disruption. So if you're working on a fusion project and trying to build systems to control a plasma, your models have to do more than extrapolate the smooth part of the trajectory. They need to predict when the regime itself (the governing dynamics of the physical system) is about to change. That’s not trivial. The governing equations here are a coupled set of nonlinear partial differential equations (PDEs). Even with modern","sample":false,"doi":"10.1088/2632-2153/adca83","short":"plasma-dynamic-transitions","released":"April 24th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Transfer Learning for Nuclear Fusion","carousels":["Physics","Nuclear Power","Energy Science","Nuclear Fusion","Deep Learning","Fine Tuning","Transfer Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"transfer-learning-nonlinear-plasma-dynamic-transitions-in-low-dimensional-embeddings-via-deep-neural-networks"},{"title":"A comparative study of neural network pruning strategies for industrial applications","description":"Pre-Training Pruning: This is what you’d expect if you’ve worked with static pruning or tried L1-based compression in PyTorch or TensorFlow. The model starts with a dense set of weights, then the weakest ones (measured using the L1 norm) are zeroed out before training begins. In their setup, this means computing the L1 magnitude of each connection in a layer, ranking them, and dropping the bottom X percent to hit a predefined sparsity level. It’s simple and deterministic. But once you kill a connection, it’s gone for good. You’re locking the sparsity structure in place before the model has had a chance to learn which pathways might end up being important. That tradeoff: less training overhead, but no flexibility, is a recurring theme across the other methods as well. In-Training Pruning: This method is more dynamic. The pruning process runs every epoch. After each round of backpropagation, the algorithm identifies the","sample":false,"doi":"10.3389/fcomp.2025.1563942","short":"pruning-strategies","released":"April 23rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Neural Network Pruning Strategies","carousels":["Model Training","Industrial Engineering","Operations","Manufacturing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-comparative-study-of-neural-network-pruning-strategies-for-industrial-applications"},{"title":"SWIPT-Enabled Full-Duplex Short Packet Communications With Nonlinear Energy Harvesting","description":"Let’s start with full-duplex. Each node in the system has two antennas, one for transmitting and one for receiving. That allows both nodes to transmit and receive concurrently on the same frequency channel. The upside is clear: higher spectral efficiency and reduced latency. The downside is equally familiar: self-interference. In this model, the self-interference channels are represented using Rayleigh fading with independent coefficients. These terms matter because as transmit power increases, so does the interference, and in full-duplex systems that interference is not negligible. It dominates over the background noise. Now add short-packet communication. Instead of assuming large codewords and asymptotic error-free performance, the system transmits short blocks of data, typically around 200 symbols per packet. That means Shannon capacity (the theoretical maximum rate achievable only when blocklength goes to infinity) no longer applies","sample":false,"doi":"10.1155/dsn/4731569","short":"full-duplex-short-packet","released":"April 22nd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Full-Duplex & Short Packets","carousels":["Telecommunications","Electromagnetic Spectrum","Network Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"swipt-enabled-full-duplex-short-packet-communications-with-nonlinear-energy-harvesting"},{"title":"Deep learning for algorithmic trading: A systematic review of predictive models and optimization strategies","description":"The bulk of the models they reviewed fall into one of seven architecture classes: RNNs, LSTMs, CNNs, Autoencoders (including VAEs), GNNs, Transformers, and Reinforcement Learning hybrids. Each comes with tradeoffs, and each is being used in different ways depending on the specific prediction or trading task. I’ll walk through them in that order. RNNs are the most traditional approach for time-series forecasting. They operate by feeding the output from the previous timestep back into the model. This recurrent loop gives RNNs memory, which in principle allows them to capture temporal dependencies across financial time series. But in practice, vanilla RNNs degrade quickly when trying to model anything with long-term dependencies. They’re prone to vanishing gradients, they underperform in volatile markets, and they tend to overfit when the input data is noisy (which it usually is). A couple of studies cited in the review proposed RNN variants that","sample":false,"doi":"10.1016/j.array.2025.100390","short":"dl-algorithmic-trading","released":"April 21st 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Deep Learning for Algorithmic Trading","carousels":["Finance","Economics","Deep Learning","Time Series Forecasting"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"deep-learning-for-algorithmic-trading-a-systematic-review-of-predictive-models-and-optimization-strategies"},{"title":"Health literacy profiling: a snapshot of Tasmania’s challenges and strengths using five domains of the health literacy questionnaire (HLQ)","description":"In hierarchical clustering, an algorithm works by comparing observations one by one to find the two that are the most similar. Each observation (n) is considered its own cluster to start. Once the algorithm finds the two most similar observations, it will make a new cluster. At this point you have one new cluster and all the other individual observations (cluster 1 and n minus 2 observations). It then repeats, comparing all observations again (including the new cluster). The algorithm finds the next most similar pair and makes a new cluster. Confused? Ok, let’s break it down. You can think about it like this: You have a bag of trail mix (mixed nuts, dried fruits, and chocolate), you dump it out on the counter, and try to sort it. First, you grab one piece of chocolate, and look for another. You find the match, and group them together. At this point, you have 2 pieces of chocolate in a “cluster” and all the rest of your trail mix still","sample":false,"doi":"10.1080/28355245.2024.2410201","short":"hlq-cluster-analysis","released":"April 20th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"HLQ Cluster Analysis","carousels":["Public Health","Statistics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"health-literacy-profiling-a-snapshot-of-tasmanias-challenges-and-strengths-using-five-domains-of-the-health-literacy-questionnaire-hlq"},{"title":"A Randomized, Double-Blind, Placebo-Controlled Trial to Assess the Effectiveness and Safety of Melatonin and Three Formulations of Floraworks Proprietary TruCBN for Improving Sleep","description":"Circadian rhythms are your body’s natural 24-hour clock. This internal clock uses hormones to make you feel sleepy and natural steroids to make you feel alert. It is controlled by signals like light and darkness. Light tells your brain to stay alert, and darkness triggers melatonin, the hormone that helps you sleep. Things like jet lag, working night shifts, late-night screen time, or an irregular sleep schedule can change or disrupt your circadian rhythm. If your internal clock is off, you may not get quality sleep at night and then struggle with low energy, grogginess, or trouble concentrating the next day. Over long periods, this pattern can seriously affect your overall well-being. For example, people with chronically disrupted rhythms often report mood changes and stress. Luckily, you have plenty of non-medicinal options to help you get a good night’s sleep. Unfortunately, they aren’t always effective, and you may end up joining the","sample":false,"doi":"10.3390/ph17080977","short":"melatonin-cbn-sleep","released":"April 19th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Melatonin & Cannabinols","carousels":["Medicine","Pharmacology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-randomized-double-blind-placebo-controlled-trial-to-assess-the-effectiveness-and-safety-of-melatonin-and-three-formulations-of-floraworks-proprietary-trucbn-for-improving-sleep"},{"title":"A Predictive Model of Cardiovascular Aging by Clinical and Immunological Markers Using Machine Learning","description":"The inflammatory response is the result of cellular combat against invaders. On the molecular level, the immune response is composed of various specialized cells that identify, dissolve and eliminate foreign substances in the body. It’s meant to stop once a pathogen has been dealt with so new cells can grow and tissue can repair itself. Chronic inflammation however is essentially just one long drawn out fight that our immune system just can't seem to stop. But it’s not fighting a constant bombardment of endless invaders that creates ageing-related chronic inflammation, it seems to have more to do with immune cells behaving abnormally. Research around cardiovascular disease (CVD) in particular has identified a strong connection between chronic inflammation and immuno-genetic factors. The genes that control our immune responses might be at fault for those systems turning on us as we age. What if there were a way to assess how your immune","sample":false,"doi":"10.3390/diagnostics15070850","short":"predictive-cardiovascular-aging","released":"April 18th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Predicting Cardiovascular Aging","carousels":["Medicine","Cardiovascular Disease"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-predictive-model-of-cardiovascular-aging-by-clinical-and-immunological-markers-using-machine-learning"},{"title":"Exploring quantum materials and applications: a review","description":"A quantum material is a substance whose behavior cannot be explained by classical physics. Instead, we need quantum mechanics in order to understand their unique properties. What do we mean by classical physics when talking about materials? Materials are governed by particle interaction, for example, the motion of ions in saltwater can be classically explained by electrostatic interactions. But with quantum materials, a quantum mechanics approach is the only way to explain certain characteristics like spin entanglements and high temperature superconductivity. If my explanation of quantum materials feels a little strange or isn’t completely sinking in, then I invite you to enjoy the following quote from Professor of solid-state chemistry, Robert Cava: “I will not endeavour to provide a precise definition of what a quantum material is, but I know one when I see it.” In order to take his advice, and know one when we’ve","sample":false,"doi":"10.1186/s40712-024-00202-7","short":"exploring-quantum-materials","released":"April 17th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Quantum Materials","carousels":["Materials Science","Quantum Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"exploring-quantum-materials-and-applications-a-review"},{"title":"Sound-Based Assembly of Magnetically Actuated Soft Robots Toward Enhanced Release of Extracellular Vesicles","description":"Magnetic soft robots are one of the most promising tools currently being pursued for biomedicine. They offer wireless control, rapid response, and are often compatible with biological systems. Magnetoresponsive materials can be manipulated remotely and allow for a wide variety of potential movements including bending, stretching, and folding. These kinds of transformations can be completed even in a confined space. This capability makes them perfect for miniaturization. These soft robots could be used for drug delivery, detection and diagnosis, or even for minimally invasive surgery. Numerous methods for manufacturing these robots have been explored thus far. Recent advancements in additive manufacturing (including inkjet-based, extrusion-based, droplet-based, and laser-based) have allowed for the development of agile, multifunction robots. However, these methods are far from perfect. For example, in the extrusion-based technique","sample":false,"doi":"10.1002/aisy.202400437","short":"sound-based-faraday","released":"April 16th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Sound-Based Robot Assembly","carousels":["Robotics","Nanotechnology","Audio Processing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"sound-based-assembly-of-magnetically-actuated-soft-robots-toward-enhanced-release-of-extracellular-vesicles"},{"title":"Case Report: Electroanatomic mapping as an early diagnostic tool in arrhythmogenic cardiomyopathy","description":"The heart’s electrical signals should be managed by the sinoatrial node, a small mass of specialized tissue located in the upper right atrium, a major traffic area. Oxygen depleted blood from all over the body passes through the vena cava into the right atrium. From this perch, the sinoatrial node sends out an electrical signal that initiates each heart beat. If PVCs are present, then something is happening to that electrical signal between its origin and its destination. Maybe an interception of the electrical signal from another tissue mass in the heart? Another signal location trying to take over the sinoatrial turf? Did it make any enemies recently? PVCs aren't necessarily life threatening, and in many cases, they don't warrant treatment. Her previous team however, decided to play it safe. They initiated a catheter ablation, the insertion of a catheter with a heating element to burn away any tissues that could be","sample":false,"doi":"10.3389/fcvm.2024.1392186","short":"case-report-mystery","released":"April 15th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Electroanatomic Mapping","carousels":["Medicine","Cardiovascular Disease"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"case-report-electroanatomic-mapping-as-an-early-diagnostic-tool-in-arrhythmogenic-cardiomyopathy"},{"title":"Evaluating and addressing demographic disparities in medical large language models: a systematic review","description":"On today’s episode we are going to talk about bias in Large Language Models (LLMs) used in medicine. In this paper, the authors conducted a systematic review of LLMs to see if they contained biases and which were most prevalent. We will first briefly talk about how these LLMs are being used in medicine and what seems promising about them. Next, we will dive into what human bias in medicine is, and how it can manifest in a Machine Learning model. We will then explore how the authors used the PRISMA guidelines and JBI Critical Appraisal Tools, and what they found. Last, we will mention some mitigation tools that can help reduce bias in AI. It seems like everywhere you look there is a new AI tool promising to make your life better and easier. It’s no different for healthcare professionals. Healthcare systems tend to be low on resources, with overworked doctors and nurses being the norm. In terms of time, well, speeding up","sample":false,"doi":"10.1186/s12939-025-02419-0","short":"llm-medical-bias","released":"April 14th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Medical LLM Biases","carousels":["Medicine","Largel Language Models","Natural Language Processing","Model Training"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"evaluating-and-addressing-demographic-disparities-in-medical-large-language-models-a-systematic-review"},{"title":"Application of Forced Oscillation Technique in Assessing Pulmonary Fibrosis in Hermansky-Pudlak Syndrome","description":"Hermansky-Pudlak Syndrome (HPS) is a rare hereditary condition characterized by genetic mutations impacting Lysosome Related Organelles (LRO). One of the deadliest manifestations of HPS is the development of scarring in the lung tissue called pulmonary fibrosis. Early detection can significantly improve a patient’s quality of life, but many of the early warning signs don't present themselves to the standard clinical technique. Are there other, more specialized tools that might help here? In today's episode, we'll look at research that evaluates a specialized clinical tool called the Forced Oscillation Technique (FOT) as a promising early detection tool for pulmonary fibrosis. We’ll explore pulmonary fibrosis in HPS, how it is clinically diagnosed and why the current methods need an overhaul. Then we’ll see how the authors evaluated the forced oscillation technique in patients with HPS to see if it can improve clinical","sample":false,"doi":"10.3390/arm92060040","short":"forced-oscillation","released":"April 13th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Forced Oscillation","carousels":["Medicine","Chronic Puliminary Disease"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"application-of-forced-oscillation-technique-in-assessing-pulmonary-fibrosis-in-hermansky-pudlak-syndrome"},{"title":"Active robotic search for victims using ensemble deep learning techniques","description":"Could you find a needle in a haystack? Sounds impossible right? Now imagine the needle is a person, and the haystack is a collapsed building. Now the question is no longer can you find the needle, it’s when will you find the needle. But what if a robot could do it for you, and do it with your thought process, and your sense of urgency? That’s the challenge that search and rescue (SAR) teams face with every natural disaster that occurs, which, by the way, is happening more frequently than ever. According to recent data, since the year 2000, the number of natural disasters has shifted from 300 to around 450 events per year. With it comes the need for more efficient, reliable, and safe ways to find survivors trapped in disaster zones. The stakes are high, and the terrain is often too dangerous for human rescuers. So, once again, we ask the question: can robots do the job for us?","sample":false,"doi":"10.1088/2632-2153/ad33df","short":"active-robotic-search","released":"April 12th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Search and Rescue Robots","carousels":["Disasters","Robotics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"active-robotic-search-for-victims-using-ensemble-deep-learning-techniques"},{"title":"National fisheries restricted areas: an alternative tool for the sustainable management of Black Sea vulnerable and economically important fish populations","description":"According to the latest data from the General Fisheries Commission for the Mediterranean, over half of the fish stocks in the Mediterranean and Black Sea are currently overexploited. Despite a decade of conservation efforts, sustainable fisheries management remains challenging. Traditional Marine Protected Areas (MPAs) aren't always effective for both biodiversity conservation and fisheries management, so alternative approaches are needed. Now, you might be thinking, “doesn't the Black Sea already have fishing restrictions?” Well, yes and no. There's a large Fisheries Restricted Area covering 1.76 million square kilometers in the Mediterranean and Black Seas, but there's a critical problem: it only applies to waters deeper than 1,000 meters. This is completely irrelevant for the Black Sea, which below 200 meters becomes anoxic, meaning there’s no oxygen and thus it is essentially lifeless. All Black Sea fishing activity is","sample":false,"doi":"10.3389/fmars.2025.1570936","short":"national-fisheries","released":"April 11th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Protected Zones","carousels":["Ecology","Agriculture","Aquaculture","Environmental Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"national-fisheries-restricted-areas-an-alternative-tool-for-the-sustainable-management-of-black-sea-vulnerable-and-economically-important-fish-populations"},{"title":"Evaluation of efficacy and safety of coenzyme Q10 in pediatric hemodialysis patients: a randomized controlled trial","description":"Today we will look at hemodialysis (HD), and the impact that it has on the body. We will focus on the oxidative stress and inflammation experienced by HD patients and how this is currently being addressed. The authors of today's paper set up a randomized control trial to determine if the positive effects of coenzyme Q10 in adult HD patients would translate to the pediatric population. If your kidneys are functioning badly, and resources allow for it, you get HD. HD is a treatment for kidney failure that uses a machine, and a special filter called a dialyzer to clean your blood. It acts like an artificial kidney. So, how does this work? First, an arteriovenous fistula or graft would be surgically inserted into your arm. This implant of sorts is used to connect your bloodstream to the dialysis machine without puncturing your veins and arteries with large gauge needles every time you need HD. The machine connects to you with two","sample":false,"doi":"10.1186/s43094-024-00752-9","short":"pediatric-hemodialysis","released":"April 10th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Coenzyme Q10","carousels":["Medicine","Pharmacology","Chronic Disease","Chronic Liver Disease"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"evaluation-of-efficacy-and-safety-of-coenzyme-q10-in-pediatric-hemodialysis-patients-a-randomized-controlled-trial"},{"title":"Lessons from national biobank projects utilizing whole-genome sequencing for population-scale genomics","description":"In 2003, after 13 laborious years (and even more including its conception) the Human Genome Project declared that the first human genome was sequenced (well 92% of it, but that is pretty complete all things considered). Today, a mere 20 years later, genome sequencing can be done in well under a day. This leap in technology has allowed us to scale up genomic studies to unprecedented levels. Now the real question stands, what can be done with this incredible technology to improve our lives? Well, in terms of medicine, quite a lot! As genomics technology gets cheaper, better, and faster, it has allowed nations to apply whole-genome sequencing (WGS) to very large projects. These are called national biobank projects. They are collecting hundreds-of-thousands to millions of samples in order to expand our understanding of human genetic information and how it relates to our health. National biobank projects are special because they work to","sample":false,"doi":"10.1186/s44342-025-00040-9","short":"national-biobanks","released":"April 9th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Genomic Biobanks","carousels":["Genetics","Public Health","Medicine"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"lessons-from-national-biobank-projects-utilizing-whole-genome-sequencing-for-population-scale-genomics"},{"title":"The Reliever Reliance Test: evaluating a new tool to address SABA over-reliance","description":"You’re short of breath, and a little light headed. Your chest feels tight, and you can feel that familiar wheezing fit starting to come on. You know what to do. Rummage through your bag until you find it. There it is. Remove the cap, shake it a little, try to breathe out, then put it to your lips. Breathe in, as you press down on the little canister. Hold your breath for a few seconds, and wait. Did it work? If not, try another round. If you suffer, or have ever suffered from asthma, I’m sure this sounded familiar. At times your SABA inhaler just might have been your best friend. Unfortunately, as we’ll explore in today's episode, overusing it has consequences. It might not be helping in the long run, it might actually be slowly making things worse. For many, the use of SABA is more than a medicine, it’s a ritual. But, if a ritual isn’t helping us, then it needs to change. But how? What is the","sample":false,"doi":"10.1038/s41533-024-00389-4","short":"reliever-reliance-test","released":"April 8th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"The Reliever Reliance Test","carousels":["Medicine","Chronic Disease","Chronic Pulimnary Disease"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-reliever-reliance-test-evaluating-a-new-tool-to-address-saba-over-reliance"},{"title":"Atomic Force Microscopy (AFM) nanomechanical characterization of micro- and nanoplastics to support environmental investigations in groundwater","description":"Current spectroscopic techniques like Raman spectroscopy, Fourier Transform Infrared Spectroscopy and Laser Direct Infrared are excellent for analyzing the exact chemical composition of the microplastics, but they cannot give accurate quantitative measurements for particles smaller than 10 micrometers. This leaves out nanoplastics altogether! Not only that, the current detection techniques have a high uncertainty when the micro-nanoplastics form a hetero-aggregate. Let’s go into that in more detail. Raman spectroscopy, Fourier Transform Infrared Spectroscopy and Laser Direct Infrared operate in different ways, but principally they have some big similarities: 1. They send out a beam of light or infrared radiation to the sample. 2. Some wavelengths of light are absorbed by the sample to generate what we call a “spectrum”, a unique fingerprint of the sample. 3. This unique spectrum can be compared against a database of many known","sample":false,"doi":"10.1016/j.emcon.2025.100478","short":"atomic-force-microscopy","released":"April 7th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Atomic Force Microscopy","carousels":["Environmental Science","Nanotechnology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"atomic-force-microscopy-afm-nanomechanical-characterization-of-micro--and-nanoplastics-to-support-environmental-investigations-in-groundwater"},{"title":"Continuous lipreading based on acoustic temporal alignments","description":"While visual cues help for understanding speech, research has found that only 30% of speech information is visible. Differences in the facial movements between individuals only makes it more complex. This means that VSR will, by default, be less accurate than a system that only uses audio. Nonetheless, VSR has progressed substantially. Most of the recent technologies for VSR have relied on end-to-end deep learning models. These models require enormous amounts of training data and substantial computational resources. In some cases, these prerequisites are not available. This is especially true when developing VSR for languages that do not have ample video content for training. So this brings us to the crux of the issue, how do you make an effective Visual Speech Recognition model when you don’t have very much training data? In today’s article, the researchers are trying to do just that. They’re trying something new","sample":false,"doi":"10.1186/s13636-024-00345-7","short":"lip-reading","released":"April 6th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Acoustic Temporal Alignments","carousels":["Audio Processing","Assistive Technology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"continuous-lipreading-based-on-acoustic-temporal-alignments"},{"title":"A Review on Recent Trends of Bioinspired Soft Robotics: Actuators, Control Methods, Materials Selection, Sensors, Challenges, and Future Prospects","description":"Nature has been the main design guide here. Jellyfish, snails, inchworms, even plants and fish, all have unique motion strategies and material compositions that inspire different types of soft robots. Researchers are now trying to mimic these movements, not just for fun, but for practical applications like minimally invasive surgery, search and rescue, wearable tech, and agricultural assistance. Now, to actually move these soft robots, you need an actuator. But here’s the thing, we can’t just strap a motor onto a blob of gel and hope it’ll crawl. Soft actuators need to be, well, soft, but still generate movement, ideally with enough force and precision to be useful. This is where things get interesting. One approach is to use Shape Memory Alloys (SMAs), metals that “remember” their shape and return to it when heated. You may have seen a video of this before. In one, a paper clip is stretched out, smoothed into a strand of wire and","sample":false,"doi":"10.1002/aisy.202400414","short":"bioinspired-soft-robotics","released":"April 5th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Shape Memory Alloys","carousels":["Robotics","Nanotechnology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-review-on-recent-trends-of-bioinspired-soft-robotics-actuators-control-methods-materials-selection-sensors-challenges-and-future-prospects"},{"title":"AI-driven diagnostics and personalized treatment planning in oral oncology: Innovations and future directions","description":"A CNN is a type of neural network that is particularly well-suited to image analysis. Like our brains, it’s made up of neurons that relay information back and forth to other neurons in the network as it analyzes the image. It can be trained to accurately detect a specific object in an image, like a cancer tumor in an oral MRI. It can also be trained to differentiate between objects, like lesions and non cancerous sores based on the image's features. These features are distinguishing characteristics of what you want the CNN to learn to recognize. Information is visually broken up into pixels, and each neuron in the network analyzes a small portion of the image. Now, imagine a loaf of bread, pre-sliced. Each slice of bread represents a group of neurons, or a layer. The end pieces are the input layer and output layer respectively. The input being an image you want the CNN to analyze, and the output being the CNNs prediction as to what","sample":false,"doi":"10.1016/j.oor.2024.100704","short":"ai-driven-diagnostics","released":"April 4th 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"A.I. Driven Diagnostics","carousels":["Convolutional Neural Networks","Medicine","Oncology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"ai-driven-diagnostics-and-personalized-treatment-planning-in-oral-oncology-innovations-and-future-directions"},{"title":"Life on the edge: A new toolbox for population-level climate change vulnerability assessments","description":"Not every animal species is going to survive climate change. For any one species to survive, they need two things: a location that will remain hospitable to life, and a genome that is pre-adapted to the changes to come. Just as humans living in different environments possess genetic adaptations to their environment like melanin in the skin or malaria resistance in the blood, animal populations within the same species often differ in subtle ways that make them better adapted to their environment. Some might be better adapted to warming temperatures while others might have genetic advantages that help them cope with drought. Is it possible to identify which populations of a species are most likely to make it through the next few decades? If so, we can focus our conservation efforts on amplifying their adaptive genes in the species. Today, we’ll be looking at a new toolbox called “Life on the Edge”, or LotE, integrating genomic","sample":false,"doi":"10.1111/2041-210X.14429","short":"lote-toolbox","released":"April 3rd 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Life on the Edge","carousels":["Climate Science","Environmental Science","Genetics","Statistics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"life-on-the-edge-a-new-toolbox-for-population-level-climate-change-vulnerability-assessments"},{"title":"Simultaneous assessment of mitochondrial and vascular function using the Flow Mediated Skin Fluorescence technique","description":"In order for a diagnostic method to stand out, we need a method that has a standard unit of measure that is specific and reliable. Flow Mediated Skin Fluorescence (FMSF) can potentially fill this gap. While it has certain disadvantages, new research is finding ways to work around them. Previously, one of the main disadvantages was that FMSF failed to differentiate between vascular and mitochondrial dysfunction. But, in this paper, the authors managed to distinguish one from the other. Let’s dive in to see how this was done. So what is FMSF? It is a non-invasive test that evaluates microcirculation by detecting changes in skin fluorescence. Fluorescence is a phenomenon that occurs when light is absorbed by a molecule and then re-emitted as a different color. This happens because the light absorption excites the electrons in the molecule which causes it to glow. Nicotinamide Adenine Dinucleotide (NAD) is a coenzyme that exists in two","sample":false,"doi":"10.3389/fphys.2025.1509159","short":"vascular-function-fmsf","released":"April 2nd, 2025","instagram":"","image":"","mp3":"","journal":"Frontiers in Physiology","author":"Marcinek","university":"Lodz University of Technology","country":"Poland","lead":"In this paper they introduce us to a diagnostic tool that uses the fluorescent nature of metabolic coenzymes to determine microvascular health.","host":"Kristi Clayton","producers":"Luis Lopez","writers":[],"thumbnailTitle":"Skin Fluorescence","carousels":["Medicine","Diagnostic Medicine"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"simultaneous-assessment-of-mitochondrial-and-vascular-function-using-the-flow-mediated-skin-fluorescence-technique"},{"title":"Livestock guardian dogs establish a landscape of fear for wild predators: Implications for the role of guardian dogs in reducing human–wildlife conflict and supporting biodiversity conservation","description":"Risk-sensitive foraging is a behavioral response to a “landscape of fear” that is created when a competing predator is in an area, like coyotes and wolves for example. In this case the “competing predators” are livestock guardian dogs. The weaker predator must always be aware of their surroundings for fear of being attacked and even killed, so they will usually reduce how much they forage (which means looking for food, scavenging, and hunting). Basically the predator asks itself “is attempting to eat a juicy sheep worth the risk of being killed by 3 giant sheepdogs? Probably not.” We can measure risk-sensitive foraging with a thing called giving up density (GUD). This is how willing an animal is to stay in one place in order to get more food. The idea is this: if they are in a high risk area, they will forage for less time. Alternatively, if there is lower risk, they will spend as long as they can getting more food.","sample":false,"doi":"10.1002/2688-8319.12299","short":"livestock-guardian-dogs","released":"April 1st, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Livestock Guardian Dogs","carousels":["Biodiversity","Agriculture","Livestock","Ecology","Wildlife"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"livestock-guardian-dogs-establish-a-landscape-of-fear-for-wild-predators-implications-for-the-role-of-guardian-dogs-in-reducing-humanwildlife-conflict-and-supporting-biodiversity-conservation"},{"title":"Temperature-Tunable Cholesteric Liquid Crystal Optical Combiners for Extended Reality Applications","description":"In the XR world, in order to augment reality, most head-mounted devices use what’s called a Near-Eye Display (NED) system. For AR devices, this NED is paired with an optical combiner (OC). The job of an OC is to reflect computer-generated images into your eye while allowing real-world light to pass through. Prism optics, waveguides, and Freeform lens systems are the usual suspects here, and each has its pros and cons. Prisms are light and cheap, but they give you a narrow field of view (FOV). Waveguides are sleek but struggle with chromatic aberration and light loss. And freeform optics offer great visuals but tend to be bulky and thick. Across the board, these systems are fundamentally static. They lack real-time adaptability. Want to switch from full immersion to light overlay or no overlay at all? Well, you're out of luck. So what if the optical layer itself could be made to change? What if you could “tune” it in real","sample":false,"doi":"10.1002/aisy.202400411","short":"temperature-tunable-clcs","released":"March 31st, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Cholesteric Liquid Crystals","carousels":["Extended Realtive","Virtual Reality","Augmented Reality"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"temperature-tunable-cholesteric-liquid-crystal-optical-combiners-for-extended-reality-applications"},{"title":"Audio Deep Fake Detection with Sonic Sleuth Model","description":"In 2020, a bank manager in Hong Kong received a call. It was from the senior director of a company that regularly did business with the bank. The person explained that the company was about to make a major acquisition, and he requested $35 million to be transferred to the seller's account. The money was sent, and everything seemed normal. Not long after, the bank employee was shocked to learn that he had not spoken to the director at all. He had fallen victim to a Deepfake scam. Today we’ll look at how researchers are trying to stay ahead of the growing threat of Deepfake audio using a new AI detection model called Sonic Sleuth. We’ll look at how they created the model, what feature extraction tools were most effective, and if Sonic Sleuth might help us determine the difference between real and fake. Before we look at the model, let’s talk about what makes Deepfake audio so dangerous and hard to detect.","sample":false,"doi":"10.3390/computers13100256","short":"sonic-sleuth","released":"March 30th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Audio Deep Fakes","carousels":["Deep Fakes","Generative A.I.","Audio Processing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"audio-deep-fake-detection-with-sonic-sleuth-model"},{"title":"Stochastic resetting mitigates latent gradient bias of SGD from label noise","description":"Consider training a language model on a corpus where shorter sentences are overrepresented. If the model updates its parameters using mini-batches drawn randomly from the full dataset, shorter and syntactically simpler examples will dominate the early gradient estimates. These examples might favor certain token predictions or structural patterns that are not representative of the broader language distribution. As a result, the model parameters will be nudged in directions that overfit these simpler forms. This doesn’t just introduce noise, it creates a directional bias in the gradient field, pulling the optimization process toward a region that minimizes loss on an unbalanced subset of the data. Even as training continues and more varied examples appear, the model may be stuck in a basin shaped by these early biases. This phenomenon, while hard to detect in raw training curves, has been observed in practice in domains like","sample":true,"doi":"10.1088/2632-2153/adbc46","short":"stochastic-resetting","released":"March 29th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Stochastic Resetting","carousels":["Model Training","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"stochastic-resetting-mitigates-latent-gradient-bias-of-sgd-from-label-noise"},{"title":"Recent Advances in Graphene-Based Membranes with Nanochannels and Nanopores","description":"Draw 6 dots in the shape of a hexagon, and connect the dots with a line. Now draw the same hexagon next to that hexagon, so that they tessellate (fit together with no gaps between them). Keep growing your hexagons up down and side to side until it resembles a honeycomb lattice, or chicken wire. Congratulations! You’ve drawn graphene. Each dot represents a carbon atom and each line is the covalent bond between them. How do you even make a material that's 1 atom layer thick? The answer is surprisingly simple: scotch tape. Professor Sir Konstantin Novoselov (Kostya) was a PhD student working under Professor Sir Andre Geim at the University of Manchester in 2004 when they made a surprising discovery. Geim encouraged the lab group to spend Friday afternoons playing around with different research ideas. One such idea involved trying to isolate a material that was just 1 atom layer thick. Here’s how they did it: They obtained a lump of","sample":false,"doi":"10.1002/sstr.202400320","short":"graphene-nanopores","released":"March 28th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Graphene Based Membranes","carousels":["Graphene","Nanotechnology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"recent-advances-in-graphene-based-membranes-with-nanochannels-and-nanopores"},{"title":"Data-Driven Molecular Typing: A New Frontier in Esophageal Cancer Management","description":"Esophageal cancer is extremely hard to treat due in large part to one particularly diabolical factor, tumor heterogeneity. As you might imagine, tumors are not all the same. With a wide variety of cancer types, it would stand to reason that there would be variety in tumors. That would be an understatement. ESCC tumors can vary wildly from one another. Take for example a patient with esophageal cancer with two malignant tumors. These tumors may have variations in cell compositions, DNA, and protein expression. Even if both tumors were caused by the same genetic mutation in the host DNA, they may develop completely different cell structures, express completely different biomolecules and even have different types of additional genetic mutations. The tumors may also react to treatments differently, putting stress on patients and increasing the potential for the cancer to return. On top of these variations, recent studies have","sample":false,"doi":"10.1002/cam4.70730","short":"molecular-typing","released":"March 27th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Molecular Typing","carousels":["Oncology","Medicine","Data Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"data-driven-molecular-typing-a-new-frontier-in-esophageal-cancer-management"},{"title":"Internet of Paint (IoP): Design, Challenges, Applications and Future Directions","description":"The researchers performed a channel capacity analysis, a test to determine the theoretical maximum rate at which information can be transmitted, measured in bits per second. To calculate the overall channel capacity for THz transceivers in paint, the total bandwidth is divided into narrow sub-bands, and their individual capacities are aggregated. This is possible due to the high frequency selectivity at THz frequencies; in other words, the system is capable of responding to specific frequencies while ignoring others. The division into sub-bands is also helpful to mitigate potential interference from non-white molecular noise, which varies across the frequency spectrum. In the simulation, they used a 2 mm thick layer of “Titanium white” paint; this is thicker than most paint layers and was used to represent a worst-case scenario. They then modeled three different transceiver burial depths, 0.5 mm, 1 mm, and 1.95 mm and checked","sample":false,"doi":"10.1109/ACCESS.2025.3539121","short":"internet-of-paint","released":"March 26th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Internet of Paint","carousels":["Nanotechnology","Electromagnetic Spectrum","Telecommunications"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"internet-of-paint-iop-design-challenges-applications-and-future-directions"},{"title":"An evolutionary game theory analysis on the environmental impact of discharging Fukushima’s nuclear wastewater: International stakeholders and strategic dynamics","description":"In classic game theory, players make rational decisions based on perfect information. But in real life, especially in complex environmental crises, information is limited, and rationality is bounded. That's where evolutionary game theory excels. It acknowledges that players don't instantly arrive at optimal strategies but rather adapt their approaches over time based on what they learn. The researchers created a model that gives each player two options: Japan can choose to either discharge the wastewater, or not. Other countries can choose to sanction Japan, or not. The JFA can choose to support the Japanese government, or not. Each choice carries costs and benefits. For Japan, discharging wastewater reduces storage costs but could damage their international image and lead to potential economic penalties. Other countries might gain political points by sanctioning Japan but doing so could disrupt valuable trade relationships. The JFA could","sample":false,"doi":"10.1371/journal.pone.0317419","short":"game-theory-analysis","released":"March 25th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Evolutionary Game Theory","carousels":["Political Science","Environmental Science","Disasters"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-evolutionary-game-theory-analysis-on-the-environmental-impact-of-discharging-fukushimas-nuclear-wastewater-international-stakeholders-and-strategic-dynamics"},{"title":"Human-in-the-loop transfer learning in collision avoidance of autonomous robots","description":"For a long time, pure reinforcement training has been the go-to method. It works by rewarding correct actions and penalizing incorrect ones, encouraging the model to maximize positive outcomes over time. More recently, Reinforcement Learning from Human Feedback has helped improve training time and alignment with human preferences, predictions, and judgment. Chatbots like ChatGPT, Claude, and Gemini have used this method to refine their conversational abilities over time. Early chatbot responses were factual but often rude or confusing. In the world of autonomous vehicles, self-driving cars also require a level of knowledge that allows them to overcome small unpredictable obstacles that were never incorporated into the training dataset. By incorporating human feedback, AI models could become more natural and intuitive. In most RLHF systems, you’d train your model first and then provide feedback to it after it’s already up and running. The authors did something different: they built a system that could provide a form of “pre-feedback” to the model well before training had taken place. So rather than","sample":true,"doi":"10.1016/j.birob.2025.100215","short":"hitl-transfer-learning","released":"March 24th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Collision Avoidance","carousels":["Autonomous Vehicles","Reinforcement Learning","Human in the Loop"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"human-in-the-loop-transfer-learning-in-collision-avoidance-of-autonomous-robots"},{"title":"Validation of a tele-robotic ultrasound system for abdomen and thyroid gland explorations: a comparison with standard ultrasound","description":"An in-person ultrasound involves a patient lying in various positions to optimally target the organs or body region to be screened. The sonographer holds a transducer, a device that looks like a cross between a universal TV remote and a grocery store check out scanner. The transducer makes contact with the skin, and sends the soundwaves into the body, where they bounce off soft tissues. The echo bounces back and is received by the transducer, which sends that information back to a computer to generate the images. A gel is applied to the region of the body that the scanner will touch to allow smooth movement of the transducer along the skin, and to eliminate any air pockets (between the skin and the device) that might interfere with the sound waves. Some scans can be as short as five minutes, while others can last thirty minutes. That's a lot of time to be in intimate proximity with anyone, let alone someone","sample":false,"doi":"10.1186/s13089-025-00408-6","short":"tele-robotic-ultrasound","released":"March 23rd, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Telerobotic Ultrasound","carousels":["Medicine","Diagnostic Medicine"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"validation-of-a-tele-robotic-ultrasound-system-for-abdomen-and-thyroid-gland-explorations-a-comparison-with-standard-ultrasound"},{"title":"Voxel Volumes and Biomass: Estimating Vegetation Volume and Litter Accumulation of Exotic Annual Grasses Using Automated Ultra-High-Resolution SfM and Advanced Classification Techniques","description":"In the last few years, LiDAR and Structure from Motion photogrammetry (SfM) have made progress in terms of quantifying biomass in dryland ecosystems. Unfortunately, we still need things at a finer scale, especially when it comes to grasslands. In grasslands, plants are thin and tall, grow densely packed, and have a lot of built up litter. These factors make it necessary to have high-resolution tools that allow us to create an accurate 3D rendering of the plants in an area. The existing systems work by taking images and generating a kind of 3D landscape called a point cloud. The data in the point cloud can then help us calculate the parameters necessary to estimate AGB. But, how accurate are they? Before we ask that question, let’s explain how these remote sensing systems work. LiDAR is considered active remote sensing. It works by emitting laser pulses and measuring the time it takes for them to return. This can create precise","sample":false,"doi":"10.1002/ece3.70883","short":"voxel-volumes","released":"March 22nd, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Voxel Volumes","carousels":["Ecology","Biomass","LiDAR","Point Clouds","3D Mapping","Voxels"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"voxel-volumes-and-biomass-estimating-vegetation-volume-and-litter-accumulation-of-exotic-annual-grasses-using-automated-ultra-high-resolution-sfm-and-advanced-classification-techniques"},{"title":"AlphaBoot: accelerated container cold start using SmartNICs","description":"An NIC or Network Interface Card, does exactly what its name suggests. It manages a device's network connection, letting it connect, share resources, and communicate either locally or remotely. A smartNIC goes a step further, it does all of that and more. They are designed to handle high-traffic operations and they come with features like packet processing, load management, and programmable processing units. These units are capable of running custom applications. Traditionally, some networking tasks placed a heavy burden on a server’s processing power. With SmartNIC’s acting as intelligent offload engines, these functions can now be handled directly at the network interface, freeing up computational power for other critical operations. So why is this important? Well, most solutions to the cold start problem have been tackled at the server level, by throwing more CPU and GPU at the problem. But, even with","sample":false,"doi":"10.3389/fhpcp.2025.1499519","short":"cold-start-smartnics","released":"March 21st, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Accelerated Cold Start","carousels":["Containers","Network Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"alphaboot-accelerated-container-cold-start-using-smartnics"},{"title":"Audio-as-Data Tools: Replicating Computational Data Processing","description":"In 1952, Bell Labs first developed Audrey, a system that could transcribe spoken numbers. In the 1980s, the development of the Hidden Markov Model created systems that were capable of recognizing thousands of words. This evolved into what is called the “hybrid approach,” in which three models, a lexicon model, an acoustic model, and a language model were forced into alignment to generate a more accurate transcription. With the advent of deep learning, we're able to directly map input audio to text with greater speed and higher accuracy. However, when it comes to recordings, getting an accurate transcription is only half of the picture. Recorded speech contains a variety of non-textual information, such as tone, loudness, or even accents. The field of audio processing has been evolving in parallel to these transcription tools. In today's paper, the authors took a look at a variety of modern tools for analyzing speech. They placed the","sample":false,"doi":"10.17645/mac.7851","short":"audio-as-data","released":"March 20th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Audio as Data","carousels":["Audio Processing","Data Science","Speech to Text"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"audio-as-data-tools-replicating-computational-data-processing"},{"title":"Light-Programmable g-C3N4 Microrobots with Negative Photogravitaxis for Photocatalytic Antibiotic Degradation","description":"Last summer, as the Olympic games came to Paris, all eyes were on the Seine. It was filthy. Years of untreated wastewater overflowing into the river had left it full of so much bacteria and so many viruses that it was genuinely dangerous for the athletes to jump in. And sewage wasn’t the only problem. The river was also full of antibiotics. Over a dozen different types were found in the waters. This isn’t just a problem in France. It’s far more widespread. Every major waterway suffers from this kind of contamination. But what are we to do about it? Treatment plants aren’t doing their job. Chemicals aren’t going to help. So what other options are on the table? Ideally we need teeny tiny machines that can swim around, cleaning up rogue antibiotics, and keeping rivers clear. Microrobots! In this paper, that’s exactly what these researchers came up with! In this episode of journal club, we’ll be looking at how they designed and built","sample":false,"doi":"10.34133/research.0565","short":"light-programmable-microrobots","released":"March 19th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DHr1BV_sZFn/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Light Programmable Microrobots","carousels":["Nanotechnology","Microtechnology","Antibiotics","Pharmacology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"light-programmable-g-c3n4-microrobots-with-negative-photogravitaxis-for-photocatalytic-antibiotic-degradation"},{"title":"End-to-end deep learning pipeline for real-time Bragg peak segmentation: from training to large-scale deployment","description":"This story takes place at what is called an XFEL facility. In an XFEL (which stands for X-ray Free Electron Laser) lab, researchers regularly fire ultrafast, high-intensity X-ray pulses at microscopic crystals to determine their atomic structure. A core part of that process is, as I mentioned, Bragg Peak detection. A Bragg Peak is a bright spot in a diffraction pattern. It’s formed when X-rays scatter off a crystal’s atomic lattice and interfere constructively at specific angles, in accordance with something called Bragg’s Law (thus the name). These peaks hold the key to determining a crystal’s atomic structure because their positions and intensities reveal how X-rays interact with the crystal at the atomic level. A modern XFEL can produce up to a million images per second, and they all need Bragg Peak detection run on them. But there's the problem: it can't handle that kind of speed and scale. Why? Well, existing","sample":false,"doi":"10.3389/fhpcp.2025.1536471","short":"bragg-peak","released":"March 18th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Bragg Peak Segmentation","carousels":["Microtechnology","Materials Science","Electromagnetic Spectrum"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"end-to-end-deep-learning-pipeline-for-real-time-bragg-peak-segmentation-from-training-to-large-scale-deployment"},{"title":"Combining Static Analysis With Directed Symbolic Execution for Scalable and Accurate Memory Leak Detection","description":"Memory leaks occur when dynamically allocated memory is never properly released. This leads to gradual accumulation of inaccessible memory that cannot be reclaimed by the operating system. This is particularly problematic in C and C++, where memory management is manual, meaning there’s typically no automatic garbage collection in most implementations of those languages. So developers must explicitly allocate memory using functions like “malloc” or “new” and then free it with “free” or “delete”. When memory is allocated but never freed, it remains reserved for the duration of the program's execution, even if it is no longer reachable. Over time, this results in progressively increasing memory usage. If you’re watching the memory utilization on a computer executing this kind of program you can literally see it creeping up little by little over time. Eventually this leads to performance degradation and, in the worst cases","sample":false,"doi":"10.1109/ACCESS.2024.3409838","short":"static-analysis-memory-leak","released":"March 17th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Memory Leak Detection","carousels":["Software Engineering","Continuous Integration","Debugging"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"combining-static-analysis-with-directed-symbolic-execution-for-scalable-and-accurate-memory-leak-detection"},{"title":"New frontiers in CRISPR: Addressing antimicrobial resistance with Cas9, Cas12, Cas13, and Cas14","description":"We are running low on solutions to combat superbugs. Rather than sticking with antibiotics, we’re starting to turn our gaze towards gene therapies. To this end, the authors of this paper have reviewed the latest applications of CRISPR: Clustered Regularly Interspaced Short Palindromic Repeats. They’re looking specifically at how it can be used to modify the genes of superbugs and make them more susceptible to antibiotics. Today on Journal Club, we will be talking about antimicrobial resistance (AMR), what CRISPR is, and why CRISPR could be the ultimate weapon in this battle. In 2016, a 70-year-old from Nevada died in the hospital, overcome by an infection from the bacteria Klebsiella pneumoniae. Why is this significant? The specific strain of Klebsiella had evolved into a superbug. It had developed resistance to all the antibiotics available in the United States. This means that no known medication was capable of","sample":false,"doi":"10.1016/j.heliyon.2025.e42013","short":"crispr-amr","altLink":"https://www.cell.com/heliyon/fulltext/S2405-8440(25)00393-7","released":"March 16th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"CRISPR Frontiers","carousels":["CRISPR","Genetics","Antibiotics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"new-frontiers-in-crispr-addressing-antimicrobial-resistance-with-cas9-cas12-cas13-and-cas14"},{"title":"Non-traditional data to inform modern climate science","description":"Aerosol optical depth or (AOD), is the metric for measuring the density of aerosols in the atmosphere. The AOD is determined by measuring the amount of light scattered or absorbed by aerosols; in other words, how much direct sunlight is prevented from reaching the ground. Lower values below 0.05 indicate a clear sky, whereas an AOD above 2 or 3 indicates a high particle concentration. The AOD is measured globally through an array of satellites equipped with radiometers (sensors that measure the intensity of radiant energy). By comparing how the AOD changes at various wavelengths of light, these satellites can also determine the Ångström Exponent, a measurement of particle size. When the effects of aerosol are substantially different for red and blue wavelengths, the resulting Ångström Exponent is higher. Lower exponent values typically indicate natural aerosols such as sea spray or mineral dust, whereas higher values often","sample":false,"doi":"10.3389/fcomm.2025.1518768","short":"nt-climate-data","released":"March 15th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Non-Traditional Climate Science","carousels":["Climate Science","Environmental Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"non-traditional-data-to-inform-modern-climate-science"},{"title":"WGO: a similarly encoded whale-goshawk optimization algorithm for uncertain cloud manufacturing service composition","description":"Similar Integer Coding incorporates an awareness of service similarity. Instead of treating each service as an entirely distinct option, this approach groups services with comparable QoS attributes into clusters before assigning integer codes. These clusters are formed based on a similarity measure, specifically cosine similarity, which evaluates how close two services are in terms of key performance metrics. Cosine similarity is a mathematical technique that measures the angle between two vectors in a multi-dimensional space, rather than their absolute distance. In the context of service composition, each service can be represented as a vector of its QoS attributes, where each attribute (execution time, cost, reliability) corresponds to a dimension. The cosine similarity score between two services is computed as the dot product of their vectors divided by the product of their magnitudes, resulting in a value between -1 and 1. A similarity","sample":false,"doi":"10.1007/s43684-025-00089-x","short":"wgo-manufacturing","released":"March 14th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Whale Goshawk Algorithm","carousels":["Cloud Computing","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"wgo-a-similarly-encoded-whale-goshawk-optimization-algorithm-for-uncertain-cloud-manufacturing-service-composition"},{"title":"Portable Solar-Integrated Open-Source Chemistry Lab for Water Treatment with Electrolysis","description":"To understand how it works, and what benefit it has to our environment, we need to look at the basics. Two electrodes: an anode and a cathode, are placed into a water source. Let’s use a jar as an example. Each electrode is connected to a power source, with the anode attached to the positive terminal and the cathode to the negative. When power is supplied, a reaction occurs, splitting the water into its two elements: hydrogen and oxygen. The hydrogen is captured, while the oxygen is either stored or released into the atmosphere. This entire process is known as green hydrogen production, and when applied to wastewater, it provides a viable way to create a clean fuel source from water that would otherwise be discarded. But there are two major challenges with this process. First, chemical reactions that can occur in wastewater can produce hazardous gases beyond just hydrogen and oxygen. Second, to test these processes effectively","sample":false,"doi":"10.3390/technologies13020057","short":"portable-electrolysis","released":"March 13th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Portable Electrolysis","carousels":["Environmental Science","Energy Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"portable-solar-integrated-open-source-chemistry-lab-for-water-treatment-with-electrolysis"},{"title":"DevOps Integration With Capability Model Maturity Integration: A Systematic Mapping Review","description":"The year was 1986, and the Department of Defense had a problem. They were interviewing Software Development agencies in order to award contracts, and they needed a way to pick a winner. All the dev-shops interviewed quite well. They all had expansive portfolios. They’d all write very convincing proposals, they’d give impressive presentations, and they all seemed to know what they were doing. The issue was, the Department had been fooled in the past. Previous contractors had overstated their abilities. And many, it turned out, weren't actually capable of even a fraction of their claims. Given a contract, they’d try! They’d certainly try!...to build what was asked for, but they wouldn’t succeed. Instead, they’d miss deadlines, or deliver buggy applications, or just give up and abandon the project. So, the Feds were left with an interesting question: How do you evaluate a Software Engineering team that you just met? How do you","sample":true,"doi":"10.1109/ACCESS.2025.3542630","short":"devops-cmm","released":"March 12th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Capability Maturity Model","carousels":["Engineering Management","DevOps"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"devops-integration-with-capability-model-maturity-integration-a-systematic-mapping-review"},{"title":"Fully integrated wearable control system for micro/nanorobot navigation","description":"So how can we allow a surgeon to control nano-sized objects with precision and intuition, without the huge costs and steep learning curve? The authors of this study aimed to find out just that. A solution that incorporated a wearable device, an electromagnetic generator, and an AI planner, enabling 3 dimensional control of a nanorobot. This device needed to consistently extract physiological signals from the user while accurately maneuvering the robots in real time. The researchers proposed a Fully Integrated Wearable Control System (FIWCS) that detects surface electromyogram signals (sEMG) and gyroscopic rotations through gestures like waving and wrist rotations. They also incorporated a microphone to allow surgeons to initiate tasks using voice commands. Tests were then run using an optical microscope to monitor the speed, rotation and task execution. To understand the true scale of this innovation, we need to see how these nanorobots","sample":false,"doi":"10.1088/2631-7990/ada8e5","short":"wearable-nanorobots","released":"March 11th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Wearable Nanorobots","carousels":["Nanotechnology","Microtechnology","Nanorobots","Robotics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fully-integrated-wearable-control-system-for-micronanorobot-navigation"},{"title":"Beyond encryption: How deep learning can break microcontroller security through power analysis","description":"Side-channel attacks exploit unintended information-leakage from a system’s physical operations. These leaks can emerge in different forms, such as timing variations, electromagnetic emissions, or even acoustic signals. One of the most effective and well-documented forms of side-channel attacks is power analysis, which observes fluctuations in a device’s power consumption as it processes cryptographic operations. Every computational step, from simple arithmetic to complex encryption functions, requires electrical energy, and the precise way that energy is used can reveal patterns about the underlying operations. Power analysis attacks take advantage of these patterns to infer secret information, such as cryptographic keys, without needing to directly access the encrypted data. Traditional power analysis techniques include simple power analysis (SPA) and differential power analysis (DPA)","sample":false,"doi":"10.1016/j.prime.2025.100947","short":"beyond-encryption","released":"March 10th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Beyond Encryption","carousels":["Security","Microcontrollers"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"beyond-encryption-how-deep-learning-can-break-microcontroller-security-through-power-analysis"},{"title":"Strategies for specific multimodal imaging of cancer-associated fibroblasts and applications in theranostics of cancer","description":"In this episode, we’ll explore the innovative way that the authors harnessed the FAPI Nanoparticles to positively impact theranostics in cancer treatment. We’ll walk through what the FAPI Nanoparticle is, what makes it so useful, and how the researchers tested it. We’ll then discuss how it may be able to revolutionize the treatment of tumors. So let’s start this story by meeting another molecule that sits at the center of all of this. Fibroblasts activating protein, or FAP. Not FAPI, that’s something else. More on that later. FAP is a protein expressed on the outer membrane of close to 90% of the tumors growing on organs. These molecules have very specific molecular structures that are used to locate tumors in living tissue. In essence imaging technologies detect tumors in the body by looking for specific biomarkers like FAP that tumors express on their outer surfaces. Like sprinkles on a cake. FAP is such","sample":false,"doi":"10.1016/j.mtbio.2024.101420","short":"fibroblast-activating-protein","released":"March 9th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Multimodal Imaging","carousels":["Oncology","Medicine","Nanotechnology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"strategies-for-specific-multimodal-imaging-of-cancer-associated-fibroblasts-and-applications-in-theranostics-of-cancer"},{"title":"Data leakage detection in machine learning code: transfer learning, active learning, or low-shot prompting?","description":"Data leakage occurs during training, when information that should be unavailable to the model inadvertently influences its learning process. Think of it as contamination. Your testing/evaluation data somehow got into the training data. As you can guess, this can lead to overly optimistic performance metrics that do not translate into real-world effectiveness. This issue is particularly insidious because it masquerades as a highly successful model, with impressive training and validation results that collapse once the model is deployed. The problem is not that the model has failed to learn meaningful patterns, but rather that it has learned patterns it should never have had access to in the first place. As a result, the model does not actually generalize but instead exploits unintended shortcuts in the data. So how does this happen? There are several ways, and they stem from flaws in your data pipeline","sample":false,"doi":"10.7717/peerj-cs.2730","short":"data-leakage","released":"March 8th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Data Leakage in ML","carousels":["Model Training"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"data-leakage-detection-in-machine-learning-code-transfer-learning-active-learning-or-low-shot-prompting"},{"title":"A novel and fast crash simulation method: Revolutionizing racetrack safety barrier analysis","description":"In the fast-paced world of Formula One racing, engineers work tirelessly to construct a vehicle that can achieve the impossible, breakneck speeds with razor-sharp control and precision. Unfortunately, they’re being driven by humans. And humans make mistakes, so crashes are inevitable. To mitigate serious injuries, racetracks are lined with barriers meant to soften the impact of the crash. But how do we know if those barriers are good enough to save a driver’s life? Well, we test them, over and over again. Today, we’ll examine the testing procedures used on tire barriers at Formula 1 race tracks. We’ll start by looking at standard Finite Element (FE) simulations, then we’ll explore a novel Soft-Body physics simulation, and finally compare both to physical crash tests. Before diving in, we need to consider the scale of vehicle testing, especially in high-speed racing. We’ve all seen those advertisements where a","sample":false,"doi":"10.1016/j.rineng.2024.103870","short":"crash-test-simulation","released":"March 7th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DHut93HMH6t/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Racetrack Safety Analysis","carousels":["Physics","Simulations","Gaming Engines"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-novel-and-fast-crash-simulation-method-revolutionizing-racetrack-safety-barrier-analysis"},{"title":"Mosquito-derived ingested DNA as a tool for monitoring terrestrial vertebrates within a peri-urban environment","description":"Let’s say you have now collected some mosquitoes and preserved them. What’s next? Once DNA is collected from a substrate, in this case the blood that a mosquito had for lunch, that DNA must be extracted, amplified, sequenced, and compared against genomes that we already know. A popular method for DNA amplification is PCR. In PCR (Polymerase chain reaction): Extracted DNA is heated so that it separates into two strands. Short synthetic DNA fragments… called… primers are added. Using the primers as templates, desired DNA is amplified through multiple rounds of DNA synthesis. Once there is enough of the DNA it can be sequenced and we can figure out what it belongs to. So, let’s get into what the authors did and how it turned out. The authors set up light traps to collect mosquitoes and see what level of vertebrate diversity they could survey in just 4 nights. Mosquitos were","sample":false,"doi":"10.1002/ecs2.70163","short":"mosquito-derived-dna","released":"March 6th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Mosquito Derived DNA","carousels":["Ecology","Genetics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"mosquito-derived-ingested-dna-as-a-tool-for-monitoring-terrestrial-vertebrates-within-a-peri-urban-environment"},{"title":"Temporal Relation Modeling and Multimodal Adversarial Alignment Network for Pilot Workload Evaluation","description":"The paper introduces a workload classification system called TRM-MAAN. It is designed to assess pilot workload in real time using physiological data. The system relies on two primary signals: EEG: which measures electrical activity in the brain. EMG: which captures muscle activity. Both of these signals offer insight into a pilot’s cognitive and physical state but integrating them into a single, reliable model is challenging. EEG and EMG operate on different time scales and frequency ranges, meaning that traditional fusion techniques often fail to align them properly. Moreover, workload is inherently dynamic, changing continuously throughout a flight, so any meaningful classification model must account for temporal dependencies rather than treating data points in isolation. To address these issues, the framework uses a Transformer. The reason for choosing a Transformer (over other deep learning architectures) lies in","sample":false,"doi":"10.1109/JTEHM.2025.3542408","short":"pilot-evaluation","released":"March 5th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Pilot Workload Evaluation","carousels":["Transportation","Safety","Temporal Analysis","Adversarial Networks","Workplace Technology","Cognitive Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"temporal-relation-modeling-and-multimodal-adversarial-alignment-network-for-pilot-workload-evaluation"},{"title":"A Comparison Between Single-Stage and Two-Stage 3D Tracking Algorithms for Greenhouse Robotics","description":"Real-world farming isn’t as neat and simple as a library of images. Nature is unpredictable. No amount of training data will account for variables like lighting, position, and bunch size. These variations make it much harder for AI to identify the tomatoes accurately 100% of the time. And when you factor in the complexity of the plant’s structure into the mix, things get even messier. This is where Multi-Object Tracking (MOT) technology comes in. It’s a set of algorithms designed to track multiple objects while they, or the camera, are in motion. In MOT systems this is known as re-identification. Think of the technology that allows commentators to track each player on a football field during a game. While the human eye perceives this as smooth tracking, it’s actually a series of frames fed into an algorithm, along with their corresponding location within three-dimensional space. This 3D space is what’s known","sample":false,"doi":"10.3390/s24227332","short":"greenhouse-robotics","released":"March 4th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Greenhouse Robotics","carousels":["Algorithms","Robotics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-comparison-between-single-stage-and-two-stage-3d-tracking-algorithms-for-greenhouse-robotics"},{"title":"Atom Search Optimization: a comprehensive review of its variants, applications, and future directions","description":"ASO is rooted in molecular dynamics, a branch of physics that describes how atoms interact under forces like attraction and repulsion. There are principles that govern the movement and behavior of atomic particles, and they form the basis for ASO’s search strategy. Each candidate solution is represented as an atom within a simulated environment. The algorithm then mimics two fundamental forces: Interaction forces: These describe the attraction and repulsion between atoms. Interaction forces are based on the Lennard-Jones potential, a well-known function in physics that describes how atoms attract each other at long ranges and repel each other at short distances. In this context, this means that candidate solutions close to one another in the search space will experience repulsion, preventing overcrowding and encouraging diversity, while those farther apart will experience attraction, helping the algorithm converge toward","sample":false,"doi":"10.7717/peerj-cs.2722","short":"atom-search","released":"March 3rd, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Atom Search Optimization","carousels":["Algorithms","Search","Physics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"atom-search-optimization-a-comprehensive-review-of-its-variants-applications-and-future-directions"},{"title":"Off-the-shelf medication transformed: Custom-dosed metoprolol tartrate tablets via semisolid extrusion additive manufacturing and the perception of this technique in a hospital context","description":"Every parents’ worst nightmare: Your child has just been diagnosed with a rare condition, and you’re finally home from the hospital. Time to give them their medication. The pharmacy only had adult tablets, so you’ll need to break them in half. The two halves are not equal, and you notice some collateral damage on the kitchen table. Given the option between underdose and overdose, you choose option 3: Make some coffee. As you stand in front of the machine dialing-in the amount of caffeine the situation calls for, you think to yourself: Why isn’t there a machine that can dial-in the right amount of medication for my child? …well...maybe there is. In today’s paper, the authors are assessing the feasibility of using 3D printers to modify adult tablets into smaller, patient-specific doses. If they’re successful, they’ll have proved that it’s possible to downsize a tablet to a","sample":false,"doi":"10.1016/j.ijpx.2024.100277","altLink":"https://www.sciencedirect.com/science/article/pii/S2590156724000495","short":"metoprolol-printing","released":"March 2nd, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Custom Dosed Tablets","carousels":["Pharmacology","3D Printing","Manufacturing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"off-the-shelf-medication-transformed-custom-dosed-metoprolol-tartrate-tablets-via-semisolid-extrusion-additive-manufacturing-and-the-perception-of-this-technique-in-a-hospital-context"},{"title":"The technique of fuzzy analytic hierarchy process (FAHP) based on the triangular q-rung fuzzy numbers (TR-q-ROFNS) with applications in best African coffee brand selection","description":"Traditional logic operates in absolutes, where something is either true or false, present or absent, good or bad. But many real-world problems don’t fit neatly into binary classifications. Fuzzy logic provides a way to represent uncertainty by allowing variables to exist in degrees rather than absolutes. Instead of saying a coffee brand is either \"high quality\" or \"low quality,\" fuzzy logic assigns a membership value to quality, indicating the extent to which a brand belongs to that category. This approach more closely mirrors human reasoning, where preferences and perceptions are rarely black and white. Multi-criteria decision-making, or MCDM, is a framework designed to evaluate and rank alternatives when multiple, often conflicting, factors must be considered simultaneously. Unlike single-factor decision-making methods that prioritize one variable, such as cost or performance, MCDM recognizes that real-world decisions","sample":false,"doi":"10.7717/peerj-cs.2555","short":"fahp-technique","released":"March 1st, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fuzzy Analytic Hierarchy Process","carousels":["Algorithms","Classification","Fuzzy Logic"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-technique-of-fuzzy-analytic-hierarchy-process-fahp-based-on-the-triangular-q-rung-fuzzy-numbers-tr-q-rofns-with-applications-in-best-african-coffee-brand-selection"},{"title":"Solving Integer Ambiguity Based on an Improved Ant Lion Algorithm","description":"On October 4th, 1957, the Soviet Union launched Sputnik: the first satellite ever put into orbit. This, to put it bluntly, scared the crap out of the Americans and propelled the U.S. into the space race. In the days and weeks after launch, the U.S. became obsessed with tracking Sputnik's movements. Where is it now? Ok, how about now? And now? In order to track it, they used Doppler shift measurements. Radio receivers on the ground would listen to Sputnik’s beeping signal, and analyze how its frequency changed as it moved. The resulting measurements allowed engineers to calculate its exact orbit and predict its future positions. The U.S. got quite good at this, and this led to a realization. If we can track a satellite in space with ground-based measurements, then the converse is also true. If we had multiple satellites in space at one time, then we could use them to track objects on Earth. Within four months","sample":false,"doi":"10.3390/s25041212","short":"integer-ambiguity","released":"February 28th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Ant Lion Algorithm","carousels":["Algorithms","GPS","Electromagnetic Spectrum","Telecommunications"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"solving-integer-ambiguity-based-on-an-improved-ant-lion-algorithm"},{"title":"Mass spectrometry imaging as a promising analytical technique for herbal medicines: an updated review","description":"Herbal medicines often have many bioactive compounds, working simultaneously on many different parts of the body, making it difficult for researchers to identify the actions of specific molecules. Mass Spectrometry Imaging (MSI) techniques have provided a visual window into the molecular realm of herbal medicines, enabling researchers to identify locations of useful compounds and observe the chemical mechanisms of pathology. Molecular level imagining can greatly improve the quality control of the herbal medicine landscape by helping to standardize cultivation and processing methods, ensuring safe and reliable medicines for all. In this episode of Journal Club, we’ll explore the three major methods of MSI, present how researchers use MSI techniques in herbal medicine analysis, and see how they can be applied to quality control improvement. But first, let’s start things off by looking at how herbal medicines work.","sample":false,"doi":"10.3389/fphar.2024.1442870","short":"mass-spectrometry","released":"February 27th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Mass Spectrometry Imaging","carousels":["Electromagnetic Spectrum","Medicine","Pharmacology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"mass-spectrometry-imaging-as-a-promising-analytical-technique-for-herbal-medicines-an-updated-review"},{"title":"Resampling Point Clouds Using Series of Local Triangulations","description":"Delaunay triangulation constructs a set of triangles connecting the points in such a way that no point is unnecessarily enclosed within any triangle. This can be difficult to picture, so let’s take a moment to visualize it. You’ve got a 3D space, and a bunch of points floating in it. A Delaunay triangulation would try to connect these points with triangles in a way that avoids skinny or highly stretched triangles, instead favoring triangles that are as close to equilateral as possible. It doesn't add points that aren't there, and it doesn't move any of your existing points, it just figures out the way to connect the existing points such that it maximizes the minimum interior angle across all triangles. Remember that an equilateral triangle has the largest possible minimum-angle (in other words, its smallest angle is the largest it could be). As you would expect Delaunay triangulation is well-suited for","sample":false,"doi":"10.3390/jimaging11020049","short":"resampling-point-clouds","released":"February 26th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Delaunay Triangulation","carousels":["Point Clouds","3D Mapping","Voxels"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"resampling-point-clouds-using-series-of-local-triangulations"},{"title":"Multi-Server Two-Way Communication Retrial Queue Subject to Disaster and Synchronous Working Vacation","description":"Traditional FIFO (First-In-First-Out) are ill-suited for telephony because customers do not passively wait in line. They either hang-up and redial, or they give up entirely. This leads to something called a “retrial phenomenon”, where unserved customers retry the system in an attempt to obtain service. Sometimes they do this immediately, sometimes they do it after a delay. If this isn’t managed properly, retrial traffic can become self-perpetuating. It causes waves of congestion that overload the system, creating a kind of cyclic doom spiral that takes everything down. To make it more complicated, servers are not merely passive responders to inbound requests; they also initiate outbound calls. Many helplines proactively reach out to clients (for follow-up care, appointment reminders, or callbacks). This means that server availability is not solely determined by inbound traffic but also by internally","sample":false,"doi":"10.3390/a18010024","short":"retrial-queue","released":"February 25th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Retrial Queue","carousels":["Telecommunications","Electromagnetic Spectrum","Distributed Systems"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multi-server-two-way-communication-retrial-queue-subject-to-disaster-and-synchronous-working-vacation"},{"title":"Domain knowledge-based deterministic graph traversal method for white blood cell classification","description":"Geesh...is every computer vision paper just another deep learning classifier? It can certainly seem that way. There are so many projects built on top of Yolo, ResNet, and VGG that it can be tempting to believe that that’s all there is...that there’s nothing else going on in that field. So today, we’re going to look at something different. A computer-vision problem that’s being solved in a way that we rarely see. Instead of a normal deep-learning classifier, the authors built a system that performs a deterministic traversal through a directed graph in order to arrive at a class label. Why? Because it turns out that traditional CV models are not a panacea. They have a number of drawbacks that make them less suitable for specific applications. In today’s episode we’re going to talk about how most CV models work, why they’re not ideal for certain use-cases, how this alternative method is better suited, and then how","sample":false,"doi":"10.1088/2632-2153/adb126","short":"wbc-classification","released":"February 24th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Deterministric Graph Traversal","carousels":["Medicine","Algorithms","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"domain-knowledge-based-deterministic-graph-traversal-method-for-white-blood-cell-classification"},{"title":"The Kernel Density Estimation Technique for Spatio-Temporal Distribution and Mapping of Rain Heights over South Africa: The Effects on Rain-Induced Attenuation","description":"We have to start with a Probability Density Function (PDF). Not to be confused with a Probability Distribution Function, which would show us a distribution (the probability of all possible values a random variable can have). A Probability Density Function shows us the likelihood of a variable having a value within a specific range of values, like rain height measurements through the summer. A higher density of rain height measurements that fall in the specific range, the more likely it is that rain will fall in that range in the future. The Density function is the one that we are interested in today. The function is the equation that data is fed into to calculate the probability spread. The visual expression of this function is a line graph with a parabolic arc. Let's use the famous bell shaped curve as an example. The middle of the curve represents the highest density of data points. The X axis is the","sample":false,"doi":"10.3390/atmos15111354","short":"kernel-density","released":"February 23rd, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Kernel Density Estimation","carousels":["Statistics","Environmental Science","Electromagnetic Spectrum","Telecommunications"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-kernel-density-estimation-technique-for-spatio-temporal-distribution-and-mapping-of-rain-heights-over-south-africa-the-effects-on-rain-induced-attenuation"},{"title":"Optimizing Solid Oxide Fuel Cell Performance Using Advanced Meta-Heuristic Algorithms","description":"Unlike internal combustion engines, which burn fuel to produce mechanical energy, fuel cells generate electricity through an electrochemical process. They pull electrons from hydrogen atoms, creating an electric current, and then combine the hydrogen with oxygen to produce water. No flames, no emissions. There are several types of fuel cells, in two big groups: low-temperature and high-temperature. Within that latter group are several subtypes; the one we’re looking at today is called SOFC: Solid Oxide Fuel Cells. SOFCs rely on a solid ceramic electrolyte (usually a kind of zirconia called YSZ) to transport oxygen ions from the cathode to the anode. They run very hot: between 600 and 1000 degrees Celsius. This allows for greater fuel flexibility, enabling them to operate on hydrogen as well as hydrocarbon fuels like methane or even ammonia.","sample":false,"doi":"10.22034/aeis.2024.460563.1202","short":"sofc-performance","released":"February 22nd, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Solid Oxide Fuel Cell","carousels":["Energy Science","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"optimizing-solid-oxide-fuel-cell-performance-using-advanced-meta-heuristic-algorithms"},{"title":"Energy-aware operation of HPC systems in Germany","description":"HPC engineers aren’t like most devs. They work in an environment that is decidedly...weird. It’s an environment where languages like Fortran abound (and are actually quite popular). An environment where batch jobs can queue for days, where computers are cooled by water instead of fans, where performance is measured in teraflops, storage is measured in exabytes, networking speeds are faster than most SSDs, and job failures can be caused by cosmic rays flipping bits. HPC is just a whole other universe. And it’s a universe that uses an almost unbelievable amount of power.High-performance computing centers are among the most power-hungry facilities in the world. A single supercomputing installation can draw upwards of 20 megawatts of juice. That’s an amount comparable to the total electricity consumption of a small city. The JUPITER system planned for Germany is expected to require an amount of power roughly","sample":false,"doi":"10.3389/fhpcp.2025.1520207","short":"energy-aware-hpc","released":"February 21st, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Energy Aware HPC","carousels":["Cloud Computing","High Performance Computing","Environmental Science","Energy Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"energy-aware-operation-of-hpc-systems-in-germany"},{"title":"A low functional redundancy-based network slimming method for accelerating deep neural networks","description":"You’ve done it. It took you months of work, but you’ve done it. You trained the perfect computer-vision model. Maybe it's a CNN, maybe it’s a vision-transformer, who cares. It’s yours, it works, it’s accurate, and you’re ready to roll it out. There’s only one problem: it’s big. Real big. Way bigger than you anticipated. Best case scenario: inference is going to be slow.Worst-case scenario: you won’t be able to deploy to the device it’s supposed to run on. So, what are your options? You’ve got quite a few: from network decomposition, to quantization, to knowledge distillation. And in today’s paper, the authors introduce another method to consider. They call it LFRNS, the Low Functional Redundancy-based Network Slimming method. And they say it’s your best way forward. The authors claim that (using this technique) they were able to cut the parameters of computer-vision models by more than half, with only a 1% loss in accuracy. How? Well","sample":false,"doi":"10.1016/j.aej.2024.12.118","altLink":"https://www.sciencedirect.com/science/article/pii/S1110016824017162","short":"network-slimming","released":"February 20th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Network Slimming Method","carousels":["Deep Neural Networks","Model Training","Model Performance"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-low-functional-redundancy-based-network-slimming-method-for-accelerating-deep-neural-networks"},{"title":"From traditional robotic deployments towards assisted robotic deployments in nuclear decommissioning","description":"If you watched the HBO miniseries “Chernobyl” a few years back, then this is a story you already know well. In 1986 there was an explosion in Reactor 4 at the Chernobyl Nuclear Power Plant in modern-day Ukraine. This accident released massive amounts of radiation, and created an environment that was lethal not just to humans and animals, but also to machines. You see, when Soviet engineers sent in remote-controlled robots to aid in the cleanup, many of them failed almost immediately. The radiation fried their electronics. It caused their systems to glitch, their sensors to malfunction, and their circuits to burn out. Some of the robots just stopped moving, others spun around aimlessly, and others lost communication with their operators. This led to one of the darkest moments in an already tragic event. Officials decided to send in what they termed \"bio-robots\" instead. Of course, these weren't robots at all","sample":false,"doi":"10.3389/frobt.2025.1432845","short":"nuclear-decommissioning","released":"February 19th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Nuclear Decommissioning","carousels":["Energy Science","Nuclear Power","Robotics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"from-traditional-robotic-deployments-towards-assisted-robotic-deployments-in-nuclear-decommissioning"},{"title":"Variational Autoencoders-Based Algorithm for Multi-Criteria Recommendation Systems","description":"A VAE is a deep learning model designed to learn compact representations of complex data while preserving its underlying structure. Traditional autoencoders simply compress input data into a lower-dimensional space and then attempt to reconstruct it. VAEs go further. They incorporate a probabilistic component that allows for more flexible and expressive representations. This makes them particularly well-suited for applications where data exhibits variability and uncertainty. Instead of mapping inputs to a single fixed latent representation, a VAE learns a probability distribution over possible representations, enabling it to generate new data points and make more nuanced predictions. Its architecture consists of two primary components: an encoder and a decoder, connected through a latent space. The encoder takes high-dimensional input data (such as a user’s multi-criteria ratings) and compresses it into a","sample":true,"doi":"10.3390/a17120561","short":"vae-mcrs","released":"February 18th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Multi-Criteria Recommendation Systems","carousels":["Software Engineering","Deep Learning","Variational Autoencoders"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"variational-autoencoders-based-algorithm-for-multi-criteria-recommendation-systems"},{"title":"An interaction-fair semi-decentralized trajectory planner for connected and autonomous vehicles","description":"If you took a Psych, Econ, or Poli-Sci class in college, there’s a good chance you learned about Prisoner’s Dilemma. It’s a classic scenario: Two people are arrested for a crime and taken to jail. They’re held in separate cells so they can’t communicate with each other. The detectives interrogate them separately and present them both the same offer: If neither of you confess you’ll each get a one-year sentence. If one of you confesses, that person will go free and the other person will get a three-year sentence. If you both confess you’ll both get two years. What would you do? The purpose of this scenario is to highlight the conflict between self-interest and cooperation, and to show that when cooperation breaks down (or communication is unavailable) there can often be a worse outcome for all parties involved. This is true of Prisoner’s Dillemma, Stag Hunt, Tragedy of the Commons, Volunteer’s Dilemma and","sample":false,"doi":"10.1007/s43684-024-00087-5","short":"trajectory-planner","released":"February 17th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Trajectory Planner","carousels":["Autonomous Vehicles","Algorithms","Game Theory"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-interaction-fair-semi-decentralized-trajectory-planner-for-connected-and-autonomous-vehicles"},{"title":"Two-Stage Optimization Model Based on Neo4j-Dueling Deep Q Network","description":"In this paper, the authors answer an important question: What can you do when you've got an optimization problem, and neither rule-based approaches, mathematical techniques nor heuristic algorithms are able to do the job? They've come up with a novel solution: a two-stage model. In the first stage, their system constructs a graph-based representation of the ADN, where power flow data and network topology are mapped into a queryable structure. This allows for easy identification of feasible load transfer paths. In the second stage, it determines the optimal sequence of switch operations, while minimizing congestion, reducing power losses, and maintaining network stability. For the first stage, they are using a database called Neo4j, and for the second stage they’re using a model called a Dueling Deep Q-Network (Dueling DQN). Let’s dive into what both of those are, and how they’re being used here","sample":false,"doi":"10.3390/en17194998","short":"neo4j-dueling","released":"February 16th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Neo4j Dueling Deep Q Network","carousels":["Deep Neural Networks","Deep Learning","Graph Databases","Databases"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"two-stage-optimization-model-based-on-neo4j-dueling-deep-q-network"},{"title":"Artificial intelligence-based framework for early detection of heart disease using enhanced multilayer perceptron","description":"A simple perceptron is the most basic type of artificial neural network. It consists of a single layer of neurons that directly map input features to an output. Each neuron in a perceptron receives multiple numerical inputs, applies a corresponding weight to each, sums the weighted inputs, and then passes the result through an activation function that produces an output. This is typically a step function that produces a binary output. This means a perceptron functions as a linear classifier, capable of distinguishing between two classes only if they are linearly separable (meaning they can be divided by a straight line or a hyperplane). While these are effective for simple classification problems like AND or OR logic gates, a single-layer perceptron fails to model more complex relationships where data points cannot be neatly separated by a single decision boundary. A multilayer perceptron (MLP) extends the capabilities of a simple perceptron by introducing one or more hidden layers between the input and output layers. These hidden layers contain","sample":false,"doi":"10.3389/frai.2024.1539588","short":"multilayer-perceptron","released":"February 15th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Heart Disease Detection","carousels":["Medicine","Perceptrons","Cardiovascular Disease"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"artificial-intelligence-based-framework-for-early-detection-of-heart-disease-using-enhanced-multilayer-perceptron"},{"title":"A framework for measuring physical garment durability","description":"We’ve all been in this situation before. We’re buying a shirt online, and we’ve found one that looks perfect. It’s the right size, it’s the right cut, and it's the right color. The only thing we’re not sure about, is its quality. How can we know if it’ll last forever, or disintegrate in the first wash? Will the photos tell us that? Or how about the reviews? Or, does price equal quality? What we could use is a rating system for clothing durability. Having that would allow us to buy more confidently, and to know our clothes will last. In today's paper, the authors present the groundwork for just such a system. One that can be applied to all types of garments. We’ll start by exploring the variables that are most important to garment durability, look at how the researchers went about testing them and then look at how they used the data","sample":false,"doi":"10.1016/j.clrc.2024.100245","short":"garment-durability","released":"February 14th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Garment Durability","carousels":["Manufacturing","Physical Products","Textiles","Statistics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-framework-for-measuring-physical-garment-durability"},{"title":"An Analytical System Design For Forensic Fingerprint Examination","description":"You’ve seen this trope before, I’m sure. There’s caution-tape around a crime-scene. Detectives and investigators swarm about, looking for evidence. One of them is dusting for fingerprints, and eventually they find something! A finger print on a door-knob, or a glass, or on a window. They run the prints, and find the bad guy. Voilà, happy ending. That kind of story fits nicely into an episode of SVU, but it doesn’t actually reflect much of what the real process is like. In the real-world, there are a number of issues with fingerprints. For starters, they’re everywhere and on everything, in various states of decay. Every household appliance, and remote control, and phone, and computer, and table-top, and light-switch, and cupboard is covered in them. So the process of dusting for prints isn’t like looking for a single print or two in an otherwise clean room. The opposite: the room is full of prints, and you’re trying to figure out","sample":false,"doi":"10.1109/ACCESS.2025.3535581","short":"forensic-fingerprints","released":"February 13th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fingerprint Examination","carousels":["Forensics","Criminal Justice","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-analytical-system-design-for-forensic-fingerprint-examination"},{"title":"A Novel Technique for Facial Recognition Based on the GSO-CNN Deep Learning Algorithm","description":"Facial recognition is so ubiquitous that we rarely stop to think about how it actually works. If I hold my phone up to my face to unlock it, what is the phone actually doing? Is this a deterministic algorithm? Is it a machine-learning model? How does it work? And in the rare case that it struggles to recognize me, why is that? In today’s paper the authors introduce a new form of facial recognition that overcomes some of the problems of the previous versions. The challenge for us is to understand the context of their contribution. We’re not going to be able to grok what these authors are doing unless we first take a look at what came before. So we’re going to start by going back. All the way back to when facial recognition started. We’ll explore what it was like in its fledgling phases. Then, we’re going to walk forward, through generation after generation of the technology to see how it has","sample":false,"doi":"10.1155/2024/3443028","short":"facial-recognition","released":"February 12th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Facial Recognition","carousels":["Deep Learning","Computer Vision","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-novel-technique-for-facial-recognition-based-on-the-gso-cnn-deep-learning-algorithm"},{"title":"Multi-Objective Simulated Annealing for Efficient Task Allocation in UAV-Assisted Edge Computing for Smart City Traffic Management","description":"In simulated annealing, the algorithm starts out “hot” and slowly cools off. When the system is metaphorically \"hot,\" it can make moves that may temporarily worsen the solution. And as the temperature decreases over time, the algorithm becomes more conservative, gradually focusing on refining the best solutions it discovered. The key innovation here is the controlled decay of exploration. This balances the need for global search early in the process, with fine-tuned exploitation as it converges. Let’s go back to the example of someone walking around a neighborhood. With Simulated Annealing, they’d jump from block to block in the beginning, randomly checking prices all over the area. And then, once they found the cheapest blocks, they’d get more conservative and focus on finding the cheapest house on one of those blocks. MOSA extends the principles of simulated annealing to problems where multiple conflicting objectives","sample":false,"doi":"10.1109/ACCESS.2025.3538676","short":"simulated-annealing","released":"February 11th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Multi-Objective Simulated Annealing","carousels":["Algorithms","Cloud Computing","UAVs","IoT"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multi-objective-simulated-annealing-for-efficient-task-allocation-in-uav-assisted-edge-computing-for-smart-city-traffic-management"},{"title":"Dual feature-based and example-based explanation methods","description":"I find it's useful to think of \"Explainability\" as a continuum. On one end, you have purely deterministic, single-threaded, procedural code: Do this, then that, then this, then that. When you run the program, you'll see it do those things. And conversely: it’s always easy for you to determine why it's doing the things that it's doing. It only takes the steps that are clearly expressed in the instructions that you gave it. In the middle of the continuum are things that are probabilistic but still predictable. A function with some randomness, or even a machine learning model with well-calibrated uncertainty estimates. The system runs, and you might not know exactly what a function is going to return, but you do know that it's going to be within a range of values. On the far end of the continuum, you have deep neural networks and other high-dimensional, adaptive","sample":false,"doi":"10.3389/frai.2025.1506074","short":"dual-explanation","released":"February 10th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Dual Explanation Methods","carousels":["A.I. Explainability","Model Transparency"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"dual-feature-based-and-example-based-explanation-methods"},{"title":"Beware of diffusion models for synthesizing medical images—a comparison with GANs in terms of memorizing brain MRI and chest x-ray images","description":"The vast majority of the papers we discuss are about pushing technology forward. A new way to solve a problem, a new trend in an industry, or a new tool that hasn’t found its use-case yet. But every once in a while, we come across a paper that is doing the opposite. A paper that’s saying “Wait, turn around, we’re headed in the wrong direction!” Today’s paper is in that latter group. The authors are making the argument that Diffusion Models are being misused. They say that diffusion models are being treated as if they’re upgraded GANs, but in reality they’re fundamentally different; and that difference makes them unsuitable for some of the use-cases to which GANs were being applied. It’s an interesting case that they’re making. And it gives us an excuse to dive into both GANs and Diffusion Models, learn how they work, how they’re the same, and how","sample":false,"doi":"10.1088/2632-2153/ad9a3a","short":"diffusion-vs-gan","released":"February 9th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Beware of Diffusion Models","carousels":["Generative A.I.","Diffusion"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"beware-of-diffusion-models-for-synthesizing-medical-imagesa-comparison-with-gans-in-terms-of-memorizing-brain-mri-and-chest-x-ray-images"},{"title":"Multi-Objective Task Scheduling for Earth Observation InSAR Satellites via Non-Dominated Sorting Student Psychology Based Optimization Algorithm","description":"The title of this paper is really good at two things: 1) Intimidating the reader. 2) Itemizing all the concepts we need to understand before we’re able to understand this paper. #1 is a shame, but #2 is actually useful. Today we’re going to use this horrible title as a roadmap. A checklist of all the pieces of context we need to gather together and review before we’re able to turn our attention to the system that the authors designed. Each one of the words in the title is like a jigsaw puzzle piece. It won’t be until the end of the episode that the pieces start to come together, and the whole picture starts to make sense. So bare with me, it’s going to be a journey. Looking back up at the title now, I want to start in the middle. What’s an InSAR satellite? What do they do? Once we get a grasp of that, the problem-space will start to crystallize and we’ll have set the stage for the solutions to those problems","sample":false,"doi":"10.1590/jatm.v17.1362","altLink":"https://jatm.com.br/jatm/article/view/1362","short":"insar-satellites","released":"February 8th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Multi-Objective Task Scheduling","carousels":["Space","Telecommunications","Electromagnetic Spectrum","Algorithms","Distributed Systems"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multi-objective-task-scheduling-for-earth-observation-insar-satellites-via-non-dominated-sorting-student-psychology-based-optimization-algorithm"},{"title":"Dynamic Car-Following Model With Jerk Suppression for Highway Autonomous Driving","description":"The first thing you need to know is that there’s something called \"Headway\". Headway is the time it takes for a following-vehicle to reach the same point that a leading-vehicle just passed. It is typically measured in seconds and helps determine safe following distances in traffic. If you’ve ever heard someone say to \"give x seconds to the car in front of you\", that number of seconds is headway. Today’s research largely concerns highway driving, where headway is crucial. Too much headway, and the cars behind you will start passing you; leapfrogging to the space you should have been occupying. Too little headway and not only do you risk running into the back of the next car, but you’re much more likely to feel the need to hit the brakes hard when the next car’s brake lights come on. For your passenger, that results in jerkiness. Prior to this paper, a number of systems","sample":false,"doi":"10.1109/ACCESS.2025.3535596","short":"jerk-suppression","released":"February 7th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Jerk Suppression","carousels":["Autonomous Vehicles"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"dynamic-car-following-model-with-jerk-suppression-for-highway-autonomous-driving"},{"title":"An Enhanced Contrastive Ensemble Learning Method for Anomaly Sound Detection","description":"So what does it mean to analyze sounds? What does that process entail on a technical level? Well, sound first gets captured by a microphone as an analog waveform (a continuous variation of air pressure over time). This waveform is then converted into a digital format using an analog-to-digital converter (ADC), which samples the sound at a high frequency (e.g., 16 kHz or 44.1 kHz, etc). This process quantizes each sample into discrete numerical values. The resulting digital audio is typically stored in formats such as WAV, FLAC, or MP3, which preserve these numerical representations in various levels of compression and fidelity. A digital sound file is essentially just a sequence of numbers that encode the amplitude of the sound wave at each sampled point in time. For example, in a WAV file, which is an uncompressed","sample":false,"doi":"10.3390/app15031624","short":"anomaly-sound-detection","released":"February 6th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Anomaly Sound Detection","carousels":["Sound Processing","Ensemble Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-enhanced-contrastive-ensemble-learning-method-for-anomaly-sound-detection"},{"title":"An efficient binary spider wasp optimizer for multi‐dimensional knapsack instances: experimental validation and analysis","description":"The multidimensional knapsack problem is a combinatorial optimization problem that extends the classic knapsack problem by introducing multiple constraints. In its simplest form, the traditional knapsack problem involves selecting a subset of items, each with a given weight and value. You need to maximize the total value while ensuring that the weight does not exceed a fixed capacity. The multidimensional variant generalizes this by considering multiple resource constraints instead of a single weight limit. Each item consumes resources from multiple dimensions, and the total usage across all selected items must remain within the predefined capacity for each constraint. This problem arises in many real-world scenarios where limited resources must be allocated efficiently. In logistics, for example, a company may need to pack goods into containers, each subject to multiple restrictions such as","sample":false,"doi":"10.1186/s40537-024-01055-9","short":"spider-wasp","released":"February 5th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Binary Spider Wasp Optimization","carousels":["Optimization","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-efficient-binary-spider-wasp-optimizer-for-multidimensional-knapsack-instances-experimental-validation-and-analysis"},{"title":"Deep learning and explainable AI for classification of potato leaf diseases","description":"As you would probably guess, they decided to use a convolutional neural network (CNN) as the classifier itself. This is a type of artificial neural network commonly optimized for analyzing visual data. Rather than train from scratch, they decided to use transfer learning, where a pre-trained CNN, specifically VGG16, was adapted to their new use-case. VGG16 is a well-established architecture originally trained on ImageNet. By leveraging the knowledge that’s already encoded in its convolutional layers, it can extract meaningful patterns from potato leaf images without requiring a vast dataset for training. All the researchers needed to do is replace the final classification layers of that model with custom layers suited for their specific classification task. To enhance interpretability, they incorporated Grad-CAM: Gradient-weighted Class Activation Mapping. This is a technique that","sample":false,"doi":"10.3389/frai.2024.1449329","short":"potato-famine","released":"February 4th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Potato Leaf Diseases","carousels":["Classification","Computer Vision","Deep Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"deep-learning-and-explainable-ai-for-classification-of-potato-leaf-diseases"},{"title":"Performance Evaluation of NewSQL Databases in a Distributed Architecture","description":"Where NewSQL diverges from NoSQL is in its treatment of consistency. NoSQL databases were developed to solve the scalability limitations of relational databases. Most of them accomplish this by relaxing strict consistency guarantees in favor of availability, partitioning, and performance. Rather than focusing on ACID, they often follow a model called BASE: Basically Available, Soft state, Eventually consistent. BASE allows nodes in a distributed system to return slightly outdated data in exchange for lower latency and higher throughput. While this works well for applications like social media feeds and real-time analytics, it presents serious challenges for use cases that require precise, immediate consistency. NewSQL avoids these pitfalls by maintaining ACID compliance, ensuring that distributed transactions are just as reliable as those in a traditional relational","sample":false,"doi":"10.1109/ACCESS.2025.3529740","short":"newsql-databases","released":"February 3rd, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DHKQlEas9J9/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"NewSQL Databases","carousels":["Databases","Distributed Systems"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"performance-evaluation-of-newsql-databases-in-a-distributed-architecture"},{"title":"Multi-density crime predictor: an approach to forecast criminal activities in multi-density crime hotspots","description":"They decided to use a combination of two different technologies: SARIMA and LSTM. They would build, train, and test both independently, and then consider if they should be ensembled together. Let's learn a little bit more about these two model types. SARIMA, or Seasonal AutoRegressive Integrated Moving Average, is an extension of the ARIMA model that has been modified to handle seasonal time series data. The AutoRegressive (AR) component models a time series as a linear combination of its past values, using lagged observations as predictors. The Integrated (I) component applies differencing to remove trends and make the series stationary. The Moving Average (MA) component captures dependencies on past forecast errors, adjusting predictions based on previously observed deviations. SARIMA extends this by adding seasonal autoregressive (SAR), seasonal moving average (SMA), and","sample":false,"doi":"10.1186/s40537-024-00935-4","short":"crime-prediction","released":"February 2nd, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DF_FoxdMAZ8/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Multi-Density Crime Predictor","carousels":["Criminal Justice","LSTM","Temporal Analysis"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multi-density-crime-predictor-an-approach-to-forecast-criminal-activities-in-multi-density-crime-hotspots"},{"title":"Skyline query under multidimensional incomplete data based on classification tree","description":"The process begins by inserting each tuple into the tree. The root node contains all data tuples, and from there, branching occurs based on the presence or absence of attributes. Intermediate nodes store weight-based decisions rather than attribute values, ensuring that tuples with missing values are assigned correctly. The tree grows downward, with leaf nodes representing fully classified groups of tuples that share identical missingness patterns. Once classification is complete, the tree’s indexing mechanism ensures that data can be efficiently retrieved and processed. Since each leaf node corresponds to a distinct missing data pattern, skyline queries can be executed within each bucket separately, minimizing unnecessary dominance comparisons across tuples with incompatible attribute sets. One of the other key innovations here is the introduction of Optimal Virtual Points","sample":false,"doi":"10.1186/s40537-024-00923-8","short":"skyline-query","released":"February 1st, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Skyline Queries","carousels":["Classification","Data Structures","Databases","Search"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"skyline-query-under-multidimensional-incomplete-data-based-on-classification-tree"},{"title":"Analog Sequential Hippocampal Memory Model for Trajectory Learning and Recalling: A Robustness Analysis Overview","description":"It's called the Artificial General Intelligence Modularity Hypothesis. I’m just going to call it “Modularity” for short. The Modularity argument goes like this. Two premises and a conclusion: Premise 1: The human brain is not one big thing. It’s separated into regions. There’s the occipital lobe that processes vision, and the amygdala that regulates emotion. There’s the frontal lobe, the prefrontal cortex, the cerebellum, and many others. No single one of these regions is a brain unto itself, they each have a narrow focus. But collectively, they are more than the sum of their parts. Intelligence, as we know it, is an emergent property that mysteriously manifests itself only when these disparate components connect, interact, and communicate. Premise 2: Each AI sub-field (and each new type of model) is equivalent to a different region in the brain. While LLMs are highly sophisticated, they’re really just","sample":false,"doi":"10.1002/aisy.202400282","short":"hippocampal-memory","released":"January 31st, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFxwXhfMlAj/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Hippocampal Memory Model","carousels":["Artificial General Intelligence","Cognitive Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"analog-sequential-hippocampal-memory-model-for-trajectory-learning-and-recalling-a-robustness-analysis-overview"},{"title":"A comprehensive overview of load balancing methods in software‐defined networks","description":"​If you’re operating a website at scale, then it’s very unlikely that you’re running it on a single server. When you were setting up your DNS, you probably didn’t have your A-Records point right to the static IP of a server. Instead, you most likely have your A-Records set to an IP address that maps (either statically or ephemerally), to a load balancer. This load balancer (or a set of load balancers), sits in front of your cluster of servers. And when traffic comes in, the load balancer picks which server should actually receive the traffic and process the request. I make a request to your website, and it gets processed by Server-1. someone else makes a request and it gets processed by Server-2, etc. This allows your system to scale horizontally. Your cluster of servers is able to divide up the work that would have otherwise all fallen on one of them. These kinds of balancers are","sample":false,"doi":"10.1007/s43926-025-00098-5","short":"load-balancing","released":"January 30th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFvIAbWM5fL/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Load Balancing in SDN","carousels":["Network Engineering","Software Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-comprehensive-overview-of-load-balancing-methods-in-softwaredefined-networks"},{"title":"The Future of Last-Mile Delivery: Lifecycle Environmental and Economic Impacts of Drone-Truck Parallel Systems","description":"​The Traveling Salesman Problem (TSP) is a classic optimization challenge. There’s a set of points (locations), and a “salesman” (or in this case, a delivery vehicle) who must visit each point once, and then return to the starting point. And he must do all this in the shortest total distance. On the surface, it seems fairly straightforward. You might assume that with enough computational power, you could just check all the options fairly quickly. But you can’t. The complexity of TSP grows exponentially as the number of points increases. The number of total possibilities is the factorial of one-less than the number of points. So with just a handful of destinations, it’s feasible to calculate every possible route and choose the shortest one. But, as the number of points grows, the solutions can’t be built incrementally, so there is a combinatorial explosion. This is what we call NP-Hard","sample":false,"doi":"10.3390/drones9010054","short":"last-mile","released":"January 29th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFbn9KZs2Al/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Last Mile Delivery","carousels":["Algorithms","UAVs"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-future-of-last-mile-delivery-lifecycle-environmental-and-economic-impacts-of-drone-truck-parallel-systems"},{"title":"Random k conditional nearest neighbor for high-dimensional data","description":"Today’s paper is about advancements in an algorithm called k-Nearest Neighbors. If you’ve listened to some of our Machine-Learning episodes, you’ve undoubtedly heard that term before. k-Nearest Neighbors (or kNN for short) is everywhere, and is used for everything. Why? Because it’s simple and it's effective. It’s not necessarily always the best tool for the job (and later we’re going to see how these authors are trying to modify it to be better at more things), but it is pretty good at a lot of use-cases. That’s why you’ll see kNNs used in ecology, in linguistics, in sports analytics, and even in archaeology. So before we get into this paper, let’s talk about kNN for a while. How does it work? What do “distances in feature space” even mean? And why is this algorithm so good at calculating them? Let’s get into it.","sample":true,"doi":"10.7717/peerj-cs.2497","short":"random-kcnn","released":"January 28th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFXMoLMMBQN/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"K-Conditional Nearest Neighbors","carousels":["Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"random-k-conditional-nearest-neighbor-for-high-dimensional-data"},{"title":"Temperature variability and its effect on seasonal yield of rice in Bangladesh: a long-term trend assessment","description":"Our paper today looks at how one country, Bangladesh, is using data-science to avoid repeating the mistakes of the past. This research is part of a larger initiative they’re using to equip the agricultural sector with the statistical and computational tools they need to adapt their growing strategies to climate change. In this paper they explore the relationship of temperature to rice yields. The authors use statistical analysis methods to discover trends hidden in daily temperature data over time, and show how they impact crop growth. We’re going to walk through how exactly they’re doing that. We’ll look at descriptive statistics, the Man-Kendall Test, and Wavelet Coherence. We’ll show how these researchers use those tools to get a multifaceted understanding of the variables that are critical to drought intervention. When it established itself as an independent","sample":false,"doi":"10.1080/23311932.2024.2447903","short":"rice-yields","released":"January 27th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFUTCwfMysU/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Temperature Variability on Rice","carousels":["Environmental Science","Statistics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"temperature-variability-and-its-effect-on-seasonal-yield-of-rice-in-bangladesh-a-long-term-trend-assessment"},{"title":"Leveraging Machine Learning to Identify Subgroups of Misclassified Patients in the Emergency Department: Multicenter Proof-of-Concept Study","description":"RETTS was developed in Sweden in the early 2000s, and is a structured and evidence-based triage model designed for high-resource healthcare settings. RETTS categorizes patients based on a combination of both vital signs and clinical symptoms. When they arrive at the ER, patients undergo an initial assessment of a few key physiological parameters (like heart rate, respiratory rate, blood pressure, oxygen saturation, and temperature). These values are then cross-referenced with a rubric called Emergency Symptoms and Signs (ESS). ESS provides guidelines for interpreting the clinical context of the patient's presentation. The system assigns patients into one of five urgency levels. Each urgency level is designated as a specific color, and is mapped to a recommended maximum waiting time. There is: Red (immediate care), Orange (20 minutes), Yellow","sample":false,"doi":"10.2196/56382","short":"misclassified-patients","released":"January 26th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Misclassified Patients","carousels":["Classification","Medicine","Emergency Medicine","Triage"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"leveraging-machine-learning-to-identify-subgroups-of-misclassified-patients-in-the-emergency-department-multicenter-proof-of-concept-study"},{"title":"NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation","description":"Traditional 3D reconstruction techniques often rely on explicit geometric representations such as point clouds, meshes, or voxel grids. This new idea they presented: NeRF (Neural Radiance Fields) represents a scene implicitly using a neural network that encodes the complex interplay of light, materials, and spatial structure in a continuous function. This function maps a 3D spatial coordinate and a 2D viewing direction to corresponding color and density values, effectively capturing the scene’s volumetric properties in a highly compact form. By leveraging the neural network’s ability to learn complex patterns, NeRF can reconstruct intricate scene details and realistic lighting effects that traditional methods struggle to achieve. At the core of NeRF's rendering process is a technique called volume rendering, which allows for the synthesis of","sample":false,"doi":"10.1109/ACCESS.2024.3522768","short":"nerf-view","released":"January 25th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Neural Radiance Fields","carousels":["3D Mapping","Point Clouds","Voxels"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"nerf-view-synthesis-subjective-quality-assessment-and-objective-metrics-evaluation"},{"title":"QUIC and TCP in unsafe networks: A comparative analysis","description":"While TCP is a connection-oriented protocol, QUIC is a UDP-based protocol that combines transport and application-layer functions for faster performance. It works by multiplexing multiple streams over a single connection and reducing handshake overhead. It supports connection migration, enables 0-RTT handshakes, provides built-in congestion control, multiplexes streams without head-of-line blocking, and minimizes latency. In other words: QUIC establishes connections quickly, handles multiple streams efficiently, and adapts to changing network conditions without requiring multiple round trips for handshakes. So yeah, it’s really fast. But, it also takes a novel approach to security. While QUIC is a transport-layer protocol, it includes features that are traditionally found in both transport and security layers. So essentially it’s doing the work of something like TCP plus TLS, except that","sample":true,"doi":"10.1049/smc2.12083","short":"quic-tcp","released":"January 24th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFsf1UQM4Fd/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"QUIC vs TCP","carousels":["Network Engineering","Software Engineering","Web Development"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"quic-and-tcp-in-unsafe-networks-a-comparative-analysis"},{"title":"Real-Time Co-Editing of Geographic Features","description":"There are two broad categories of CRDTs: state-based and operation-based. In state-based CRDTs, each replica periodically shares its entire state with others, and a merge function is used to combine different states into a unified, conflict-free version. The merge function is designed to be idempotent (meaning that applying it multiple times has the same effect as applying it once), associative (meaning that the order of merging does not matter), and commutative (merging in different sequences leads to the same result). Operation-based CRDTs, in contrast, rely on propagating individual operations rather than entire states. Each operation is designed to be deterministic and to produce the same effect across all replicas, provided that it is delivered in causal order. This reduces the amount of data that needs to be transmitted. So in practice, operation-based CRDTs are","sample":false,"doi":"10.3390/ijgi13120441","short":"geographic-crdt","released":"January 23rd, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFRUW6eM3hN/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Realtime Co-Editing with CRDTs","carousels":["Data Structures","Software Engineering","Web Development"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"real-time-co-editing-of-geographic-features"},{"title":"A Review of DNA Cryptography","description":"DNA is unbelievably compact and efficient at storing and encoding information. As a medium, it can be stored without electricity (in dry pellet form or dissolved in a solution), for thousands and thousands of years. We’ve understood how DNA stores information since Watson & Crick discovered the double-helix in the ‘50s. But until recently we’ve only been able to marvel at that storage mechanism from afar. We haven’t been able to use DNA to store information ourselves. The storage mechanisms we’ve come-up with instead are, well…way worse. Hard drives, flash drives, magnetic tape, CDs, floppy disks, etc, don’t come anywhere close to DNA’s efficiency or durability. In order to use DNA as a storage medium, we’d need to be able to read and write DNA. That is “sequence” and \"synthesize\" it. Both of these processes have historically been cost prohibitive, but that’s changing","sample":false,"doi":"10.34133/icomputing.0106","short":"dna-cryptography","released":"January 22nd, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DHHp3t4s5LI/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"DNA Cryptography","carousels":["Genetics","Datastores","Bleeding Edge Technology","Security"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-review-of-dna-cryptography"},{"title":"Advancing breast cancer diagnosis: token vision transformers for faster and accurate classification of histopathology images","description":"The ViTs process images as a sequence of non-overlapping patches rather than pixel arrays. Unlike CNNs, which rely on local receptive fields and weight-sharing, ViTs divide an image up, and then convert the pieces into flattened feature vectors. These vectors are then passed through an embedding layer that encodes positional information to maintain spatial context. The core of the architecture is its multi-head self-attention mechanism, which allows the model to attend to different regions of the image simultaneously. Since it’s a transformer, it’s able to capture complex relationships between distant regions of the tissue sample that may not be immediately adjacent but are diagnostically significant. Each transformer layer applies self-attention operations followed by normalization and feed-forward layers to refine the feature representation.","sample":false,"doi":"10.1186/s42492-024-00181-8","short":"breast-cancer","released":"January 21st, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFMdTM5M-RY/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Histopathy Image Classification","carousels":["Classification","Oncology","Medicine","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"advancing-breast-cancer-diagnosis-token-vision-transformers-for-faster-and-accurate-classification-of-histopathology-images"},{"title":"The sociolinguistic foundations of language modeling","description":"On March 23rd, 2016, Microsoft released a product that...well...they’re probably hoping we’ve all forgotten about by now. It was called “Tay”, and it was a Twitter-bot using the handle @TayAndYou. It was designed to interact with users and learn from conversations, in real-time. People would tweet at Tay, Tay would tweet back, and, the hope was, that it would become a full-fledged thoughtful netizen, carrying on interesting conversations and showcasing the advancements that Microsoft had been making in AI. It’s difficult to describe just how quickly this project went off the rails. Within hours, Tay began to mirror and amplify the language patterns it encountered, generating increasingly offensive statements. As users trolled the bot, deliberately feeding it inflammatory and discriminatory text, Tay’s learning mechanisms, which lacked strong ethical or content moderation filters, quickly adapted to replicate those inputs","sample":false,"doi":"10.3389/frai.2024.1472411","short":"sociolinguistic-foundations","released":"January 20th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFKEeClMbEc/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Sociolinguistic Foundations of LLMs","carousels":["Linguistics","Sociology","Large Language Models"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-sociolinguistic-foundations-of-language-modeling"},{"title":"Efficient Data Exchange between WebAssembly Modules","description":"What is Wasm today? It’s changed a bit from its roots, but it’s kept the core idea unchanged: developers can write code in languages like C, C++, Rust, (or any one of many other languages that now have a Wasm compilation target), and can compile their code and ship it to anywhere that Wasm is supported. Despite the name, Web Assembly actually escaped the confines of the browser years ago. It is now just a first-class runtime for a number of different environments. Wasm runs in the cloud, it runs on the edge, it runs on iOT devices, it runs on embedded systems and gaming engines. It’s everywhere. And as Wasm has expanded the scope of its deployments, it’s also begun to run into a new set of problems. The kind of problems that weren’t necessarily issues back when it was confined to the browser. Today’s paper is focused on just one of those issues. Just one of the growing-pains that","sample":false,"doi":"10.3390/fi16090341","short":"webassembly-exchange","released":"January 19th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFHc0dts2sr/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"WebAssembly Data Exchange","carousels":["Software Engineering","Web Development"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"efficient-data-exchange-between-webassembly-modules"},{"title":"ABWOA: adaptive boundary whale optimization algorithm for large-scale digital twin network construction","description":"What do bees, ants, moths, bats, fish, birds and whales have in common? Give up? They all have optimization algorithms named in their honor. And today’s article is focusing on a new variant of that last one: whale optimization. In this paper it’s being used to solve a mapping problem for something called a Digital Twin Network (DTN). But the authors didn’t just solve that problem the one way, no. They actually solved it seven different ways, with seven algorithms, and then benchmarked them against each other. That gives us the opportunity to spend today’s episode taking a stroll through algorithm land. We’re going to ground ourselves in the problem-space very briefly, then spend the rest of the time learning about seven different algorithms. How they work, their strengths and weaknesses, and which one ended up being the best fit for the DTN problem. Let’s jump into it","sample":false,"doi":"10.1186/s13677-024-00667-z","short":"abwoa-whale","released":"January 18th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DFDNzfTs5DU/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"ABWOA Algorithm","carousels":["Algorithms","Optimization","Digital Twins","Network Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"abwoa-adaptive-boundary-whale-optimization-algorithm-for-large-scale-digital-twin-network-construction"},{"title":"Scalable data assimilation with message passing","description":"Have you ever wondered where weather forecasts come from, or how meteorologists generate them? Well, it’s a multi-step process, and there are a lot of moving pieces at play. But one of the most important parts is something called numerical weather prediction (NWP). NWP is the process of taking what’s called an “initial condition” and applying mathematical and physical equations to it, to turn it into a forecast. If the initial condition is correct, then the forecast has a good chance of accurately predicting future weather conditions. If the initial condition is wrong, then the forecast will likely diverge from reality. So, what is that initial condition, and where does it come from? The initial condition is the best estimate of the current state of the atmosphere","sample":false,"doi":"10.1017/eds.2024.47","short":"data-assimilation","released":"January 17th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DE_5w4OMQVj/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Data Assimilation","carousels":["Distributed Systems","Temporal Analysis","Climate Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"scalable-data-assimilation-with-message-passing"},{"title":"Dynamic-budget superpixel active learning for semantic segmentation","description":"Imagine that you went out and bought a big jigsaw puzzle. You take it home, open the box, flip it over and dump all the thousands of little pieces on the table. What’s the next thing you do? Well, I’m no puzzle-master, but the next thing I’d do is categorize all the pieces. This is basically a “classification” task. I have to look at each one, and say “that one is sky, that’s grass, that’s a piece of a building, that’s a part of a car, that’s a part of an animal, that’s a texture, that’s a pattern” etc. If I was a computer-vision model, and I was looking at pixels instead of puzzle-pieces, then this task would be called “semantic segmentation”. In semantic segmentation, a model scans through an image and classifies each pixel into a predefined category. As it reaches each pixel, it analyzes its features, and determines its class based on learned patterns","sample":false,"doi":"10.3389/frai.2024.1498956","short":"db-superpixel","released":"January 16th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DE8981EMAkC/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Semantic Segmentation","carousels":["Model Training","Computer Vision","Classification"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"dynamic-budget-superpixel-active-learning-for-semantic-segmentation"},{"title":"Analysis on dendritic deep learning model for AMR task","description":"In order to understand today’s paper, we need to start by wrapping our heads around the problem-space it’s working in. AMR: Automatic Modulation Recognition. Imagine there's a war-zone. And in that war-zone, two armies are duking it out: the red army and the green army. The red army has soldiers scattered across the land, and these soldiers carry devices that let them communicate with each other. (Radios, satellite phones, infrared beacons, field tablets etc). These devices all communicate somewhere on the spectrum, and there’s a finite amount of spectrum available to use because there are only so many bands of electromagnetic radiation. So, the issue is, the green army has access to all the same spectral bands as the red army. So if the red army soldiers try to send messages to each other across these frequencies","sample":false,"doi":"10.1186/s42400-024-00306-9","short":"dendritic-dl","released":"January 15th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DE6GALhsJgN/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Dendritic Deep Learning","carousels":["Deep Learning","Electromagnetic Spectrum","Telecommunications"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"analysis-on-dendritic-deep-learning-model-for-amr-task"},{"title":"Growing from Exploration: A Self-Exploring Framework for Robots Based on Foundation Models","description":"The planning and execution module decomposes tasks into executable sub-tasks, again using LLM-based reasoning. Each task is processed into a sequence of commands. These commands are specific to whatever kind of robot the system is running onboard. And they could either be straight from the SDK or from a source we haven’t mentioned yet. The system has an onboard list of previously acquired skills. They call it the skills library. We’ll come back to how skills get into the library in a moment. For now, just know that as the robot is exploring its environment, the actions it previously tried that were successful in other contexts are available to it in the skills library. Once a series of actions is chosen, the execution module generates code to control the robot. During execution, the module ensures task","sample":false,"doi":"10.26599/AIR.2024.9150037","short":"robot-exploration","released":"January 14th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DE39790sx-E/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Self-Exploring Robots","carousels":["Large Language Models","Robotics","Model Training"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"growing-from-exploration-a-self-exploring-framework-for-robots-based-on-foundation-models"},{"title":"A Polynomial-Time Algorithm for Detection of Uncovered Transitions in a Petri Net-Based Concurrent System","description":"When the algorithm gets called you need to pass it an incidence matrix, which is just the mathematical version of the diagram I described earlier. It starts by just initializing an empty list. This is where it’s going to store any uncovered transitions that it finds. Next, it flips (transposes) the rows and columns of the incidence matrix. This is just to prepare it for the next steps, which involve analyzing the transitions mathematically. Now, the algorithm reworks the transposed matrix into something called Reduced Row Echelon Form (RREF). This is a cleaned-up version where patterns in the data become much clearer. It involves reorganizing and simplifying the rows to highlight key features. With the RREF in hand, it then looks at each row (representing places in the system) to find transitions that","sample":true,"doi":"10.3390/app15020680","altLink":"https://www.mdpi.com/2076-3417/15/2/680","short":"petri-nets","released":"January 13th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DE1SG0PMdB3/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Petri-Net Concurrent System","carousels":["Algorithms","Data Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-polynomial-time-algorithm-for-detection-of-uncovered-transitions-in-a-petri-net-based-concurrent-system"},{"title":"To crop or not to crop: Comparing whole‐image and cropped classification on a large dataset of camera trap images","description":"There are two main approaches for this: one-step classification, and two-step classification. One-Step Classification: A whole image classifier (WIC) processes the entire image (or frame), including the entire background, and makes predictions based on all visible elements in the photo, without isolating the specific object of interest. Two-Step Classification: In this approach an object detector attempts to identify any prominent object in the frame, and it returns the coordinates of the bounding-box that encompasses that object. On the second step, an image classifier looks at the image, but only looks within the bounding box (the region of interest) determined in the first step. Both of these approaches work, and both are quite popular. But the ML community has been split over which option is better. Today’s paper is from a research team at Google, and they’re trying to put an end to that debate","sample":false,"doi":"10.1049/cvi2.12318","short":"crop-or-not","released":"January 12th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DEyiU-fsEC_/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Cropped Image Classification","carousels":["Classification","Computer Vision","Model Preprocessing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"to-crop-or-not-to-crop-comparing-wholeimage-and-cropped-classification-on-a-large-dataset-of-camera-trap-images"},{"title":"Study of Code Smells: A Review and Research Agenda","description":"Bucket 1 is the Bloaters. These arise when something in your codebase has grown too large to handle gracefully. These smells don’t immediately break your system but instead slowly erode its maintainability. Examples include the “Long Method”, where a single function becomes a sprawling labyrinth of logic. And the “Large Class”, which is stuffed with so many responsibilities it’s hard to tell what its primary purpose is. Another classic bloater is the “Long Parameter List”, which is a sign of poor abstraction, and requires the caller to juggle too many pieces of data at once. Left unchecked, bloaters bog down your code, making it harder to navigate, extend, or debug. Bucket 2, the Object-Orientation Abusers, is all about misusing or misunderstanding fundamental principles of OOP. This bucket includes","sample":false,"doi":"10.33889/IJMEMS.2024.9.3.025","short":"code-smells","released":"January 11th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DEwHoedMTvB/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Code Smells","carousels":["Contiuous Integration","Software Engineering","Debugging"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"study-of-code-smells-a-review-and-research-agenda"},{"title":"Odatix: An open-source design automation toolbox for FPGA/ASIC implementation","description":"The year was 1985, and Ross Freeman had a problem. He was trying to design hardware solutions (computer chips) that could be quickly adapted to evolving requirements. But the existing options of the day didn’t fit. General-purpose microprocessors, ASICs, and hardwired logic boards weren’t flexible enough. Programmable logic boards and devices weren’t powerful enough. He needed a platform that was as capable as an ASIC, but could be reprogrammed after manufacturing, without the cost and time of creating a new chip for every use case. He envisioned a new kind of device that combined the efficiency and performance of hardware, with the adaptability of software. A computer chip that could be iterated upon; modified and customized over and over again. The result was the world’s first FPGA: the Field-Programmable Gate Array","sample":false,"doi":"10.1016/j.softx.2024.101970","altLink":"https://www.sciencedirect.com/science/article/pii/S2352711024003406","short":"odatix-fpga","released":"January 10th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DEtx28tM1Eh/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"FPGA/ASIC Implementation","carousels":["FPGAs","ASICs","Computing Hardware","Computer Chips"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"odatix-an-open-source-design-automation-toolbox-for-fpgaasic-implementation"},{"title":"Cloud Removal in the Tibetan Plateau Region Based on Self-Attention and Local-Attention Models","description":"At a high level, you can think of their system as a pipeline. It leverages both multi-temporal data and advanced attention mechanisms. At its core, the model integrates a combination of spatial, spectral, and contextual information. That is all just a fancy way of saying two things: It looks at different photos from the same area over time. Clouds move, so if you pay attention to one big area, and take a series of photos over time, the areas that are cloud-free will change over time. And if you collect enough photos eventually you’ll have at least one cloud-free view of every region in that area. Then you’ll be able to collage together a single photo that is wholly cloud-free. Snow-cover and cloud-cover may look the same in photos, but that’s only representing the visible light spectrum","sample":false,"doi":"10.3390/s24237848","short":"tibetan-plateau","released":"January 9th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DErDI7VM8YO/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Automated Cloud Removal","carousels":["Computer Viseion","Self Attention"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"cloud-removal-in-the-tibetan-plateau-region-based-on-self-attention-and-local-attention-models"},{"title":"Decoupling Implantation Prediction and Embryo Ranking in Machine Learning: The Impact of Clinical Data and Discarded Embryos","description":"There are two distinct machine learning tasks in play here: embryo-ranking, and implantation-prediction. They are similar-enough problems that clinicians use the same machine learning model for both tasks. The authors are saying that these two activities actually have slightly conflicting objectives, and therefore using the same model for both is wrong. The status-quo is fine for implantation-prediction, but when you use that model for embryo-ranking, the rankings are incorrect. This is because of a very subtle and difficult-to-understand phenomenon that we have never talked about on Journal Club before. It’s called the “shortcut learning” bias. And in the case of these IVF procedures, shortcut-learning is sabotaging the patient’s chance at a successful pregnancy.","sample":false,"doi":"10.1002/aisy.202400048","short":"decoupling-implantation","released":"January 8th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DEoOFPKMcmq/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Embryo Implantation Prediction","carousels":["Medicine","Model Bias","Model Training"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"decoupling-implantation-prediction-and-embryo-ranking-in-machine-learning-the-impact-of-clinical-data-and-discarded-embryos"},{"title":"Automated redaction of names in adverse event reports using transformer-based neural networks","description":"Imagine you’re writing a function called “redact_names”. It takes one parameter, a string. Your function needs to accept the string, replace any names with a series of asterisks, and return the string. It needs to handle all the corner-cases I mentioned above (full names, partials names, and initials). But remember, people’s names may have any kind of capitalization or no capitalization at all. They may be one word, or one letter, or a series of words and letters. A name could be two words, or three, or four or more. There may even be standalone sentences that contain nothing but a name. And in other cases there may not be any names in the passage at all. Think that’s not complicated enough? It gets worse. Medical writing is often chock-full of what are called “medical eponyms”","sample":false,"doi":"10.1186/s12911-024-02785-9","short":"name-redaction","released":"January 7th, 2025","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Automated Name Redaction","carousels":["Medicine","Natural Language Processing","Transformers"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"automated-redaction-of-names-in-adverse-event-reports-using-transformer-based-neural-networks"},{"title":"Context-Adaptable Deployment of FastSLAM 2.0 on Graphic Processing Unit with Unknown Data Association","description":"There’s been a lot of talk about GPUs lately, and almost all of that talk has either been about graphics processing, crypto mining, or machine learning. But, there is a small community of developers who are thinking beyond those buckets. Developers who are wondering out loud: \"What if we wrote lots of programs to run directly on GPUs? What if we used their parallel structure to handle the concurrency problems inherent in all kinds of applications?\" This idea is broadly referred to as \"GPGPU\". It stands for General Purpose computing on GPUs. Today we’re going to look at a paper that embraces the GPGPU paradigm. The authors are building a SLAM system (a Simultaneous Localization and Mapping tool), that allows a robot to map their environment and understand their position at the same time","sample":false,"doi":"10.3390/app142311466","short":"gpgpu-fastslam","released":"January 6th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DEgke98sZLj/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"GPGPU FastSLAM","carousels":["GPUs","Algorithms","Software Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"context-adaptable-deployment-of-fastslam-20-on-graphic-processing-unit-with-unknown-data-association"},{"title":"Enabling per-file data recovery from ransomware attacks via file system forensics and flash translation layer data extraction","description":"User-space ransomware works within the permissions granted to standard user accounts. This means it cannot modify system-level configurations or access kernel data. This also means, critically, that if you have backups or restore-points in protected areas that require administrator privileges, those are also safe. What the ransomware can do is encrypt most user files, as these are typically within the permissions of a standard account. Root-privileged ransomware, on the other hand, is significantly harder to detect and mitigate. Root-level ransomware can disable security tools, encrypt backups, and render entire systems inoperable. Today we're looking at a paper that presents a new mitigation option for user-space ransomware only. It won't really apply to anything operating with root privileges.","sample":false,"doi":"10.1186/s42400-024-00287-9","short":"ransomware-attacks","released":"January 5th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DEeN_28MVRU/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Per-File Attack Recovery","carousels":["Security","Operating Systems"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"enabling-per-file-data-recovery-from-ransomware-attacks-via-file-system-forensics-and-flash-translation-layer-data-extraction"},{"title":"FAIR-MAST: A fusion device data management system","description":"This story takes place at the Culham Centre for Fusion Energy (CCFE), located on the outskirts of Oxford in the UK. There are a number of different types of nuclear fusion reactors in the world, and the specific kind they’re working with at CCFE is called a tokamak. It’s originally a Russian design, and the name comes from an acronym that only makes sense in Russian, but roughly translates to \"toroidal chamber with magnetic coils\". If you’ve ever seen a photo of a fusion reactor that looked like a giant metal donut, that was probably a tokamak. The CCFE, like virtually all other nuclear-fusion sites, isn't trying to generate power for commercial purposes. Not yet, anyway. It’s a research facility. Before a fusion power plant can ever","sample":false,"doi":"10.1016/j.softx.2024.101869","altLink":"https://www.sciencedirect.com/science/article/pii/S2352711024002395","short":"fusion-data","released":"January 4th, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DEbEb4isn7Z/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fusion Device Data","carousels":["Physics","Nuclear Power","Big Data","Data Science","Nuclear Fusion"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fair-mast-a-fusion-device-data-management-system"},{"title":"PDGPT: A large language model for acquiring phase diagram information in magnesium alloys","description":"At first glance, this paper appears to be about magnesium alloys. But if you go just beneath the surface, it’s really about LLMs, and the techniques you can use to squeeze more functionality out of them. In this paper the authors are trying to build an LLM that can function as an expert system for magnesium alloy phase-diagrams. That topic is extremely narrow, but incredibly deep. And in order to function as an expert, their model must incorporate a ton of highly specific information about that field, including thermodynamic principles, multi-component alloy systems, phase transition behaviors, and huge industry-specific datasets. They decided to try out three different methods to accomplish this: 1) Base (unmodified) LLMs with prompt-engineering. 2) Base LLMs with RAG. 3) New models created with SFT. SFT stands for Supervised Fine Tuning. In the last-year or so, OpenAI made an endpoint available where you can","sample":false,"doi":"10.1002/mgea.77","short":"pdgpt-sft","released":"January 3rd, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DEY2UvvMVTJ/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"LLM for Phase Diagrams","carousels":["Large Language Models","Materials Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"pdgpt-a-large-language-model-for-acquiring-phase-diagram-information-in-magnesium-alloys"},{"title":"Enhancing Data Security Through VLSM Subnetting and TCP/IP Model in an ENT","description":"If you’ve gotten used to creating VPCs on AWS or GCP, (or VNets on Azure), then you’ve probably become pretty spoiled. All those configuration options, and knobs and dials. The CIDR blocks and subnets and masks. All that comes out of the box when you’re working in the cloud. But if you’re administering a traditional corporate network for an enterprise, the picture is probably very different. These kinds of legacy systems don’t provide nearly the functionality that you might want and need to support the company’s growing demands. And that’s where this paper comes in. The authors are proposing what they’re calling an ENT: An Enhanced Network Topology that makes a number of changes all-at-once to quickly modernize older networks.","sample":false,"doi":"10.3390/app142310968","short":"vlsm-subnetting","released":"January 2nd, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DEWifB3s4F6/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"VLSM Subnetting","carousels":["Network Engineering","Security"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"enhancing-data-security-through-vlsm-subnetting-and-tcpip-model-in-an-ent"},{"title":"Causal contextual bandits with one-shot data integration","description":"When you’re playing a slot-machine, you’re making a series of choices based on the information and feedback you’re receiving from the interface. Each pull of the lever represents a decision to act, based on the outcome of previous plays. Over time, you start to gather information about potential rewards, and you must decide whether to continue playing, stop, or change strategies. You are effectively balancing the uncertainty of future rewards against the results you’ve been observing. This is called a sequential decision-making problem, and it is very similar to many other decisions that you, (or another person, or a business, or an autonomous-car) need to make all the time. In many aspects of life, you're taking actions, observing outcomes, and making choices that (ideally) optimize your results over time.","sample":false,"doi":"10.3389/frai.2024.1346700","short":"causal-contextual-bandits","released":"January 1st, 2025","instagram":"https://www.instagram.com/journalclub.io/reel/DETtCSgsvBo/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Causal Contextual Bandits","carousels":["Gambling","Reinforcement Learning","Algorithms","Optimization"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"causal-contextual-bandits-with-one-shot-data-integration"},{"title":"Computational Cost and Implementation Analysis of a Wavelet-Based Edge Computing Method for Energy-Harvesting Industrial IoT Sensors","description":"Wavelets are mathematical functions that are designed to analyze data at different scales or resolutions. Think of a camera with different zoom-levels or lenses. When you zoom in you see more detail but less of the whole context, and when you zoom out you see the whole picture, but fewer details. That's like a wavelet adjusting its focus to capture both the fine details or the broader trends of a signal. A wavelet transform uses these wavelets to break a signal into its components, separating coarse, low-frequency information (the \"big picture\") from finer, high-frequency details (the \"small nuances\"). This decomposition allows for efficient analysis while still preserving the essential characteristics of the signal. These authors use two types of transforms","sample":false,"doi":"10.1109/ACCESS.2024.3519715","short":"wavelet-transforms","released":"December 31st, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DERQlXisuwp/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Wavelet Based Edged Computing","carousels":["Cloud Computing","Edge Computing","IoT"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"computational-cost-and-implementation-analysis-of-a-wavelet-based-edge-computing-method-for-energy-harvesting-industrial-iot-sensors"},{"title":"Sustainable Environmental Technologies: Recent Development, Opportunities, and Key Challenges","description":"At Journal Club, we spend a lot of time talking about technologies that are, from an environmental perspective, inherently unsustainable. At least in their current forms. It’s worth taking a moment to remind ourselves that a significant number of the GPUs that were mining crypto a few years ago, are still running at full throttle. It’s just that now they’ve been repurposed to power ML instead. So, all the same environmental critiques that were made of crypto back then could be made of AI today. One would hope that, today, all that energy is being put to a more noble use, but still...carbon footprint is carbon footprint. And I’m sure there's room for all of us to do better. Since we’re about to put a bow on 2024, I figured that now would be a good time to take a look at a few technologies that are on the other side of the fence. The green side","sample":false,"doi":"10.3390/app142310956","short":"sustainable-environmental-technologies","released":"December 30th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DEOroEXs0br/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Sustainable Environmental Technologies","carousels":["Environmental Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"sustainable-environmental-technologies-recent-development-opportunities-and-key-challenges"},{"title":"Selective state models are what you need for animal action recognition","description":"With all the fanfare around tools like ChatGPT, Claude and Gemini, it can be easy to think that transformer architectures are the be-all end-all of AI. That they represent the latest and greatest technology for processing text, media, and documents of all kinds. In reality, they don’t. There was a single point in time when transformer architecture was the bleeding-edge for the use cases it was designed to fill, but that was a few years ago. In the time since then, the research hasn’t stopped. And in fact, a whole new generation of models and architectures have been developed in recent years with the deliberate aim of overcoming some of the specific limitations of transformers. One of those new architectures is called Mamba","sample":false,"doi":"10.1016/j.ecoinf.2024.102955","short":"selective-state","released":"December 29th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DEMWKqssefm/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Selective State Models","carousels":["Computer Vision","Ecology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"selective-state-models-are-what-you-need-for-animal-action-recognition"},{"title":"Smart medical report: efficient detection of common and rare diseases on common blood tests","description":"Some diseases are pretty straightforward to diagnose. If you're unfortunate enough to have something like hep-b or mononucleosis, your doctor should be able to order a test that will give you a definitive result fairly quickly. But that's not how all (or even most) diseases work. For a great number of illnesses: like chronic kidney disease, autoimmune disorders, or Wilson's Disease, there may not be an antibody test, or reactive test, or any other kind of rapid diagnostic kit. There's no single point-in-time way to tell if you have the condition or not. The only way your doctors can diagnose those kinds of illnesses","sample":false,"doi":"10.3389/fdgth.2024.1505483","short":"blood-tests","released":"December 28th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DEJb7wUsu8N/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Rare Disease Identification","carousels":["Medicine","Diagnostic Medicine","Hematology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"smart-medical-report-efficient-detection-of-common-and-rare-diseases-on-common-blood-tests"},{"title":"Analysis of project management principles with the Scrum framework in systems development: a case study in a public organization","description":"Let’s start at the beginning. Up until about two decades ago, you didn’t download software. You bought it at a store, in a box. It was a physical product. For that to happen, the software had to be put on some kind of medium, boxed, wrapped, put in a bigger box with others smaller boxes, then put on a pallet with other bigger boxes, wrapped in shrinkwrap, stored in a warehouse, sent to a distributor, trucked to the store, unpacked, and put on a shelf. There was a physical supply chain, and getting your code from your workstation to the customer’s machine took a very long time, and was very expensive. For this reason, software updates were","sample":false,"doi":"10.14488/BJOPM.1878.2024","short":"scrum-case","released":"December 27th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DEHPW3uMY5s/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Project Management with Scrum","carousels":["Project Management","Engineering Management","Agile","Scrum"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"analysis-of-project-management-principles-with-the-scrum-framework-in-systems-development-a-case-study-in-a-public-organization"},{"title":"Cost modeling and optimization for cloud: a graph-based approach","description":"As Engineers we rarely think about infrastructure costs. But once an application reaches a certain scale (or when a startup runs out of free credits) we no longer have a choice. We have to think about it. We need to be able to predict financial costs just as accurately as we can predict uptime and load speeds. Off the shelf calculators (like the kind that the cloud-host provides) are fine for small things, but if you need to predict the costs of dozens or hundreds of interconnected pieces of infrastructure, you need something more robust. You need a financial model. The question is, how do you do that? How do you build one of those? That’s what today’s paper is all about","sample":false,"doi":"10.1186/s13677-024-00709-6","short":"cost-modeling","released":"December 26th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DEEQSKNsnfl/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Cost Modeling Cloud Infrastructure","carousels":["Cloud Computing","Engineering Management","Data Structures"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"cost-modeling-and-optimization-for-cloud-a-graph-based-approach"},{"title":"Seamless Transition to Post-Quantum TLS 1.3: A Hybrid Approach Using Identity-Based Encryption","description":"Today is a special episode of Journal Club. This is the first installment of a series I’m calling \"Post Quantum Readiness\". I’m going to sprinkle these episodes in every once in a while over the next year, or two, or however long they’re needed. While the goal of every Journal Club episode is to get you up to speed on some new research (and this episode is no exception in that regard), this \"Post Quantum Readiness\" series is going to be much more focused on practical advice. We’re going to be looking at research papers of course, but for this series we’re specifically trying to extract three things from them: 1. What you need to know now. 2. What you’ll need to know tomorrow. 3. Calls to action. Steps you can take immediately to start to get ahead of this.","sample":false,"doi":"10.3390/s24227300","short":"post-quantum-part-1","released":"December 25th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DEBjgU5slWB/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Post Quantum TLS","carousels":["Security","Quantum Computing","Encryption","Network Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"seamless-transition-to-post-quantum-tls-13-a-hybrid-approach-using-identity-based-encryption"},{"title":"Network architecture for single image super-resolution: A comprehensive review and comparison","description":"Did you ever watch that show CSI: Crime Scene Investigation? In many episodes, there will be one character sitting at a computer pulling up video surveillance of the crime scene or somewhere nearby. And another character will see some blurry suspect or object in the video and say something like “Wait, pause that. Now zoom in and enhance!” The person at the computer will type a few keystrokes, and just like magic, the grainy frame of the perpetrator will turn into a high resolution photo. This has been a Hollywood trope for decades. In reality, we are just now (in the last few years) getting to the point that we have the ability to do anything close to that with normal hardware. And that genre of technology is called SISR: Single Image Super Resolution","sample":false,"doi":"10.1049/ipr2.13100","short":"sisr","released":"December 24th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DD_euyDs1w8/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Single Image Super-Resolution","carousels":["Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"network-architecture-for-single-image-super-resolution-a-comprehensive-review-and-comparison"},{"title":"Fractal Neural Network Approach for Analyzing Satellite Images","description":"An FNN is built using fractal blocks, which are modular units that repeat. Each block contains standard components like convolutional layers for extracting features from input data, and pooling layers for reducing dimensionality and retaining important information. What makes FNNs unique is how these blocks are organized: instead of stacking layers linearly as in traditional neural networks, the architecture branches recursively. At each recursive step, a fractal block is expanded into multiple sub-blocks, which are connected in parallel paths. But unlike in a true fractal, this only repeats for a range, not infinitely. Let’s walk through the points at which an FNN diverges from a CNN, and what it does differently. In a traditional CNN, layers are stacked, (as I mentioned), sequentially. With each layer processing","sample":false,"doi":"10.1080/08839514.2024.2440839","short":"fractal","released":"December 23rd, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DD8ZGVDsxIa/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fractal Neural Networks","carousels":["Computer Vision","Convolutional Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fractal-neural-network-approach-for-analyzing-satellite-images"},{"title":"Probabilistic photonic computing with chaotic light","description":"Optical computers are fundamentally different from traditional electronic computers. In essence, they use photons (light) rather than electrons to process and transmit information. This shift in medium leads to several critical distinctions in how components operate and interact. Recall that at the heart of traditional computers is the transistor, a semiconductor device that controls the flow of electrons to perform logical operations and amplify signals. In contrast, optical computers leverage optical transistors (or similar photonic components) that control and manipulate light. Unlike electronic transistors, which rely on voltage or current, optical transistors operate through phenomena such as nonlinear optical effects, where one light beam can modulate another. This enables optical components to switch signals at speeds closer to the speed of light, significantly faster than the electron mobility in silicon","sample":false,"doi":"10.1038/s41467-024-54931-6","short":"photonic","released":"December 22nd, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DD6T-gSMAAz/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Photonic Computing","carousels":["Physics","Electromagnetic Spectrum","Computing Hardware"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"probabilistic-photonic-computing-with-chaotic-light"},{"title":"Advanced R-GAN: Generating anomaly data for improved detection in imbalanced datasets using regularized generative adversarial network","description":"A GAN is a type of machine learning model that is able to generate (synthesize) new data that resembles its training data. It doesn’t just take one piece of its training data and give it to you, it creates new data that was not actually part of its training, but that shares a number of similar characteristics with the data it saw during training. It does this by having two different core components: a generator, and a discriminator. Think of the generator as the artist, and the discriminator as the critic. The generator creates new things and tries to pass them off as being part of the original training set. The critic evaluates them, either saying \"no, I can tell this wouldn't have been in the training set\", or \"yes, this fooled me. It looks like the training data\". The process of synthesizing data in a GAN can be thought of as a back-and-forth conversation between these two “adversaries”. Thus the name: Adversarial Network.","sample":false,"doi":"10.1016/j.aej.2024.10.084","short":"gan","released":"December 21st, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DD3pVhessRy/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"R-GAN for Imbalanced Datasets","carousels":["Model Training","Adversarial Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"advanced-r-gan-generating-anomaly-data-for-improved-detection-in-imbalanced-datasets-using-regularized-generative-adversarial-network"},{"title":"Edge Computing Architecture for the Management of Underwater Cultural Heritage","description":"Your mission is to travel to a new site and install sensors, monitoring, and edge nodes as usual. But there’s a catch. This cultural heritage site… is underwater. It’s not a dig-site or a cave, it’s an ancient shipwreck. So now you’ve got some thinking to do. How does the heritage-site being underwater change what you need to build? What’s the same, and what’s different? Let’s walk through it. There are five key differences: 1. There’s no power in the middle of the ocean. 2. Radio signals attenuate in water. 3. GPS is ineffective under water. 4. Not only is everything going to get wet, but pressure is high, temps are cold and saltwater corrodes everything. 5. Connectivity to the cloud will be possible, but limited. You’re no longer working in vanilla IoT. This is IoUT, the Internet of Underwater Things.","sample":false,"doi":"10.3390/jmse12122250","short":"uch","released":"December 20th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DD0-rQHsELd/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Underwater Edge Computing","carousels":["Cloud Computing","Edge Computing","IoT"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"edge-computing-architecture-for-the-management-of-underwater-cultural-heritage"},{"title":"A five-phase combinatorial approach for solving a fuzzy linear programming supply chain production planning problem","description":" The authors argue that traditionally, you would solve this problem by gathering all your data then solving it as a fuzzy linear programming (FLP) problem. But, in this case, they say that’s not good enough. So this paper is introducing a new strategy that gets better results. It’s a five-phase combinatorial method that integrates five separate ideas: Triangular Intuitionistic Fuzzy Numbers (TIFN), Intuitionistic Fuzzy Linear Programming (IFLP), Realistic Robust Programming (RRP), Chance-Constrained Programming (CCP) and Augmented Epsilon Constraint (AUGMECON). Their argument is that this new system improves on FLP by allowing hesitation, ensuring robustness, considering both satisfaction and non-satisfaction levels, and generating Pareto-optimal solutions.","sample":false,"doi":"10.1080/23311916.2024.2334566","short":"scpp","released":"December 19th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDyGEwKsRrn/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Five-Phase Combinatoral Approach","carousels":["Fuzzy Logic","Linear Programming","Optimization","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-five-phase-combinatorial-approach-for-solving-a-fuzzy-linear-programming-supply-chain-production-planning-problem"},{"title":"State-of-the-Art Trends in Data Compression: COMPROMISE Case Study","description":"If I say peanut butter and _______, you’ll probably be able to guess “jelly”. That's just something your brain can do. In computer science we’d call this predictive modeling. That’s been the foundation for a lot of the things we use everyday, from the autocomplete in the search bar, to ChatGPT. In today’s paper we’re going to see predictive modeling applied to data compression. The authors have developed a system that compresses files to a smaller size (than normal compression-algorithms) by just leaving out chunks of the data. The idea being: they’ll be able to guess what was removed when they go to decompress it. While this approach isn’t fundamentally different from how modern compression works (other algorithms do use predictive modeling), these authors introduce new mechanisms, and error-correction systems that are genuinely novel. They call their new system: COMPROMISE.","sample":false,"doi":"10.3390/e26121032","short":"compromise","released":"December 18th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDv66DzsNe_/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Trends in Data Compression","carousels":["Bleeding Edge","Data Science","Data Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"state-of-the-art-trends-in-data-compression-compromise-case-study"},{"title":"Design and Deployment of ML in CRM to Identify Leads","description":"Today we’re going to be looking at a system-design paper that is not actually for a standalone application at all. The system the authors are building is actually just a very complex plugin (or extension) for CRMs: Customer Relationship Management platforms. Specifically, this one works with Salesforce, and the \"Apex\" developer platform. That being said, the Salesforce-specific code is really just a tiny part of it. The vast majority of their work is around training an ML model that can review an incoming lead, and attempt to “qualify” that lead programmatically. It then assigns that lead a score, which gets pulled into the CRM","sample":false,"doi":"10.1080/08839514.2024.2376978","short":"crm","released":"December 17th, 2024","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"CRM Lead Identification","carousels":["Sales","System Architecture","Regression","Cloud Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"design-and-deployment-of-ml-in-crm-to-identify-leads"},{"title":"An algorithmic multiple attribute decision-making context to model uncertainty associated with the hospital site selection problem using complex sv-neutrosophic soft information","description":"If you open up the PDF for today’s article, you’ll see that the meat of the paper is all formulas. It’s just equation after equation. I’m not going to read them to you, that would be an awful episode. Instead, I’m going to do my best to break down the mathematical foundation on which this paper is based. Then I’ll explain how they’re using those formulas, and what they’re trying to accomplish. The math in this paper is all based on Set Theory, so we’re going to start there. Technically, it’s all based on single-valued neutrosophic soft sets…but we’ll need to build-up to that. Set theory is a foundational area of mathematics that deals with the study of collections of objects, known as sets. It provides a framework for defining and manipulating collections of elements. In set theory, operations like union, intersection, and complement define how sets relate to one another, while concepts like","sample":false,"doi":"10.1080/08839514.2024.2375110","short":"hospital","released":"December 16th, 2024","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Neutrosophic Soft Information","carousels":["Optimization","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"an-algorithmic-multiple-attribute-decision-making-context-to-model-uncertainty-associated-with-the-hospital-site-selection-problem-using-complex-sv-neutrosophic-soft-information"},{"title":"Ideological orientation and extremism detection in online social networking sites: A systematic review","description":"If Section 230 gets nerfed by the incoming administration, social media sites will need to get a handle on hate-speech and extremism very quickly. Every modern social media platform has a hate-speech problem, and this is nothing new. In fact, the authors of today’s paper were able to find 110 different studies in which the investigators attempted to build a system for identifying and classifying that kind of language and behavior. Then, they ran a \"systematic-review\" (which is like a fancy meta-analysis), on all the papers to determine the best way that we can use technology to identify ideological extremism. That’s what this paper is about. It’s a head to head shootout between six different approaches, to figure out which is most effective. Let’s review each type of approach, then look at how these authors conducted their comparisons, and finally take a look at their conclusions.","sample":false,"doi":"10.1016/j.iswa.2024.200456","short":"hate-speech","released":"December 15th, 2024","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Extremism Detection","carousels":["Political Science","Sociology","Natural Language Processing","Deep Learning","Convolutional Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"ideological-orientation-and-extremism-detection-in-online-social-networking-sites-a-systematic-review"},{"title":"Detecting drug transfers via the drop-off method: A supervised model approach using AIS data","description":"In the 1970’s and 80’s, a strange fish was regularly sighted off the coast of Miami, bobbing up and down in the water. It was big, brown, and oddly...rectangular. The locals had a name for it: the “square grouper”. The square grouper was, of course, not actually a fish. It was a compressed bale of illegal drugs that traffickers had dropped out of a plane into the water so that a smaller vessel (often a speedboat) could scoop it up. In modern times, this is known as the “drop-off” method, and in today’s paper the authors attempt to train a model that can detect when a boat is engaging in this kind of illegal behavior. We’re going to walk through what the modern-day version of a drop-off looks like, how other researchers have tried to detect this behavior before, and exactly what these authors are doing differently.","sample":false,"doi":"10.1016/j.mlwa.2024.100590","short":"drop-off","released":"December 14th, 2024","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Detecting Drug Transfers","carousels":["Criminal Science","Drug Enforcement","LSTMs"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"detecting-drug-transfers-via-the-drop-off-method-a-supervised-model-approach-using-ais-data"},{"title":"Optimized Edge-Cloud System for Activity Monitoring Using Knowledge Distillation","description":"The complexity came mostly in step 2: Getting low-power edge nodes to run lightweight models. Deploying models on edge devices like NVIDIA Jetson Nano, which have limited GPU cores and memory, is challenging. Modern deep learning and CV architectures often involve millions or even billions of parameters, and they need to perform 3D convolutional operations to extract spatial and temporal features from video frames. This is necessary for accurate action recognition, but it requires substantial memory and processing capabilities. To make this possible in a resource-constrained environment, the authors applied Knowledge Distillation, a model compression technique that creates smaller, more efficient models while preserving much of the predictive accuracy of larger, more complex models. In this process","sample":false,"doi":"10.3390/electronics13234786","short":"aal","released":"December 13th, 2024","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Activity Monitoring with Distillation","carousels":["Model Training","Edge Computing","Cloud Computing","MLOps","Model Performance"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"optimized-edge-cloud-system-for-activity-monitoring-using-knowledge-distillation"},{"title":"Save A Life Maps-Traffic Clearance System for Emergency Services","description":"The routing algorithm starts by decoding the route polyline string (received from Google Maps), into a series of waypoints. Each waypoint is a latitude-longitude pair. The waypoints are then filtered to reduce unnecessary computational overhead. A filtering service selects only waypoints that are at least 500 meters apart, minimizing the total number of points while maintaining path accuracy. The immediate-waypoint service then takes in that information, and identifies the next two waypoints along the path from the current position of the emergency vehicle. These waypoints guide the real-time navigation process and serve as reference points for subsequent route recalculations. The real-time location of the vehicle is continuously tracked, and the route is continuously recalculated in real-time.","sample":false,"doi":"10.1080/08839514.2024.2429185","short":"save-a-life","released":"December 12th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDtIVsLM-s9/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Traffic Clearance System","carousels":["Civil Engineering","Public Health","Transportation"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"save-a-life-maps-traffic-clearance-system-for-emergency-services"},{"title":"Unsupervised Machine Learning Approaches for Test Suite Reduction","description":"Back when I was managing Engineering teams, code coverage was everything. I spent an inordinate amount of time pushing our Engineers to raise the coverage-level as high as we could raise it. More unit tests, more component tests, more end-to-end and integration tests, more smoke tests, more everything. For me, the coverage-reporter was the strongest indicator of our code quality and the stability of our system. Statements, branches, functions, lines: those breakouts were my scorecard, and my teams probably spent more time improving those numbers than anything else. Back then, if you would have given me the option of reducing the number of tests on our codebase, I never would have taken it. In fact, I probably would have laughed in your face. But...The Times They Are A-Changin","sample":false,"doi":"10.1080/08839514.2024.2322336","short":"test-reduction","released":"December 11th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDqe8fbsA0r/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Test Suite Reduction","carousels":["Software Engineering","Engineering Management","Continuous Integration"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"unsupervised-machine-learning-approaches-for-test-suite-reduction"},{"title":"Optimized efficient job scheduling resource (OEJSR) approach using cuckoo and grey wolf job optimization to enhance resource search in cloud environments","description":"Cuckoo Search Optimization (CSO) is a metaheuristic algorithm inspired by the unique reproductive behavior of certain cuckoo bird species. These birds lay their eggs in the nests of other bird species, relying on the host birds to incubate and raise their offspring. If the host bird detects an alien egg, it may either abandon the nest or destroy the egg. This ensures that only the most deceptive and well-hidden eggs survive. This biological process serves as a metaphor in CSO, where \"eggs\" represent potential solutions to an optimization problem, and \"nests\" are different candidate solutions in the search space. The algorithm's ability to balance exploration and exploitation of the search space","sample":false,"doi":"10.1080/23311916.2024.2335363","short":"cuckoo","released":"December 10th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDn-_4Es1c3/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Grey Wolf Optimization","carousels":["Algorithms","Optimization","Cloud Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"optimized-efficient-job-scheduling-resource-oejsr-approach-using-cuckoo-and-grey-wolf-job-optimization-to-enhance-resource-search-in-cloud-environments"},{"title":"A Temporal Graph Network Algorithm for Detecting Fraudulent Transactions on Online Payment Platforms","description":"Temporal Graph Networks (TGNs) extend GNNs by incorporating time-sensitive interactions into the graph structure. Unlike static graphs, which capture a frozen view of relationships, temporal graphs model how relationships evolve over time. TGNs process sequences of time-stamped events, making them well-suited for dynamic environments like online payment systems where transactions occur continuously. Each time a relevant event happens—such as a credit card being linked to a device or a payment being made—TGNs update their understanding of the network state. TGNs rely on event-based temporal graphs (ETGs) rather than snapshot-based graphs. Snapshot-based graphs divide","sample":false,"doi":"10.3390/a17120552","short":"tgn","released":"December 9th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDlRLMgs9h2/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Temporal Graph Network","carousels":["Graphs","Finance","Fraud Detection","Temporal Analysis"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-temporal-graph-network-algorithm-for-detecting-fraudulent-transactions-on-online-payment-platforms"},{"title":"Morpheus: A library for efficient runtime switching of sparse matrix storage formats","description":"In ML, matrices are vital because they naturally encode data, models, and computations in a compact and efficient manner. You might have previously heard that ML runs on vectors, and that’s largely true, but matrices are just as important and often work in conjunction with vectors. Vectors represent individual data points or model parameters, while matrices enable large-scale data processing by grouping vectors together. So it’s really both of those concepts together that form the numerical underpinning of machine learning. Matrices support a wide range of tasks that ML pipelines rely on. Notably: data representation, model parameterization, and numerical computation.","sample":false,"doi":"10.1016/j.softx.2024.101775","short":"morpheus","released":"December 8th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDicjOlMhMw/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Sparse Matrix Storage Formats","carousels":["Databases","Model Training","Data Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"morpheus-a-library-for-efficient-runtime-switching-of-sparse-matrix-storage-formats"},{"title":"Ambience: an operating system for IoT microservices","description":"Why embark on any of this at all? What problem are they actually solving? What unmet need is there that they’re trying to fill? The first thing to know is that we're not talking about microservices running on big servers or the public cloud (AWS, GCP, etc.). We're talking about microservices running in highly resource-constrained environments, specifically IoT devices. This could be a smart thermostat, a wearable health tracker, a factory floor sensor, or a wildlife monitoring system. Either way, don't think of the playing field as a big hulky processors with a ton of horsepower and memory. It's the opposite of that.","sample":false,"doi":"10.55056/jec.786","short":"ambience","released":"December 7th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDgMsmUMxWs/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Operating System for Microservices","carousels":["Operating Systems","Microservices","Softare Engineering","IoT"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"ambience-an-operating-system-for-iot-microservices"},{"title":"A Three-Stage Heuristic For Optimizing Container Relocations In Maritime Container Terminals","description":"Every stack is a LIFO queue (last-in-first-out), so there’s only one solution, right? Wrong. It’s more complicated than that. Here’s why. And this is what makes it NP-Hard: Each container that is in the way of the container you want to reach is called a “blocking” container. Every time you move a blocking container, you have to decide where to put it, and that decision has consequences for future retrievals. Not only does each stack have height limitations, but the placement of that container on another stack can either make future retrievals easier or harder depending on the sequence of container requests that come later. If you move a container to a stack where it blocks another container that will be needed soon, you’ve effectively created an additional retrieval problem for yourself.","sample":false,"doi":"10.3846/transport.2024.21668","short":"three-stage","released":"December 6th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDdltO0sPuN/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Three-State Heuristic","carousels":["Optimization","Logistics","Operations","Shipping","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-three-stage-heuristic-for-optimizing-container-relocations-in-maritime-container-terminals"},{"title":"Stealthy Messaging: Leveraging Message Queuing Telemetry Transport for Covert Communication Channels","description":"If you just sent those 10 pieces as is, any eavesdropper could easily reconstruct the message. So you don’t do that. This is where that agreed-upon key comes in. You perform a mathematical operation called modular exponentiation on each of the 10 parts, using the key. Modular exponentiation involves raising a number to a certain power (the exponent) and then finding the remainder when divided by another number (the modulus). This operation is commonly used in cryptography because it's easy to perform in one direction but very difficult to reverse without knowing the exponent, which, in this case, is the key.","sample":false,"doi":"10.3390/app14198874","short":"stealthy","released":"December 5th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDa35WPM5fs/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Stealth Messaging with MQTT","carousels":["Security","Network Engineering","Telecommunications","Spycraft"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"stealthy-messaging-leveraging-message-queuing-telemetry-transport-for-covert-communication-channels"},{"title":"FRR: A Fast Routing Recovery mechanism minimizing network formation time in smart grids","description":" The authors of this paper were looking for ways to improve the bootup (or “formation”) speed of a certain type of network between IoT devices. In a power-loss scenario, like a blackout these devices would need to boot back up and because of the complexity of the network they were establishing, that would take quite a long time. There’s just a lot of information and configuration that needs to be sent back and forth between different nodes, and this takes awhile. All these authors did, and all this paper is about is caching a little bit of that data. That’s the whole idea. Each node in the system needs","sample":false,"doi":"10.1016/j.ijepes.2024.110364","short":"frr","released":"December 4th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDQ4hlXsX69/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fast Routing Recovery","carousels":["Network Engineering","Energy Science","Smart Grids"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"frr-a-fast-routing-recovery-mechanism-minimizing-network-formation-time-in-smart-grids"},{"title":"Building a High-Performance Graph Storage on Top of Tree-Structured Key-Value Stores","description":"Imagine it’s the early 2000s, and you’re working as a Software Engineer at one of the budding social networks of the time. It could be a Facebook, a MySpace, a Friendster, a Twitter, etc. What makes your work special is that you’re part of what’s increasingly being known as “Web 2.0.” Gone are the days of static websites and individual user experiences. This is the dawn of the dynamic web and shared experiences. Social experiences. Your company is not just storing data about users and their individual flows through the application, but also how each user is interacting with each other user. You have new concepts that describe this. For the first time, you have things like “following” and “follower.” You have “friends,” you have “groups” and social circles. You have relationships.","sample":false,"doi":"10.26599/BDMA.2023.9020015","short":"tugraph","released":"December 3rd, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDQyGQlsR-R/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"High Performance Graph Storage","carousels":["Graphs","Data Structures","Databases"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"building-a-high-performance-graph-storage-on-top-of-tree-structured-key-value-stores"},{"title":"Software patterns and data structures for the runtime coordination of robots, with a focus on real-time execution performance","description":"If you live in a region with an autonomous taxi pilot program, your local evening news is probably having a field-day with all the ridiculous (and often hilarious) mistakes that these cars are making. Some of these mistakes are issues with sensors, some are issues with training, and some are issues with law enforcement: like the viral video of the Cruise car in SF a couple years ago that got pulled over by the police and for some reason drove away during the traffic stop. But a lot of the issues lately have been stemming not from the robotaxis interacting with the environment, but actually from","sample":false,"doi":"10.3389/frobt.2024.1363041","short":"coordination","released":"December 2nd, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDQshWEMdeB/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Runtime Coordination of Robots","carousels":["Robotics","Data Structures","Distributed Systems"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"software-patterns-and-data-structures-for-the-runtime-coordination-of-robots-with-a-focus-on-real-time-execution-performance"},{"title":"Intracranial aneurysm detection based on 3D point cloud object detection method","description":"The question these researchers are attempting to answer is can a Machine Learning model be trained to be able to look at the 3D point-cloud dataset and detect an aneurysm the way a medical professional could if they were looking at the 3D representation themselves. Based on my reading of the article I don’t think it’s their intention that such a model would replace what a Doctor would be doing, just putting an extra set of electronic eyes on the 3D-data to minimize the chance that a bulging area on a vessel would ever be missed. Luckily there is quite a lot of precedent when it comes to object-detection within a 3D space, so this research is really more of a shootout than an experiment.","sample":false,"doi":"10.1080/23311916.2024.2363456","short":"intracranial","released":"December 1st, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDGx_KBsQTz/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Aneurysm Detection","carousels":["Point Clouds","3D Mapping","Medicine","Neurology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"intracranial-aneurysm-detection-based-on-3d-point-cloud-object-detection-method"},{"title":"Fusion Text Representations to Enhance Contextual Meaning in Sentiment Classification","description":"This paper is about a great piece of software with a terrible name. It’s called GloWord_biGRU. At a high-level this research is all about sentiment classification. It’s about building a tool that can classify user-comments, posts, and other freeform text as either positive or negative. Imagine that you work at a place like Youtube. You have lots of videos, people can thumb-up or thumb-down them to indicate if they like it, but they can also leave a comment. One popular video could have hundreds of thousands of comments, far too many for a team-member to review. But you do want to review those comments somehow. You want to feed the overall sentiment of each comment back into the system as if it was a thumbs-up or thumbs-down. So, you have a bunch of text, and you need to convert each blob into a boolean. True if it’s a positive comment, false if it’s negative. And of course you need to do this at scale, as quickly and cost-efficiently as possible. What do you do?","sample":false,"doi":"10.3390/app142210420","short":"fusion","released":"November 30th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDGpuias-m-/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fusion Text Representations","carousels":["Natural Language Processing","Classification","Sentiment Analysis"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fusion-text-representations-to-enhance-contextual-meaning-in-sentiment-classification"},{"title":"Improving Performance of Key–Value Stores for High-Performance Storage Devices","description":"We all know that key-value stores are fast. They're fast at reading, they're fast at writing. The question is, could they be faster? Is it theoretically possible that there is still, to this day, a significant gap between their potential maximum, and their realized performance? Today's authors say yes, there is. In this paper they started with a host machine, and they analyzed the performance of the host's underlying storage hardware (NVMe SSD), to determine (at the lowest level) how fast data could actually be fetched-from and written-to disk. Then they setup a key-value store (RocksDB) on that host, then benchmarked reads and writes of that DB against the host's raw performance. Now what you'd expect to see is a little performance hit, explainable by the presence of the database application itself. It needs to run business logic, and that logic takes a little time. Understandable. But what the authors actually found was a far more significant","sample":false,"doi":"10.3390/app14177538","short":"kvhp","released":"November 29th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDGphWBsWuD/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"High Performance Storage","carousels":["Databases","Computing Hardware","High Performance Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"improving-performance-of-keyvalue-stores-for-high-performance-storage-devices"},{"title":"A serverless computing architecture for Martian aurora detection with the Emirates Mars Mission","description":"In this paper, the authors develop a detection and analysis framework, specifically geared at Martian aurora observation. An aurora is a natural light display in a planet's atmosphere, caused by charged particles colliding with atmospheric gases and emitting light. If you've heard of the Aurora Borealis (aka the \"Northern Lights\"), here on earth, that's probably the most famous example. The authors' system would allow users to identify auroras, classify their types, and analyze their properties. Let’s see what they built and how they built it. At a high level, their system is a data-driven image analysis pipeline. Rather than manually","sample":false,"doi":"10.1038/s41598-024-53492-4","short":"mars","released":"November 28th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DDA-vKuMmbd/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Martial Aurora Detection","carousels":["Serverless","Microservices","Space","Cloud Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-serverless-computing-architecture-for-martian-aurora-detection-with-the-emirates-mars-mission"},{"title":"A Stochastic-Process Methodology for Detecting Anomalies at Runtime in Embedded Systems","description":"In this paper they build a runtime anomaly detection framework that gets deployed alongside an embedded application and operates as a real-time monitoring system. The application monitors the target application's memory access patterns, and uses a combination of Discrete Cosine Transform (DCT) and Hidden Markov Models (HMMs) to detect deviations from normal behavior. Let's dig into the details and see how this works. Memory reference sequences are detailed logs of memory access events produced by an application during its runtime. Each sequence is essentially a timeline of memory addresses that the program reads from or writes to, in the exact order they occur. These events include operations such as accessing variables, loading data into cache, or interacting with external storage. By capturing","sample":false,"doi":"10.71602/tfss.2024.1183368","short":"stochastic","released":"November 27th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DC59NKqMVay/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Runtime Anomaly Detection","carousels":["Embedded Systems","Debugging","Reliability Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-stochastic-process-methodology-for-detecting-anomalies-at-runtime-in-embedded-systems"},{"title":"RosenPy: An open source Python framework for complex-valued neural networks","description":"A complex number is a number of the form <b>a + b<i>i</i></b>, where <b>a</b> and <b>b</b> are real numbers, and <b><i>i</i></b> is the square root of -1. Here, <b>a</b> is the real part, and <b>b</b> (when paired with <b><i>i</i></b>) is the imaginary part. Together, they form a point in a two-dimensional space called the complex plane, where the x-axis represents the real part and the y-axis represents the imaginary part. This allows operations like addition, multiplication, and rotation to be visualized geometrically. In many signal processing applications, such as telecommunications, radar, and image processing, the representation of data as complex numbers is not just convenient but necessary. Complex numbers are used to","sample":false,"doi":"10.1016/j.softx.2024.101925","short":"rosenpy","released":"November 26th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DC3WNghstjM/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Complex Valued Neural Networks","carousels":["Software Engineering","Python","Convolutional Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"rosenpy-an-open-source-python-framework-for-complex-valued-neural-networks"},{"title":"Designing a system call analyzer for system calls used inside Linux containers","description":"This is a system design paper in which they envision a system that can help Podman monitor, intercept and analyze the syscalls happening from within semi-trusted or untrusted containers. This is about telemetry and observability, nothing more. The authors make the case that there may be instances where you need to run a container and give it access to the ability to make syscalls (which it wouldn’t have by default), but then need to monitor what it’s doing carefully. This could be a piece of vendor software, or a piece of software you wrote that incorporates a 3rd party library you haven’t fully vetted yet. It might need access to syscalls for some reason we don’t","sample":false,"doi":"10.1051/bioconf/202413803025","short":"syscalls","released":"November 25th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DC3Jo2vMNaY/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"System Call Analyzer","carousels":["Systems Engineering","Operation Systems","Distributed Systems"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"designing-a-system-call-analyzer-for-system-calls-used-inside-linux-containers"},{"title":"Revolutionizing Diabetic Retinopathy Diagnosis with Modified Regularization Long Short-Term Memory Framework","description":"The real contribution in this paper is a framework called Modified Regularization Long Short-Term Memory (MR-LSTM). There’s a lot going on in that name, so we’re going to need to build up a definition slowly. A Long Short-Term Memory (LSTM) network is a specialized type of recurrent neural network (RNN) designed to process sequential data. Unlike traditional neural networks, LSTMs excel at retaining long-term dependencies in data sequences, thanks to their unique gating mechanisms. These gates—input, forget, and output—control the flow of information, selectively remembering or discarding details to maintain context over extended timeframes. This makes LSTMs particularly adept at","sample":false,"doi":"10.32890/jict2024.23.4.6","short":"retinopathy","released":"November 24th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCx63KXsWW1/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Diagnostic Retinopathy Diagnosis","carousels":["Chronic Disease","Medicine","LSTMs"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"revolutionizing-diabetic-retinopathy-diagnosis-with-modified-regularization-long-short-term-memory-framework"},{"title":"User Experience Techniques Adopted by Brazilian Game Development Studios: An Exploratory Study","description":"A frequency distribution revealed that 46% of studios adopted competitive analysis as a UX technique. Cluster analysis grouped studios based on shared characteristics, identifying patterns such as the fact that small studios often cited financial limitations and lack of knowledge as barriers to UX. Temporal analysis showed a shift over time, with newer studios (founded post-2021) demonstrating greater reliance on MVPs and prototypes for validation while older studios (pre-2015) more frequently employed structured UX practices and dedicated teams.","sample":false,"doi":"10.1155/2024/1857881","short":"atlasti","released":"November 23rd, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCvenxVMEyM/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"tags":[],"thumbnailTitle":"Game Developer UX Techniques","carousels":["User Experience","Game Development"],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"user-experience-techniques-adopted-by-brazilian-game-development-studios-an-exploratory-study"},{"title":"Quotient Network-A Network Similar to ResNet but Learning Quotients","description":"In today’s paper, the authors propose a new concept: a new variant of ResNet that overcomes two key issues with that methodology. They’re calling their concept a “Quotient Network”. Where ResNet learns in part by calculating differences between old and new features, the Quotient Network learns by calculating the quotients between them instead. So rather than subtraction they’re doing division. Now, that probably makes no intuitive sense to you right now, and that’s ok. We’re about to change that.","sample":false,"doi":"10.3390/a17110521","short":"quotient","released":"November 22nd, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCsq93bsm5Y/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Quotient Network","carousels":["Deep Learning","Model Architecture"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"quotient-network-a-network-similar-to-resnet-but-learning-quotients"},{"title":"Elevating metaverse virtual reality experiences through network-integrated neuro-fuzzy emotion recognition and adaptive content generation algorithms","description":"The pipeline begins with preprocessing. Raw audio recordings often contain noise—unwanted artifacts that can distort the data. So the first step is to employ a Chebyshev filter, known for its sharp roll-off characteristics, to minimize high-frequency noise while retaining the integrity of the signal. For instance, this might clean up background sounds like static or muffled speech, ensuring the emotional cues within the user's voice remain prominent. Once the signal is cleaned, it is segmented using a process called framing. Audio data is continuous, but machine learning models require discrete ","sample":false,"doi":"10.1002/eng2.12894","short":"neuro-fuzzy","released":"November 21st, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCowOBxM61j/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Metaverse Emotion Recognition","carousels":["Virtual Reality","Fuzzy Logic"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"elevating-metaverse-virtual-reality-experiences-through-network-integrated-neuro-fuzzy-emotion-recognition-and-adaptive-content-generation-algorithms"},{"title":"A Proactive Model for Intrusion Detection Using Image Representation of Network Flows","description":"Before we talk about today’s paper, we need to pause, jump in our time machines, and go back to talk about a paper from 26 years ago. In 1998, Yann Lecun, a professor at NYU, published a seminal paper on computer vision: Gradient-Based Learning Applied to Document Recognition. In that paper, the authors outlined the application of convolutional neural networks (CNNs) for recognizing handwritten characters. But more importantly for our purposes today, that paper was also the vehicle through which they first published the MNIST dataset. If you’ve worked","sample":false,"doi":"10.1109/ACCESS.2024.3489772","short":"idx","released":"November 20th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCnjKiusv1P/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Intrusion Detection with Image Representation","carousels":["Security","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-proactive-model-for-intrusion-detection-using-image-representation-of-network-flows"},{"title":"Traffic weaver: Semi-synthetic time-varying traffic generator based on averaged time series","description":"If you’re working as a network engineer for a high traffic application, like a website or an API your mandate is likely pretty broad. You need to not only accommodate, serve, log and analyze today’s traffic, but you need to preemptively build the systems that will allow you to continue doing those things tomorrow. If the site scales up, if the traffic peaks, if there’s a flash-sale or a news article that changes the traffic patterns you need to be on top of it…before it happens. And you need to do all of this without a crystal ball. How?","sample":false,"doi":"10.1016/j.softx.2024.101946","short":"weaver","released":"November 19th, 2024","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Semi-Synthetic Traffic Generator","carousels":["Temporal Analysis","DevOps","Reliability Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"traffic-weaver-semi-synthetic-time-varying-traffic-generator-based-on-averaged-time-series"},{"title":"Video object detection via space–time feature aggregation and result reuse","description":"The system employs a one-stage object detection model, YOLOx, as its foundation. Unlike two-stage detectors that rely on region proposal networks (RPNs) to generate candidate object regions—an inherently computationally intensive process—YOLOx bypasses this stage by directly predicting bounding boxes and classifications in a single pass through the network. This design allows for faster inference speeds, a critical feature for real-time applications. The YOLOx model serves as a lightweight yet robust baseline, leveraging CSPDarkNet as its backbone for efficient feature extraction. This backbone strikes a balance between computation and feature representation, ensuring sufficient granularity to detect objects under varying conditions of motion and occlusion.","sample":false,"doi":"10.1049/ipr2.13179","short":"object-detection","released":"November 18th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCkWR9DM8rT/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Video Object Detection","carousels":["Temporal Analysis","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"video-object-detection-via-spacetime-feature-aggregation-and-result-reuse"},{"title":"A Lightweight Barcode Detection Algorithm Based on Deep Learning","description":"They started with YOLOv8, a single-stage object detection model designed for efficient and fast object recognition. Its architecture consists of three primary components: The backbone, the neck, and the detection head. The backbone serves as the feature extractor, processing raw image data to produce rich feature maps that emphasize important aspects of the input, such as edges, shapes, and textures. The neck is responsible for feature fusion, taking information from different levels of the backbone to combine spatial and semantic details into more refined representations. Lastly, the detection head predicts bounding boxes and class labels based on these fused features, outputting the final detection results.","sample":false,"doi":"10.3390/app142210417","short":"barcode","released":"November 17th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DChpCDfsLDp/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Barcode Detection","carousels":["Computer Vision","Deep Learning","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-lightweight-barcode-detection-algorithm-based-on-deep-learning"},{"title":"Fruit fast tracking and recognition of apple picking robot based on improved YOLOv5","description":"China is producing nearly 40 million tons of apples a year, and there’s simply not enough people to pick them. So, Chinese producers are increasingly turning to apple-picking robots to do the job. These can take several different forms, but the one we’re looking at today is a single arm on a platform with an effector attached that can grab apples, twist them off the branch, and plunk them into a basket.","sample":false,"doi":"10.1049/ipr2.13164","short":"fruit","released":"November 16th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCfMyuUsveb/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Apple Picking Robot","carousels":["Computer Vision","Robotics","Agriculture"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fruit-fast-tracking-and-recognition-of-apple-picking-robot-based-on-improved-yolov5"},{"title":"SmartScanPCOS: A feature-driven approach to cutting-edge prediction of Polycystic Ovary Syndrome using Machine Learning and Explainable Artificial Intelligence","description":"This paper is about two very different, but related things. On one hand, yes, it is about using Machine Learning to predict or diagnose the existence of Polycystic Ovary Syndrome. But on the other hand, it’s really about explainable A.I. You see, researchers have been developing ML models to predict or flag PCOS in patients for years. It’s such a popular area of research that there are openly available Kaggle datasets on the subject that allow anyone to easily train a model to do that. It’s been done, and it’s being done. That’s really not the point here.","sample":false,"doi":"10.1016/j.heliyon.2024.e39205","short":"pcos","released":"November 15th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCb0kU0sfON/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"PCOS Prediction","carousels":["Medicine","Reproductive Health","Data Science","Temporal Analysis","A.I. Explainability"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"smartscanpcos-a-feature-driven-approach-to-cutting-edge-prediction-of-polycystic-ovary-syndrome-using-machine-learning-and-explainable-artificial-intelligence"},{"title":"GWAI: Artificial intelligence platform for enhanced gravitational wave data analysis","description":"In 1916 Albert Einstein predicted the existence of Gravitational Waves: disturbances or ripples in spacetime. Transient displacements in a gravitational field. Gravitational Waves (GWs), would be caused, he said, by massive, accelerated objects like colliding black holes or neutron stars. But, he also predicted that GWs would be extremely difficult to measure, requiring incredibly sensitive instruments.","sample":false,"doi":"10.1016/j.softx.2024.101930","short":"gwai","released":"November 14th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCW9gMHM2Rx/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Gravitational Wave Analysis","carousels":["Physics","Model Architecture","System Architecture"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"gwai-artificial-intelligence-platform-for-enhanced-gravitational-wave-data-analysis"},{"title":"Opportunities for retrieval and tool augmented large language models in scientific facilities","description":"In 1998, NASA launched the Mars Climate Orbiter. The spacecraft was designed to orbit Mars and relay vital atmospheric data back to Earth. For months, the orbiter traveled through space, with mission-control monitoring its progress and making minor adjustments as needed. Anticipation built as the team prepared for the critical moment when the orbiter would enter Mars' orbit. On the scheduled day, engineers gathered together, awaiting confirmation that the spacecraft had successfully positioned itself around Mars. Instead, they were met with an unsettling silence. Attempts to contact the orbiter failed, and it became clear that the Mars Climate Orbiter was lost, its mission ending abruptly as it vanished into the Martian atmosphere.","sample":false,"doi":"10.1038/s41524-024-01423-2","short":"calms","released":"November 13th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCVda3os8Lh/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"LLMs in Scientific Facilities","carousels":["Large Language Models"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"opportunities-for-retrieval-and-tool-augmented-large-language-models-in-scientific-facilities"},{"title":"Analysis of Similarity Caching on General Cache Networks","description":"Caching is, in a word, complex. And in today's paper, it gets significantly more complex. Some would say it becomes ridiculously complex, but I’ll leave that for you to decide. This paper takes the traditional concept of a \"cache-hit\" or \"cache-miss\" and adds a third option: a \"similarity-hit\". A similarity-hit means that the system found cached content that is (in some way) close to what the user is requesting, but not exactly it. Instead, it’s something similar-enough that it might still satisfy the user, and it can be retrieved from the cache rather than the original source.","sample":false,"doi":"10.1109/ACCESS.2024.3489620","short":"similarity-caching","released":"November 12th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCSHAX5M_yE/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Similarity Caching","carousels":["Network Engineering","Cloud Computing","Web Development","Software Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"analysis-of-similarity-caching-on-general-cache-networks"},{"title":"RASCAL v1.0: an open-source tool for climatological time series reconstruction and extension","description":"Today, November 11th 2024, marks the first day of COP29, the 29th meeting of the Conference of the Parties. COP was created by the UNFCCC, the United Nations Framework Convention on Climate Change, to bring countries together to negotiate and set international climate action goals. COP29 is happening in Baku, Azerbaijan, and will last nearly two weeks. During this time, member countries will set their climate change policies for","sample":false,"doi":"10.5194/gmd-17-7245-2024","short":"rascal","released":"November 11th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCQW31MMMeu/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Climatological Time Series Reconstruction","carousels":["Temporal Analysis","Climate Science","Environmental Science","Data Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"rascal-v10-an-open-source-tool-for-climatological-time-series-reconstruction-and-extension"},{"title":"Pneumonia Image Classification Using DenseNet Architecture","description":"In the early days of the 20th century, AT&T had a problem. They wanted to build the first transcontinental phone line, connecting San Francisco and New York City. But, their engineers told them it was practically impossible. Voices in a phone line couldn’t travel anywhere near that far. Why? Signal attenuation. As signals flowed through the phone lines over distance, they got weaker and weaker. Even if they had the physical wires connecting the two","sample":false,"doi":"10.3390/info15100611","short":"pneumonia","released":"November 10th, 2024","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Pneumonia Image Classification","carousels":["Medicine","Respiratory Disease","Classification","Computer Vision"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"pneumonia-image-classification-using-densenet-architecture"},{"title":"A fault‐tolerant and scalable boosting method over vertically partitioned data","description":"Imagine that you're a bank, and you've got a fraud problem. People are signing up for your credit-cards with stolen identities, racking up charges, then disappearing. And it's costing you a fortune. It turns out, the fraudsters are doing this all over town, all over the state, all over the country. It's not just a problem for your bank, it's a problem for all the others as well. So one day you and the other bankers decide to get ahead of it.","sample":false,"doi":"10.1049/cit2.12339","short":"vfl","released":"November 9th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCLZ1n0syN7/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Scalable Boosting Method","carousels":["Model Training","Model Architecture","MLOps"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-faulttolerant-and-scalable-boosting-method-over-vertically-partitioned-data"},{"title":"Multi‐modal video search by examples—A video quality impact analysis","description":"Let’s say you’re a software engineer at a major video-streaming company. This could be Netflix, Max, YouTube, or even Twitch or Kick. Either way, your company’s core competency is video: ingesting it, processing it, encoding and decoding it, hosting it, and streaming it out to consumers. And you’re good at it. But a new feature request just came down from on-high, and it’s, well, as we like to say: \"non-trivial.\" What feature? Search.","sample":false,"doi":"10.1049/cvi2.12303","short":"hamming","released":"November 8th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCGtCons_FJ/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Multi-Modal Video Search","carousels":["Software Engineering","Distributed Systems","Feature Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multimodal-video-search-by-examplesa-video-quality-impact-analysis"},{"title":"ARTDET: Machine learning software for automated detection of art deterioration in easel paintings","description":"If you’re a lover of fine art, I have a little bit of a spoiler for you today. Some of the most iconic pieces are not actually fully original anymore. If you go see the Mona Lisa, The Last Supper, Guernica, Starry Night, or even the ceiling of the Sistine Chapel, you’re not seeing that art as the painter left it however many decades or centuries ago. You’re seeing a version of the art that curators and historians have attempted to revive and restore to reflect what it looked like back when it was first painted.","doi":"10.1016/j.softx.2024.101917","short":"artdet","sample":false,"released":"November 7th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCDyZZSMy23/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Deterioration Detection","carousels":["Computer Vision","Visual Arts","Creative Arts"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"artdet-machine-learning-software-for-automated-detection-of-art-deterioration-in-easel-paintings"},{"title":"Optimizing Scorpion Toxin Processing through Artificial Intelligence","description":"If you ever rent an Airbnb out in the desert somewhere, like Joshua Tree, for example, your host is probably going to spend quite a bit of time talking to you about your shoes. Where to put them, how to put them there, where not to put them, what to do before you put them on, and what to do if you ignored the first instructions and accidentally left them somewhere you weren’t supposed to leave them.","doi":"10.3390/toxins16100437","short":"scorpion","sample":false,"released":"November 6th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DCCYdzisq87/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Scorpion Toxin Processing","carousels":["Ecology","Genetics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"optimizing-scorpion-toxin-processing-through-artificial-intelligence"},{"title":"Does ChatGPT Help Novice Programmers Write Better Code? Results From Static Code Analysis","description":"What makes good code? If you have two snippets that solve the same problem without throwing errors, what makes one of those snippets better than the other? More advanced than the other? More maintainable than the other?","doi":"10.1109/ACCESS.2024.3445432","short":"novice","sample":false,"released":"November 5th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DB_k593M_tH/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"ChatGPT and Novice Programmers","carousels":["Large Language Models","Software Engineering","Engineering Management"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"does-chatgpt-help-novice-programmers-write-better-code-results-from-static-code-analysis"},{"title":"Learning to drive as humans do: Reinforcement learning for autonomous navigation","description":"Think back for a moment to the first time you ever drove a car. It was you, it was whoever was teaching you, the steering wheel, gas, brake, clutch, and the shifter. If you’re a bit younger, then maybe no clutch. But as far as advanced technology, that was probably it. You may have had a radio, or some way to play music, but if you're like me you didn't have a phone, GPS, lidar, cameras, motion sensors, traffic data, bluetooth, or anything else fancy.","doi":"10.1177/17298806241278910","short":"navigation","sample":false,"released":"November 4th, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DB9CAxDMgCT/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Reinforcement Learning for Autonomous Cars","carousels":["Autonomous Vehicles","Reinforcement Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"learning-to-drive-as-humans-do-reinforcement-learning-for-autonomous-navigation"},{"title":"Employing deep learning in crisis management and decision making through prediction using time series data in Mosul Dam Northern Iraq","description":"Late on the night of March 12, 1928, the St. Francis Dam, a crucial piece of Los Angeles’s water infrastructure, failed without warning. Built just a few years earlier, the dam had been a symbol of progress, an ambitious project to secure water for a growing city. But at 11:57 p.m., a crack turned into a rupture, and within seconds, the dam broke apart, releasing billions of gallons of water into the San Francisquito Canyon. A wall of water, over 100 feet high, surged downstream, taking homes, farms, and hundreds of lives with it. By the time it reached the Pacific Ocean, over 50 miles away, the flood had left a trail of destruction across the valley.","doi":"10.7717/peerj-cs.2416","short":"mosul","sample":false,"released":"November 3rd, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DB589FDsXQY/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Crisis Management","carousels":["Temporal Analysis","Disasters","Civil Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"employing-deep-learning-in-crisis-management-and-decision-making-through-prediction-using-time-series-data-in-mosul-dam-northern-iraq"},{"title":"Telemedicine data secure sharing scheme based on heterogeneous federated learning","description":"A couple of months ago, <a href=\"https://www.tiktok.com/@jessicawetz6/video/7399423920828468485\" target=\"_blank\">a video</a> went viral on TikTok of a patient named Jessica explaining the lengths she has to go to just to get her various medical providers on the same page. Jessica carries a huge binder to her medical appointments, and from the sounds of it, that binder contains virtually every x-ray, procedure, medication, lab result, and exam they've ever had. It includes everything that any doctor who has seen them has ever documented, prescribed, ordered, or said about Jessica. Some people might watch that video and think: Why on earth is Jessica doing this? Why is this necessary? But for the millions of people who have watched and rewatched this video, for the numerous people in the comments who have asked Jessica how to structure their own patient binder, what information to include, and whether to use a cover page, Jessica really strikes a chord.","doi":"10.1186/s42400-024-00250-8","short":"federated-learning","sample":false,"released":"November 2nd, 2024","instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Heterogenous Federated Learning","carousels":["Medicine","Security","Federated Learning","Model Architecture","MLOps"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"telemedicine-data-secure-sharing-scheme-based-on-heterogeneous-federated-learning"},{"title":"Studying the Efficiency of the Apache Kafka System Using the Reduction Method, and Its Effectiveness in Terms of Reliability Metrics Subject to a Copula Approach","description":"If you go to Google Trends or the Keyword Planner and look up the worldwide search traffic for the word “Kafka,” you might be forgiven for assuming that Metamorphosis must be on the bestseller list. Every month, there are almost 700,000 searches for that term. What gives? Did every high schooler in the world get assigned the same book report? No, searches for Kafka have been rising for a decade and started spiking a year ago not because of Franz Kafka but because of Apache Kafka, the open-source distributed event streaming platform.","doi":"10.3390/app14156758","short":"kafka","sample":false,"released":"November 1st, 2024","instagram":"https://www.instagram.com/journalclub.io/reel/DB0BROJsw5b/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Efficiency of Apache Kafka","carousels":["Kafka","Temporal Analysis","Systems Engineering","Distributed Systems"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"studying-the-efficiency-of-the-apache-kafka-system-using-the-reduction-method-and-its-effectiveness-in-terms-of-reliability-metrics-subject-to-a-copula-approach"},{"title":"FSBOA: feature selection using bat optimization algorithm for software fault detection","description":"This paper has a whole lot going on, and from the title, it might not be entirely clear what it’s focusing on. At the highest level, this paper is about creating a better system for Software Fault Prediction (SFP). That is: shoring up the quality of the software you deliver by using machine learning model that can look at your codebase and predict where issues will arise. SFP isn’t by itself a holistic Quality Assurance process, but it can be a meaningful part of a larger QA/QC regime. So everything we’re going to talk about in this paper does in some way tie back to that: creating better SFP tools so that developers can ship better code.","doi":"10.1007/s43926-024-00059-4","short":"bats","released":"October 31st, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBzTqP7MxST/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Bat Optimization","carousels":["Optimization","Algorithms","Reliability Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"fsboa-feature-selection-using-bat-optimization-algorithm-for-software-fault-detection"},{"title":"A distributed data processing scheme based on Hadoop for synchrotron radiation experiments","description":"Just outside of Geneva, right near the border between Switzerland and France is the charming little municipality of Meyrin. Population about 26,000. They’ve got some apartment buildings, some low-rise office parks, a few hotels, some restaurants, cafes, a train station, and oh yeah… they’ve got the world’s largest and highest-energy particle accelerator: the LHC. CERN’s Large Hadron Collider. If you’re driving around, you won’t notice the LHC at all because it’s actually buried about 100 meters underground. This 17-mile track has been home to some of the most momentous experiments in modern physics. If you remember the race to identify the Higgs boson subatomic particle a few years ago...that was here. They did that. And that’s just one of the types of experiments that the LHC does.","doi":"10.1107/S1600577524002637","short":"synchrotron","released":"October 30th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBw4K6UsyLb/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Hadoop for Synchrotrons","carousels":["Distributed Systems","Datastores","Hadoop","Big Data","Physics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-distributed-data-processing-scheme-based-on-hadoop-for-synchrotron-radiation-experiments"},{"title":"High-Performance Computing Storage Performance and Design Patterns—Btrfs and ZFS Performance for Different Use Cases","description":"Imagine it’s 2003, and your friend brings a thumb-drive to school. On it: a pirated version of Outkast’s new album, Speakerboxxx/The Love Below. He was up all night on Limewire finding and downloading a decent copy. But he did it. This copy is solid, he listened to the whole thing on his PC before he copied it onto the drive. You borrow the thumb-drive and take it home, and plug it into your Mac. Error. You try again. Error again. Your Mac can’t read the drive. Something about NTFS. The computer suggests you reformat the drive, a process that will erase all the files. You stare at the screen, no Roses for you today.","doi":"10.3390/computers13060139","short":"zfs","released":"October 29th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBtVIQ8sFvY/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Btrfs vs ZFS","carousels":["Operating Systems","Datastores","High Performance Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"high-performance-computing-storage-performance-and-design-patternsbtrfs-and-zfs-performance-for-different-use-cases"},{"title":"Break-Pad: effective padding machines for tor with break burst padding","description":"Let’s say I am a despot at the head of an oppressive totalitarian government. You are one of the millions of people who live in the country under my control. One way I can retain my position and stay in power is through mass surveillance, keeping an eye on what everyone is saying, what they’re doing, where they’re going, and who they’re associating with. A big part of that is monitoring what they’re doing online: what sites they’re visiting, how long they’re staying on those sites, and how much information they’re sending to and receiving from those sites. If I can figure out every website that everyone is visiting and every app they’re using, I can use that data to crack down on journalists, dissidents, activists—you name it. Even if I can’t see the information they’re sending to or receiving from these sites, just knowing the sites they’re connecting to is enough for me to act.","doi":"10.1186/s42400-024-00222-y","short":"break-pad","released":"October 28th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBrTVS_ML4B/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Padding Machines for Tor","carousels":["Security","Spycraft","Privacy"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"break-pad-effective-padding-machines-for-tor-with-break-burst-padding"},{"title":"Hardware for Deep Learning Acceleration","description":"If you’ve ever tried to train a deep neural network, you’ve probably spent a lot of time waiting. Waiting for training, waiting for boosting, waiting for validation runs, waiting waiting waiting. Why is that? Well, remember in school when you learned matrix multiplication, and you had to do it by hand? Remember how long that took? How tedious it is? Well yeah, your computer feels the same way. The crux of the problem here are MACs: Multiply-Accumulate Operations, in which matrix multiplication is an integral part. MACs are what the machine is doing, and what’s taking so long.","doi":"10.1002/aisy.202300762","short":"dl-hardware","released":"October 27th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBoCiBRMlUc/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Deep Learning Hardware","carousels":["Computing Hardware","GPUs","Deep Learning"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"hardware-for-deep-learning-acceleration"},{"title":"DSIPTS: A high productivity environment for time series forecasting models","description":"If you’ve been listening to Journal Club for a while, you’ve probably noticed that a lot of the Machine-Learning, Deep Learning and Computer Vision episodes have a similar story arc:The researchers have a problem. They collect data. They clean and normalize that data. They extract and select the features they care about. They pick a few algorithms to test against each other. They run the training. They choose a few metrics to use to validate the models and benchmark them against each other. Sometimes they also stack models together or use some kind of ensemble learning. That storyline exists in Journal Club so frequently because that is the most common flow for how this research happens. But what our storylines don’t necessarily capture, is that many of these steps are highly manual, tedious, and repetitive. I might, for example, casually mention that a researcher trained models on KNN, Random Forest and SVM, but that doesn’t mean that those three training cycles looked anything like each other. They might have been in totally separate programs or notebooks, with different libraries, happening at different times on different machines, with a number of discrete manual idiosyncratic steps for each one. Getting different models trained with different algorithms for a given set of data isn’t generally a push-button thing.","doi":"10.1016/j.softx.2024.101875","short":"dsipts","released":"October 26th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBmNvIgM4ou/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"High-Productivity Forecasting","carousels":["Temporal Analysis","Model Training","MLOps"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"dsipts-a-high-productivity-environment-for-time-series-forecasting-models"},{"title":"A Tour Recommendation System Considering Implicit and Dynamic Information","description":"When I go on vacation, I like to do: nothing. I want to fly to wherever I’m going, sleep all day, chill all night, lay around the room, lay around the pool, order room service, be a sloth. For me, the idea of having to wake up early, put on actual clothes, and go do something sounds completely insane. Why anyone would jam-pack their vacation time with an itinerary full of stuff they have to do is beyond me. That just sounds like work.","doi":"10.3390/app14209271","short":"tour","released":"October 25th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBjzTAJsJHY/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Tour Recommendation System","carousels":["Tourism","Natural Language Processing","Sentiment Analysis"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-tour-recommendation-system-considering-implicit-and-dynamic-information"},{"title":"End-to-end vertical web search pseudo relevance feedback queries recommendation software","description":"We all use search engines every day, for a variety of tasks. And our use of them can be broadly categorized into two types: standard searches and exploratory searches. In a standard search, a user looks up information when they already have some understanding of the subject. Even if they don't know the specific answer, they know enough to craft a coherent query that leads to relevant results. For example, searching for \"what is the capital of France?\" is straightforward because the user knows the general structure of the answer (a single city name) and can phrase the question clearly. This is the type of search traditional engines like Google excel at—they deliver concise, accurate results based on well-defined, unambiguous queries.","doi":"10.1016/j.softx.2024.101872","short":"prf","released":"October 24th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBg-8BuMikI/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Vertical Web Search","carousels":["Search","Natural Language Processing","Distributed Systems"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"end-to-end-vertical-web-search-pseudo-relevance-feedback-queries-recommendation-software"},{"title":"Machine Learning Models for DDoS Detection in Software-Defined Networking: A Comparative Analysis","description":"Let’s say you’re in charge of network security at a decent sized eCommerce site. Your company’s big enough that they don’t use AWS or GCP or any other cloud provider, they just run their own machines, maybe in a datacenter or colo-center, or maybe even in a server closet right next to your desk. Either way, that network is a real physical thing that your company relies on, and everyone’s counting on you to protect it. Everything’s going fine for a while. But then, a week before your biggest sale of the year—a sale that accounts for a huge percentage of your company’s annual profits-–-a week before that, it happens.","doi":"10.51519/journalisi.v6i3.864","short":"ddos","released":"October 23rd, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DBebwFHsIJm/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"DDoS Detection in SDN","carousels":["Security","Network Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"machine-learning-models-for-ddos-detection-in-software-defined-networking-a-comparative-analysis"},{"title":"Intelligent Swarm: Concept, Design and Validation of Self-Organized UAVs Based on Leader–Followers Paradigm for Autonomous Mission Planning","description":"Toe-to-toe, a little honeybee doesn’t stand a chance against a hornet. Most hornets are 2-3 times the size of a bee, plus they have a thick exoskeleton like a lobster. And they’re mean. When a hornet enters a honeybee’s nest, it’s not there to make friends. It’s there to kill bees and steal food. But honeybees have a secret weapon: a technique called \"balling\". The bees latch onto the intruder one by one, eventually surrounding it in a blanket of bees. As they hold on, they vibrate their flight muscles, generating heat. Lots of heat. The hornet gets hotter, and hotter, and hotter, and then it dies. Victory: bees.","doi":"10.3390/drones8100575","short":"swarm","released":"October 22nd, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBbZttIMru-/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Intellgent Swarm","carousels":["UAVs","Distributed Systems","Autonomous Vehicles"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"intelligent-swarm-concept-design-and-validation-of-self-organized-uavs-based-on-leaderfollowers-paradigm-for-autonomous-mission-planning"},{"title":"A Scalable Real-Time SDN-Based MQTT Framework for Industrial Applications","description":"Let’s say you and I are Oompa Loompas in a chocolate factory. We have various jobs, and we do all the meaningful work, while the crazy guy in the hat gets all the credit. But that’s fine, it’s what we signed up for. Your job is to take caramel squares and dip them in chocolate. Then you hand them to me. I sprinkle a little salt on top and carefully wrap each chocolate-covered caramel in a cellophane wrapper, twist the ends, and then place that carefully in a box lined with tissue paper. You dip, I wrap.","doi":"10.1109/OJIES.2024.3373232","short":"mqtt","released":"October 21st, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DBYjaLaMWco/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"MQTT Framework","carousels":["Manufacturing","Distributed Systems","Network Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-scalable-real-time-sdn-based-mqtt-framework-for-industrial-applications"},{"title":"Application Strategies of Brain-computer Interface in Education from the Perspective of Innovation Diffusion Theory","description":"In September 2023, Neuralink received approval to begin human clinical trials for a neural implant called the N1. Their study, nicknamed “Prime,” builds on years of animal trials conducted on pigs and monkeys. These studies were so revolutionary and buzzworthy that even the participants, the animals themselves, became internet celebrities. Millions of people watched as Pager, the monkey, used his Neuralink implant to play ping pong with his mind.","doi":"10.1080/27706710.2024.2376368","short":"bci","released":"October 20th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBXOd-3s4IX/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Brain-Computer Interfaces","carousels":["Brain-Computer Interfaces","Education","Medicine","Medical Devices","Assistive Technology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"application-strategies-of-brain-computer-interface-in-education-from-the-perspective-of-innovation-diffusion-theory"},{"title":"Modeling and Analysis of Cooperative Packet Recovery Protocol","description":"In late October 1997, Atlanta Georgia played host to a 4-day technology conference: the 1997 International Conference on Network Protocols. At that event, a paper was presented by a 3-person team from AT&T Research Laboratories, Lucent Technologies Bell Labs, and Fujitsu Laboratory of America. AT&T, or “Ma Bell,” had been broken up a decade before in antitrust proceedings, but these ostensibly now-independent entities still collaborated on research. The paper they presented had all the hallmarks of Bell Labs innovation, namely being decades ahead of its time. The paper was called “A cooperative packet recovery protocol for multicast video,” and in it, they outlined a system in which packet loss between a sender and a receiver could be mitigated by a 3rd party server that steps in to replace packets as they’re lost.","doi":"10.1109/ACCESS.2024.3389738","short":"packet-recovery","released":"October 19th, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DBUWo1DMvag/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Cooperative Packet Recovery Protocol","carousels":["Network Engineering","Web Development"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"modeling-and-analysis-of-cooperative-packet-recovery-protocol"},{"title":"Real-Time Monitoring of Road Networks for Pavement Damage Detection Based on Preprocessing and Neural Networks","description":"In the 2017 mayoral race in Jackson Mississippi, an unusual thing happened. The democratic incumbent, Mayor Tony Yarber, was challenged by members of his own party. Eight of them. They attacked him on his record, on his policies, and on his plans. But most of all, they attacked him on potholes. You see, potholes are endemic in Jackson. About 200 miles north of New Orleans, Jackson is often hot and humid. The moisture penetrates the road surface, seeping into small cracks, and weakening the foundation. Over time, the soil is less able to support the road surface, and as traffic passes over it, deformities begin to form. First rutting, then larger dips and cracks. Meanwhile, scorching midday temperatures soften the road, then colder nights cause it to contract again, and the cracks and dips get worse. Water fills the deformities and the vicious cycle continues. In Jackson that meant pothole after pothole after pothole. The residents had seen enough, and were ready for someone to step in and fix the problem.","doi":"10.3390/bdcc8100136","short":"potholes","released":"October 18th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBRN139s82i/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Pavement Damage Detection","carousels":["Model Preprocessing","Computer Vision","Civil Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"real-time-monitoring-of-road-networks-for-pavement-damage-detection-based-on-preprocessing-and-neural-networks"},{"title":"Evaluating ARM and RISC-V Architectures for High-Performance Computing with Docker and Kubernetes","description":"In 2020, Apple revealed the first release in their “M” series of computers, their foray into designing and building their own chips. No longer would they depend on Intel's processors to power their machines; the future of Apple would be vertically-integrated chip development. And it all started with The M1. While most of the headlines of the time were about the sheer processing power of the computer, many articles buried the real lead. The incredible part of the announcement was less about Apple bringing chip-manufacturing in-house, and more about the fact that they had switched from x86 to ARM. This wasn’t just a coup d’etat for ARM, it was a win for RISC: The Reduced Instruction Set Computer architecture.","doi":"10.3390/electronics13173494","short":"risc-v","released":"October 17th, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DBOhkh-skQp/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"ARM vs RISC-V","carousels":["Computing Hardware","Microservices","Containers"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"evaluating-arm-and-risc-v-architectures-for-high-performance-computing-with-docker-and-kubernetes"},{"title":"Location Privacy Protection for the Internet of Things with Edge Computing Based on Clustering K-Anonymity","description":"The past decade has seen nothing short of a revolution in privacy protection. From GDPR in Europe to CCPA in California, to third-party cookie restrictions built into iOS, and stronger browser defaults around HTTPS. Compared to the wild-west days of the early and mid-2000s, the internet consumer today has far more protections and avenues for recourse than ever before. The operators of web applications, mobile apps, APIs, newsletters, and other internet services are governed by strict compliance regimes that dictate what they can and can’t do with your personal information. Importantly, these regimes also specify how they must care for, handle, and protect your personal data—securing it from bad actors, encrypting it, and ensuring its safety.","doi":"10.3390/s24186153","short":"k-anonymity","released":"October 16th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBMeTIvsemJ/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Location Privacy Protection","carousels":["Privacy","IoT","Edge Computing","Cloud Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"location-privacy-protection-for-the-internet-of-things-with-edge-computing-based-on-clustering-k-anonymity"},{"title":"Zero-Trust Zero-Communication Defense against Hybrid Cyberattacks in Distributed Energy Resources Using Mean Field Reinforcement Learning","description":"In the fall of 2021, after nearly six months in the halls of Congress, the Infrastructure Investment and Jobs Act (IIJA) was finally signed into law. This package, also known as the Bipartisan Infrastructure Law (BIL), allocated $1.2 trillion of funding, with $65 billion of that going specifically towards modernizing America’s power grid. Of that $65 billion, around $13 billion (20%) was set aside just specifically for power grid security. That’s thirteen Billion dollars to secure a system that, if you’re like me, you might’ve thought was already secure. Turns out, we were wrong. Not only is the grid vulnerable to a wide range of attacks from large state actors, but as the grid modernizes into a \"smart grid,\" the attack surface actually grows","doi":"10.3390/en17205057","short":"mean-field","released":"October 15th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBJYJ_ws3-g/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Zero Trust Defenses","carousels":["Security","Energy Science","Smart Grids"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"zero-trust-zero-communication-defense-against-hybrid-cyberattacks-in-distributed-energy-resources-using-mean-field-reinforcement-learning"},{"title":"Computer-assisted analysis of routine EEG to identify hidden biomarkers of epilepsy: A systematic review","description":"Okay, so this almost never happens. 99% of the time, on Journal Club the papers we are covering are advancements in computer science. That’s our bread and butter. But once in a blue moon, an article comes out that is the complete opposite. An article that says, in effect: \"Hey everyone: when it comes to this one particular technology, we have all gotten out over our skis. We as an industry are making claims that a technology is capable of something it’s not actually capable of.\" These kinds of articles are rare, but I think they contribute just as much to our understanding of the state of the industry, as the other articles do. So it’s in that spirit that I bring you today’s paper:","doi":"10.1016/j.csbj.2023.12.006","short":"eeg","released":"October 14th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBGx26AsqOE/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Epilepsy Identification","carousels":["Medicine","Diagnostic Medicine"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"computer-assisted-analysis-of-routine-eeg-to-identify-hidden-biomarkers-of-epilepsy-a-systematic-review"},{"title":"Programming Industrial Robots in the Fanuc Roboguide Environment","description":"Let’s pretend that your name is Janet and you are the CEO of Janet’s Bicycle Company. You sell bicycles to distributors, and you make those bicycles in a factory. The raw materials and third-party components come into the shipping-dock, and you’ve got a production/assembly line where you transform that pile of metal and rubber into a finished bike. From the start of the industrial revolution all the way up to the 1960s, the individual tasks involved in a production-line like yours were manually done by a human being. That person would likely have been using tools, and those tools might have provided leverage, but at its core industrial production was still a human-centered manual task. Bicycles, toasters, cars, shoes, and tape-measures, these were all made by a real person on an assembly line.","doi":"10.3390/engproc2024070020","short":"roboguide","released":"October 13th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBFqw6QMy7V/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Programming Industrial Robots","carousels":["Robotics","Manufacturing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"programming-industrial-robots-in-the-fanuc-roboguide-environment"},{"title":"Distributed Software Build Assurance for Software Supply Chain Integrity","description":"In May 2021, the White House issued Executive Order 14028, the \"Executive Order on Improving the Nation’s Cybersecurity\". This order, among other things, directed NIST (the National Institute of Standards and Technology) to develop best-practices around software supply-chain security. Before we go on, I want to disambiguate that phrase. We are not talking about supply-chain software security. That is the security of the software that manages a business' supply chain. No. We’re talking about software supply-chain security: the security of the supply chain of the software we build.","doi":"doi.org/10.3390/app14209262","short":"assurance","released":"October 12th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DBChS_7sqlg/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Distribued Build Assurance","carousels":["Distributed Systems","Software Engineering","Logistics","Operations","Supply Chain","Reliability Engineering","Continuous Deployment","Security"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"distributed-software-build-assurance-for-software-supply-chain-integrity"},{"title":"A quadratically constrained mixed-integer non-linear programming model for multiple sink distributions","description":"Sweet Mama’s Tomato Mix is a tomato-paste produced by the Weddi Africa Tomato Processing and Agro Farm. Weddi is a vertically integrated wholesaler: it operates the farm, it runs the processing plant, and it owns the distribution centers. It delivers five products (pastes in various-sized containers) directly to retailers in its own fleet of trucks, driven by its own drivers. The company operates in Ghana, in or around the city of Kumasi, a metropolitan area that is home to nearly 4 million residents. Weddi's main factory is about a hundred miles outside of the city, but its distribution hubs are closer to the city limits.","doi":"10.1016/j.heliyon.2024.e38528","short":"tomatoes","released":"October 11th, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DA_H9WKs2US/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Mixed Integer Non-Linear Programming","carousels":["Logistics","Supply Chain","Operations","Manufacturing","Optimization","Algorithms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-quadratically-constrained-mixed-integer-non-linear-programming-model-for-multiple-sink-distributions"},{"title":"Emojis as graphic equivalents of prosodic features in natural speech: evidence from computer-mediated discourse of WhatsApp and facebook","description":"A few days ago it was a friend's birthday. So at some point during the day I pulled out my phone, went to my message threads, found that person, and typed “Happy”. But as I was typing B-I-R-T-H-D-, the auto-suggest on my phone popped up with an emoji of a birthday cake 🎂. So I clicked on the suggestion, and it replaced the word I was typing with the cake. So what I was left with read as “Happy [Cake]”. I thought to myself, \"Why would it think I wanted that?\" Why would it think I was replacing the word Birthday with an emoji of a cake? Clearly I wanted to complete the word “Birthday” and then put a cake afterwards. Isn’t that how everyone uses emojis? As decorative accents after the text?","doi":"10.1080/23311983.2024.2391646","short":"emojis","released":"October 10th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DA8XGfxM-Nz/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Emojis as Prosodic Elements","carousels":["Natural Language Processing","Linguistics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"emojis-as-graphic-equivalents-of-prosodic-features-in-natural-speech-evidence-from-computer-mediated-discourse-of-whatsapp-and-facebook"},{"title":"Traffic Classification in Software-Defined Networking Using Genetic Programming Tools","description":"Here’s an uncomfortable thought about your ISP. (Your Internet Service Provider). When it comes to privacy, your interests and their interests are not aligned. Why? Because from their perspective, they need to provide you with a certain quality of service. In order to do that, they need to perform load balancing, routing, traffic prediction and forecasting. They need to identify malicious traffic flows and DDOS attacks. And if you live in a jurisdiction which doesn’t practice net neutrality, then part of their service may include application-specific metering. All of these things are predicated on their ability to classify the traffic that is passing through their network.","doi":"10.3390/fi16090338","short":"sdn","released":"October 9th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DA6aX-AsaVW/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Traffic Classification in SDN","carousels":["Network Engineering","Genetic Programming","Classification"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"traffic-classification-in-software-defined-networking-using-genetic-programming-tools"},{"title":"Enhancing QoS in Delay-Sensitive IoT Applications through Volunteer Computing in Fog Environments","description":"Imagine for a second that you are an IoT device. You’re a smart watch, or a smart speaker, or a smart lamp, or a smart fridge. Either way you’re smart, you’ve got a processor onboard, and you can handle a lot of the computational workload yourself. But for some tasks, there are just so many calculations to do (so quickly) that your onboard chip isn’t up to the job. For those kinds of workloads, you offload the processing to a remote server, let that machine do the heavy lifting, and then return the result. But there’s a problem. When it comes to choosing the type of server that you send your workload to, you are spoiled for choice. You’ve got three main classes of options: Cloud Servers, Edge Servers, and Fog Nodes.","doi":"10.33889/IJMEMS.2024.9.6.072","short":"vcs","released":"October 8th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DA2ub04Moay/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Delay Sensitive IoT","carousels":["Reliability Engineering","IoT","System Architecture"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"enhancing-qos-in-delay-sensitive-iot-applications-through-volunteer-computing-in-fog-environments"},{"title":"Imperative Genetic Programming","description":"In 1948, less than 90 years after Darwin published \"On the Origin of Species\", Alan Turing applied the concept of natural selection to Computer Science. In an unpublished essay titled “Intelligent Machinery,” he wrote: “There is the genetical or evolutionary search by which a combination of genes is looked for, the criterion being the survival value.” This line appears to be the first mention by any person, anywhere, of what is now referred to as an evolutionary algorithm. And now, 76 years later, this niche concept which has existed on the fringes of computer science for decades, is poised to finally have its time in the spotlight. Specifically, one technique within this field: Genetic Programming is coming to the forefront. Why? Because the same hardware advances, the same distributed systems and cloud computing advances that have enabled the proliferation of LLMs can also enable the widespread adoption of Genetic Programming.","doi":"10.3390/sym16091146","short":"genetic","released":"October 7th, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DA0pqNlsMFe/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Imperative Genetic Programming","carousels":["Genetic Programming","Software Engineering","Programming Paradigms"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"imperative-genetic-programming"},{"title":"Feasibility Study on MHEV Application for Motorbikes: Components Sizing, Strategy Optimization through Dynamic Programming and Analysis of Possible Benefits","description":"About a month ago, on September 7th, Héctor Garzó rounded the final turn at San Marino, crossed the finish line, and became the 2024 MotoE World Champion. He wasn’t riding any normal motorcycle. He was riding a fully-electric Ducati superbike, with a top speed of about 171 miles per hour. In fact, everyone in that race was riding a Ducati, because the storied Italian manufacturer has signed a deal to be the exclusive provider of electric motorcycles for the entire field through 2026. You see, Ducati is going long on electric motorcycles, and doing everything they can to push the technology (and the acceptance of it) to higher and higher levels. So far, they haven’t seen much success. The MotoE race where Garzo was crowned champion was streamed live on Youtube. As of this writing, the video only has about 11,000 views. Total. For a world championship.","doi":"10.3390/vehicles6030068","short":"mhev","released":"October 6th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DAxkXm4sUFC/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"MHEV for Motorbikes","carousels":["Transportation","Optimization","Dynamic Programming","Programming Paradigms","Energy Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"feasibility-study-on-mhev-application-for-motorbikes-components-sizing-strategy-optimization-through-dynamic-programming-and-analysis-of-possible-benefits"},{"title":"Real-Time Fire Detection: Integrating Lightweight Deep Learning Models on Drones with Edge Computing","description":"In the immortal words of Frankenstein’s monster: FIRE BAD! And unfortunately, we often don’t spot fires until they’re really bad. We’ll miss the small brush fires and only take notice when they’re large and out of control. This happens for a few reasons: Fires can start anywhere, even away from the cities. In the middle of open land, or in a forest where nobody will notice. If someone does notice, there can be a “bystander-effect”: everyone thinks that someone else must have called 911 to report the fire, or that someone else must already be handling it. So nobody ends up calling at all, and the fire grows and grows. Where I live in California, this is a big problem. Large parts of the state are sparsely populated open areas with lots of fuel for wildfires (dry grass and the like). So every summer a sad ritual repeats itself here. Loose cigarette butts, mismanaged campfires, downed power lines, or any of several other causes can be the trigger. And once it starts, the fire goes unspotted for a while, It grows, it spreads and eventually causes real damage. These fires cost California billions of dollars, every single year.","doi":"10.3390/drones8090483","short":"fire","released":"October 5th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DAuhPkQsgqR/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Real-Time Fire Detection","carousels":["Civil Engineering","Deep Learning","UAVs","Safety"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"real-time-fire-detection-integrating-lightweight-deep-learning-models-on-drones-with-edge-computing"},{"title":"The JavaScript Package Selection Task: A Comparative Experiment Using an LLM-based Approach","description":"NPM is a fantastic package manager in a number of ways, but it's really bad at search. To be fair, every other package manager is bad at it too: PIP, Crates, Maven, Homebrew, RPM, etc. They all struggle to give meaningful search-results for a query. When you have a problem that you need a library to solve, your chances of finding a relevant package might hinge on your ability to guess what that package might be named. The search-bar in NPM returns such irrelevant results, that you'll likely spend your day jumping from search engines, to Github, to blog posts, to youtube videos, to forum discussions. You'll go back and forth to NPM over and over again, trying out different packages to see what fits. You'll spend time reading their docs, checking their Github issues, checking if they're stable, well maintained and recently updated. It’s a pain, to say the least. I’ve always thought that non-programmers would be shocked to see how much of a Software Engineers day is spent trying to find and use new packages. Out of exasperation, many developers just choose the most popular package that seems like it might possibly do the job. Not the package best suited to the problem, not the package with highest test coverage, not the package with the best documentation, or the lowest number of open issues, just the one with the most impressive download graph.","doi":"10.19153/cleiej.27.2.4","short":"packages","released":"October 4th, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DAr17iVMsN2/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Javascript Package Selection","carousels":["Web Development","Software Engineering","Javascript"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-javascript-package-selection-task-a-comparative-experiment-using-an-llm-based-approach"},{"title":"Urban region representation learning with human trajectories: a multi-view approach incorporating transition, spatial, and temporal perspectives","description":"Shenzhen is a bustling metropolis. 17.5 million people, millions of homes, millions of cars, millions of workplaces. But it wasn’t always this way; in fact it wasn’t even this way recently. Thirty years ago Shenzhen was a 10th of its current size, forty years ago it was a quarter of that. The growth experienced in this region over the last half-century has been incredible, and the city is still growing so quickly that local municipalities are having a hard time even tracking the growth. This makes the day-to-day practice of governing somewhat difficult. Common tasks like land-use classification, population density estimation, and even housing-price tracking have become non-trivial. The census is only conducted in China once every 10 years, so how are they supposed to keep track of the population in the meantime?","doi":"10.1080/15481603.2024.2387392","short":"trajectories","released":"October 3rd, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DAp-gWHM7-P/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Human Trajectories","carousels":["Temporal Analysis","Telecommunications","Surveillance","Civil Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"urban-region-representation-learning-with-human-trajectories-a-multi-view-approach-incorporating-transition-spatial-and-temporal-perspectives"},{"title":"Towards a Block-Level Conformer-Based Python Vulnerability Detection","description":"First, we need to step back in time for a moment. In 2017, Vaswani et al published a seminal paper that would send shockwaves through the A.I. community: “Attention Is All You Need”. In it, the authors described a novel concept: the Transformer. Transformers (and their building-blocks called “transformer-blocks”) were a new type of a Neural-Network architecture based on the concept of self-attention. Self attention allowed for two key benefits: 1. The ability for tokens to maintain relationships with long-range dependencies. 2. The ability to parallelize both your training and inference. In other words, transformers made Large Language Models possible, set the stage for what would become the Foundation Models, ChatGPT, and arguably the whole AI boom of the last few years. I’m telling you this because the paper we’re about to dive-into builds on top of the concept of a transformer, utilizing an even newer concept: a Conformer. You see, after a few years working with transformers, researchers started to realize that they had a few limitations. Namely, transformers were great at determining the long-range relationships between tokens, but they struggled with short-range relationships or “local dependencies”. So the conformer was born, which utilizes a transformer but adds on convolutions for local patterns. Thus the name “con” from convolution and “former” from transformer. Conformers are designed to be great at both the big picture and the tiny details.","doi":"10.3390/software3030016","short":"vuldetective","released":"October 2nd, 2024","sample":true,"instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Conformer Based Vulnerability Detection","carousels":["Security","Python","Transformers","Convolutional Neural Networks"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"towards-a-block-level-conformer-based-python-vulnerability-detection"},{"title":"Robot Control Platform for Multimodal Interactions with Humans Based on ChatGPT","description":"In 2014 Masayoshi Son, the founder of SoftBank, revealed Pepper: A four foot tall humanoid robot that could talk, answer questions, and perform a variety of pre-programmed actions. Pepper had a tablet sticking out of its chest to display visual information to the person it was communicating with. Over the last decade thousands of these little robots were sold around the world and reprogrammed to become everything from front-desk receptionists, to tour guides, to waiters. Most of these installations were experiments: cute demos and a sneak-peak of what might be possible in the future.","doi":"10.3390/app14178011","short":"pepper","released":"October 1st, 2024","sample":false,"instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Robot Control Platform","carousels":["Robotics","Large Language Models","Manufacturing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"robot-control-platform-for-multimodal-interactions-with-humans-based-on-chatgpt"},{"title":"A multimodal fusion framework to diagnose cotton leaf curl virus using machine vision techniques","description":"Cotton farmers in Pakistan have a problem: The Silverleaf Whitefly. This little insect is a carrier of the Cotton Leaf Curl Virus (CLCuV), which causes Cotton Leaf Curl Disease (CLCuD). Cotton Leaf Curl is serious. Once infected, the virus causes photosynthate blockage in the veins of a cotton plant. Photosynthates are the compounds produced during photosynthesis, so having a photosynthate blockage is really really bad. The tertiary veins on the leaves turn yellow and thicken, the leaves start to curl, then secondary veins get blocked, which reduces surface area of the leaves. This means less photosynthesis, and the downward spiral continues. Infected plants end up shorter, with curly scaly leaves, and most importantly: the stress on the plant can cause cotton yields to drop 80%.","doi":"10.1080/23311932.2024.2339572","short":"cotton","released":"September 30th, 2024","sample":false,"instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Cotton Leaf Curl Virus","carousels":["Agriculture","Computer Vision","Electromagnetic Spectrum"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-multimodal-fusion-framework-to-diagnose-cotton-leaf-curl-virus-using-machine-vision-techniques"},{"title":"Passwordless Authentication Using a Combination of Cryptography, Steganography, and Biometrics","description":"Remember a year or two ago when “passwordless” authentication for websites was all the rage? News articles from the time proclaimed that passwords were dead and that passkeys (and related technologies) were clearly the future. Well…what happened? From what I can tell, a lot of people gave passkeys a try, hated them, and went right back to using passwords. To be fair, passwordless authentication for mobile lock-screens and mobile payments did become a reality (in the form of biometrics) but passwordless authentication on the web never really caught-on (outside of Oauth). It turns out, if you want to disrupt something as ubiquitous as passwords you need to offer a solution that is waaaay better. Not just a slight improvement, but a full step-function better. And in the minds of many users, passkeys didn't reach that bar.","doi":"10.3390/jcp4020014","short":"sesame","released":"September 29th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DAfj8iVM8_T/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Passwordless Authentication","carousels":["Security","Web Development","Biometrics"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"passwordless-authentication-using-a-combination-of-cryptography-steganography-and-biometrics"},{"title":"A predictive model for stunting among children under the age of three","description":"Worldwide, approximately 1/5th of children under the age of five suffer from some sort of physical growth-impairment. That figure has improved virtually every year for decades, but there’s still a lot of work left to do. Growth-impairment has traditionally been viewed strictly as a function of malnutrition, but there is an increasing awareness that there are a multitude of other factors that correlate strongly with growth-impairment. Identifying these risk factors could help clinicians intervene earlier and more effectively. In this research the authors attempt to build a predictive model for growth-impairment: a model that can analyze other household and familial risk factors, and inform medical professionals of any elevated risk.","doi":"10.3389/fped.2024.1441714","short":"nomogram","released":"September 28th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DAcl1V3Mie_/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Stunting Prediction","carousels":["Temporal Analysis","Medicine","Diagnostic Medicine"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-predictive-model-for-stunting-among-children-under-the-age-of-three"},{"title":"The impact of first-person avatar customization on embodiment in immersive virtual reality","description":"In the world of virtual reality, developers and designers care a lot about something called \"embodiment\". Embodiment is the feeling or sensation that you’re \"in\" the character/avatar that you're playing. You are the avatar. You have agency, you have ownership. You have what’s referred to as \"visual-motor congruence\", and you feel accurately represented by the avatar in the virtual universe. Remember that scene in the Matrix when Neo wants to learn Kung Fu? They plug him into the simulation, and suddenly he’s in a room with Morpheus training and fighting. Well, in that moment Neo knows that what he's experiencing is a simulation, but that's counteracted by the fact that he has “high embodiment” in his avatar. It’s not his actual body, but in a way, it is. He’s not really in that room, but in a way, he is. That's embodiment.","doi":"10.3389/frvir.2024.1436752","short":"embodiment","released":"September 27th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DAaP-PRsEoS/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Avatar Customization","carousels":["Virtual Reality","Game Development","User Experience"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-impact-of-first-person-avatar-customization-on-embodiment-in-immersive-virtual-reality"},{"title":"Leveraging Google Earth Engine and Machine Learning to Estimate Evapotranspiration in a Commercial Forest Plantation","description":"You've probably heard of both deforestation and reforestation. But what on earth is afforestation? Afforestation is the process of planting and growing trees where none originally grew (or they haven’t grown in a long time). Afforestation is not replanting a recently-cut forest, it’s creating a forest where there was previously grassland, desert, or even ice, for example. Though it sounds a bit odd, afforestation is a key practice in sustainable timber production. Rather than chopping down existing forests, a company will grow a brand new forest, chop it down, and repeat. But, this technique does have its drawbacks. Commercial afforestation is extremely water-hungry. And as a result, many countries regulate it tightly. In South Africa, where today’s research takes place, you can’t grow a new forest without first being issued a water license. The licenses are granted based on the government's statistical models that show how that proposed crop would affect the overall energy balance, environment and water table. In order to create those models, the government needs to know a key metric for the species of tree you want to grow: Evapotranspiration (ET).","doi":"10.3390/rs16152726","short":"evapotranspiration","released":"September 26th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DAXzX5hMZHB/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Evapotranspiration Estimation","carousels":["Environmental Science","Climate Science","Data Science","Forestry","Agriculture","Ecology"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"leveraging-google-earth-engine-and-machine-learning-to-estimate-evapotranspiration-in-a-commercial-forest-plantation"},{"title":"Performance evaluation of microservices communication with REST, GraphQL, and gRPC","description":"Now, if you’re like me: alarm bells are already ringing. These shootouts happen all the time, and in many cases the experimental design is seriously flawed. In my opinion, this paper is no exception. So rather than take this article at face value (and report their findings as fact), we’re going to take a more critical lens. I am going to present their research and their findings, but I’ll spend much more time than usual on history and context, and then I'll use that to inform counter-arguments to their analysis. This study is imperfect, but it’s not without value. They did unearth some interesting findings, I just don’t think those findings should be taken at face value; so we won’t. The way we'll get the most out of this paper is through a critical, interrogative lens, so let's do that.","doi":"10.24425/ijet.2024.149562","short":"grpc","released":"September 25th, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DAVKuw1M_iD/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"REST vs GraphQL vs gRPC","carousels":["Web Development","Microservices","Network Engineering"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"performance-evaluation-of-microservices-communication-with-rest-graphql-and-grpc"},{"title":"PREDICTOR: A tool to predict the timing of the take-over response process in semi-automated driving","description":"This year over 90% of the new cars sold in the United States have some kind of driver-assistance technology built in. That means some kind of system that can aide in the steering, braking, or both. This basket of technologies is broadly referred to as autonomous driving, semi-autonomous driving, self-driving or full-self driving etc. There’s a lot of names for it, and a lot of implementations. To keep everyone on the same page, self-driving is classified on the SAE Driving Automation Scale, from Level 0 (minimal or no self-driving) all the way up to Level 5.","doi":"10.1016/j.trip.2024.101192","short":"takeover","released":"September 24th, 2024","sample":false,"instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Take-Over Response Systems","carousels":["Autonomous Vehicles"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"predictor-a-tool-to-predict-the-timing-of-the-take-over-response-process-in-semi-automated-driving"},{"title":"Application of Proximal Policy Optimization for Resource Orchestration in Serverless Edge Computing","description":"Serverless is great. In a number of ways it's truly a transformative technology. And it's spreading: every year more hosts jump into this space to offer their own Function as a Service (FaaS) platforms: from AWS, GCP and Azure, to the edge offerings available on Cloudflare, Fastly and Akamai, to the open-source options like OpenFaaS. But as with anything, serverless is not without its drawbacks. From the \"uncapped costs\" problem, to the \"how do I run this locally?\" problem, there are obviously a few areas where the developer-experience could be improved. And that's to be expected given how nascent the technology still is. But there is one issue that's a deal-breaker for many devs. An issue so off-putting that it actually prevents them from adopting serverless at all. That issue is the \"cold start\" problem.","doi":"10.3390/computers13090224","short":"cold","released":"September 23rd, 2024","sample":true,"instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Proximal Policy Optimization","carousels":["Serverless","Microservices","Edge Computing","Cloud Computing","Optimization"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"application-of-proximal-policy-optimization-for-resource-orchestration-in-serverless-edge-computing"},{"title":"A tool to access unreachable sites inside the Archaeological Park of Ostia Antica in Rome","description":"A half-hour drive south west of Rome sits an archaeological site called Ostia Antica. It’s the ruins of an ancient city from two millennia ago. Right in the center of the site is a brick house called “Casa Di Diana” (Diana’s House). It’s believed to originally have been a five-story building used for both residential and commercial activities. Now it’s a series of half-standing walls, chambers and pillars. From an archaeological perspective, Casa Di Diana is important. It’s one of the many treasures left from the Roman empire. A site that the archaeologists who have been studying it would love to share with the world. But, in its current form, it’s simply too fragile to let anyone but trained professionals visit.","doi":"10.6092/issn.1973-9494/20041","short":"ostia","released":"September 22nd, 2024","sample":false,"instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Ostia Antica","carousels":["Archaeology","3D Mapping","Tourism"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-tool-to-access-unreachable-sites-inside-the-archaeological-park-of-ostia-antica-in-rome"},{"title":"Trustworthy and reliable computing using untrusted and unreliable quantum hardware","description":"Right now, in 2024, writing programs for quantum computers feels like you’re writing code for IBM mainframes in the 1960s. Here’s what it's like: You write your code. You find a vendor with an available quantum computer that has a compiler compatible with your code. You send your code to that vendor in the hopes that they will compile and run your code sometime soon. You wait and you wait and you wait (for minutes or hours or days) You eventually get a readout back of the result of your program and/or your errors. The whole process is like stepping into a time machine!...And not in a good way.","doi":"10.3389/fcomp.2024.1431788","short":"quantum","released":"September 21st, 2024","sample":false,"instagram":"","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Unreliable Quantum Hardware","carousels":["Quantum Computing","Security","Cloud Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"trustworthy-and-reliable-computing-using-untrusted-and-unreliable-quantum-hardware"},{"title":"On the Optimization of Kubernetes toward the Enhancement of Cloud Computing","description":"Way back in 2014 Google released an open-source version of Borg, their in-house cluster management system. Borg was immense and highly specific to Google’s systems and servers, but this new open-source version would be different: It would be smaller, portable to different types of systems and hardware, focused narrowly on container orchestration, and generally useful for a number of workloads. They called the new project: Kubernetes. Kubernetes came out at exactly the right time. Adoption of Docker had spiked in the previous years, microservices were all the rage, and companies of all sizes were grappling with a non-trivial task: container orchestration. With no robust turnkey solutions available, developers were either building one-off systems from scratch, or struggling to port their existing CI/CD systems to work with containers. Google was uniquely positioned to step in. They had been early adopters of containers, and had spent a decade learning how to run them at scale. Kubernetes (or k8s as it came to be known) was the distillation of everything they’d learned...just scaled down.","doi":"10.3390/math12162476","short":"k8s","released":"September 20th, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DAp1TXSMAU9/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Kubernetes Optimization","carousels":["Microservices","Containers","Optimization","Cloud Computing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"on-the-optimization-of-kubernetes-toward-the-enhancement-of-cloud-computing"},{"title":"Simple techniques to bypass GenAI text detectors: implications for inclusive education","description":"For as long as there have been classrooms, there have been students in those classrooms figuring out ways to cheat. And as long as students have been cheating, there have been teachers and administrators trying to catch them in the act. Nothing about this cat-and-mouse game is new. What is new however, is the power of the AI tools that students now have available to them. Foundation Models exposed through interfaces like ChatGPT can produce a decent term-paper for a student in seconds, and this has drastically changed the playing field. So what’s a teacher or professor to do? How can they be expected to identify which papers were actually written by their students, and which were copied-and-pasted from a GenAI tool?","doi":"10.1186/s41239-024-00487-w","short":"cheating","released":"September 19th, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DAQJ5M4MTf5/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"GenAI Text Detectors","carousels":["Education","Generative A.I.","Large Language Models"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"simple-techniques-to-bypass-genai-text-detectors-implications-for-inclusive-education"},{"title":"Text mining and machine learning for crime classification: using unstructured narrative court documents in police academic","description":"The researchers in this study wanted to compile a database of police-reports, and then group those reports by the type of crime-scene described within each document. Seems simple enough, no? Unfortunately the authors immediately hit a wall: It turns out that police reports contain so much sensitive and private information that they’re rarely made public. So the authors couldn't get their hands on any of them and had to figure out a workaround: Rather than deal directly with police reports, they would use public court documents instead. Their theory was that court documents often have the narrative-areas of the relevant police-reports embedded within them (literally copied and pasted from the police reports right into the court docs). So the researchers could still build a database of police-writing, they'd just have to get that writing from court documents instead of directly from the police reports.","doi":"10.1080/23311916.2024.2359850","short":"mining","released":"September 18th, 2024","sample":true,"instagram":"https://www.instagram.com/journalclub.io/reel/DApwGGssnUD/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Crime Classification","carousels":["Criminal Justice","Natural Language Processing"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"text-mining-and-machine-learning-for-crime-classification-using-unstructured-narrative-court-documents-in-police-academic"},{"title":"The Fog Node Location Problem","description":"If you find yourself working with IoT devices, you’ll probably spend a lot of time thinking about light. No matter how elegantly you program your device, and no matter how cleanly you construct the backend, the interactions between your device and its server will only ever be as quick and responsive as light allows. Light travels at around 300,000 kilometers per second. That's around 186 miles per millisecond. So for tasks that require a round-trip to the server, the ultimate latency and lagginess of your device has nothing to do with your programming abilities; it has to do with how physically far the IoT device is from the nearest data center. Let's say you're building a device with strict latency requirements, and you want a roundtrip baseline of 6 milliseconds. If that’s the case, your server can’t be more than around 560 miles away from the device. Any further and light won’t have enough time to get to the server and come back.","doi":"10.19153/cleiej.27.3.2","short":"fog","released":"September 17th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DASqWM5se4z/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Fog Node Locations","carousels":["Edge Computing","Cloud Computing","Optimization","IoT"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-fog-node-location-problem"},{"title":"Earthquake detection and early warning prediction using folium and Geopandas","description":"One of my earliest memories is of the Loma Prieta earthquake. It hit California on a Tuesday afternoon in 1989. I was three years old and I was at day-care, playing in the sandbox. All I remember is that my universe went from still and quiet to violent and loud very suddenly. In just twenty seconds 63 people died, nearly 4,000 were injured and over 12,000 displaced. A piece of the upper deck of the Bay Bridge collapsed, the Nimitz freeway in Oakland fell down, and local homes and businesses suffered billions of dollars in damages. There was no warning. None. Back then Earthquake Early Warning systems (EEWs) had been invented, but they weren't installed in California until a few years later. So when a big earthquake hit, nobody had a chance to prepare or take cover. Authorities had no time to slow freeway traffic, turn stop-lights red, or close bridges. Now, thankfully that’s all changed. And for good reason! The \"big one\" (a megathrust earthquake) could happen in California anytime, and is projected to happen sometime in the next few decades. This time, when it hits, we'll at least have a few moments of warning.","doi":"10.1080/23311916.2024.2345301","short":"quake","released":"September 16th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DASY8iDMzcE/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Earthquake Detection","carousels":["Data Science","Civil Engineering","Temporal Analysis"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"earthquake-detection-and-early-warning-prediction-using-folium-and-geopandas"},{"title":"The detection of alcohol intoxication using electrooculography signals from smart glasses and machine learning techniques","description":"Picture this: It’s some time in the not too distant future, and you’re out with your friends one night having a few drinks. Maybe a few too many drinks. At some point you decide to leave, jump in your car and start driving down the road. Within a few blocks your car becomes aware that you’re driving drunk and it takes action. What happens next is anyone’s guess: maybe the car takes your control away and goes into full self-driving mode. Maybe it just pulls over and turns itself off. Maybe it calls you a cab, maybe it calls the police. Who knows. The more pertinent question in front of us today is: How on earth did the car know you were driving drunk in the first place?","doi":"10.1016/j.sasc.2024.200078","short":"bac","released":"September 15th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DASg2YysPqE/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Alcohol Detection via Smart Glasses","carousels":["Augmented Reality","Virtual Reality","Extended Reality","Safety"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"the-detection-of-alcohol-intoxication-using-electrooculography-signals-from-smart-glasses-and-machine-learning-techniques"},{"title":"Predicting the RUL of Li-Ion Batteries in UAVs Using Machine Learning Techniques","description":"As lithium-ion batteries age they get worse and worse and eventually reach the end of their useful life. This is a big issue for companies who operate fleets of UAVs (drones). If they replace the batteries in their drones too early, they’re wasting money. If they replace them too late their missions and deliveries get compromised. So they need a way to predict exactly when a drone’s battery is going to reach the end of its useful life. This paper is using AI to do exactly that. Let's take a look.","doi":"10.3390/computers13030064","short":"uav","released":"September 14th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DAIOgiCMVex/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"RUL of Lithium Ion","carousels":["UAVs","Data Science","Energy Science","Materials Science"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"predicting-the-rul-of-li-ion-batteries-in-uavs-using-machine-learning-techniques"},{"title":"Multiple objectives dynamic VM placement for application service availability in cloud networks","description":"If you’ve been around computer science for a while you’ve undoubtedly heard of the Bin-Packing problem. While it's surely difficult, imagine how much worse it would be if you had to optimize for several variables at the same time. That’s the situation faced by high volume SaaS companies who are trying to allocate Virtual Machines (or containers) onto their bare metal compute. They’re not just trying to minimize resource waste and cost, they need to balance power consumption, failure rates, application responsiveness, uptime, and more. Doing that is NP-hard and incredibly complex. In this paper the authors conceive an elegant solution: A framework called MoVPAAC.","doi":"10.1186/s13677-024-00610-2","short":"vm","released":"September 13th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DANpUsnsS30/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Dynamic VM Placement","carousels":["Optimization","Algorithms","Cloud Computing","Containers","Operating Systems"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"multiple-objectives-dynamic-vm-placement-for-application-service-availability-in-cloud-networks"},{"title":"OpenPodcar: An Open Source Vehicle for Self-Driving Car Research","description":"In the tech industry we’ve gotten pretty used to disruption. It seems like every few months there’s a new technology that’s \"going to change everything\". But very few technologies have the potential to be as truly disruptive as autonomous driving. Why? Because in the United States, it’s estimated that around a third of all civilian jobs involve driving in some way. And around 3% of all jobs are full-time driving. So it’s not hyperbole to say that a huge number of American workers can and will have their daily lives and employment significantly impacted by autonomous driving. Now, you may think autonomous driving is a bad thing (there’s an argument for that), or you may think it’s a great thing (there’s an argument for that as well). But what I think we can all agree that technology this disruptive can't and shouldn't be solely in the hands of a few giant companies with closed-sourced systems.","doi":"10.5334/joh.46","short":"podcar","released":"September 12th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DACzHRssfF6/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"An Open Source Vehicle","carousels":["Autonomous Vehicles"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"openpodcar-an-open-source-vehicle-for-self-driving-car-research"},{"title":"A machine learning‐based credit risk prediction engine system using a stacked classifier and a filter-based feature selection method.","description":"Here's a fun fact: your credit score isn't what it used to be. Now, I don't mean that your personal credit score has gone down, I mean that the days when banks relied solely or even mostly on your credit score to determine credit worthiness are gone. Long gone. These days: When a bank needs to determine your credit worthiness, it might look briefly at your score, but then its going to use its own proprietary A.I. to review all of your credit and banking history, as well as all the publicly available data that it can find on you. Then its model will spit out a credit worthiness decision. And lest we forget: credit worthiness determines a lot. It doesn't just determine whether or not you're approved for a loan or credit card, but the interest rate you get, the size of the credit limit, the rewards you qualify for, and more.","doi":"10.1186/s40537-024-00882-0","short":"credit","released":"September 11th, 2024","sample":false,"instagram":"https://www.instagram.com/journalclub.io/reel/DACqsekMd4X/","image":"","mp3":"","journal":"","author":"","university":"","country":"","lead":"","host":"Malcolm Diggs","producers":[],"writers":[],"thumbnailTitle":"Credit Risk Prediction Engine","carousels":["Finance","Risk Analysis","Classification"],"tags":[],"keywords":["AI","A.I.","Artificial Intelligence","Machine Learning","ML"],"slug":"a-machine-learningbased-credit-risk-prediction-engine-system-using-a-stacked-classifier-and-a-filter-based-feature-selection-method"}]}