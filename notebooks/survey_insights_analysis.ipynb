{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSP AI Survey Insights Analysis (Sept 2025)\n",
    "\n",
    "This notebook analyzes survey responses to identify key insights, trends, and actionable recommendations for the team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom datetime import datetime\nfrom collections import Counter\n\n# Set style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (14, 8)\n\n# Create outputs directory\nPath('../outputs/survey-insights').mkdir(parents=True, exist_ok=True)\n\n# Generate date suffix\ndate_suffix = datetime.now().strftime('%Y_%m_%d')\nprint(f\"Date suffix: {date_suffix}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Parse Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load survey responses\n",
    "survey_df = pd.read_csv('../data/CSP AI Use and Confidence (Sept 2025) (Responses)_2025_10_03.csv')\n",
    "\n",
    "print(f\"Total survey responses: {len(survey_df)}\")\n",
    "print(f\"Total questions: {len(survey_df.columns) - 2}\")  # Excluding Timestamp and Email\n",
    "\n",
    "# Define column shortcuts using column indices to avoid quote issues\n",
    "col_frequency = survey_df.columns[2]\n",
    "col_contexts = survey_df.columns[3]\n",
    "col_barriers = survey_df.columns[4]\n",
    "col_comfort = survey_df.columns[5]\n",
    "col_understanding = survey_df.columns[6]\n",
    "col_risks = survey_df.columns[7]\n",
    "col_growth = survey_df.columns[8]\n",
    "col_optional = survey_df.columns[9]\n",
    "\n",
    "print(f\"\\nColumn names loaded successfully\")\n",
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Usage Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analyze usage frequency\nfrequency_counts = survey_df[col_frequency].value_counts()\ntotal_responses = len(survey_df)\n\nprint(\"=\" * 80)\nprint(\"USAGE FREQUENCY ANALYSIS\")\nprint(\"=\" * 80)\nfor freq, count in frequency_counts.items():\n    print(f\"{freq:30s}: {count:3d} ({count/total_responses*100:5.1f}%)\")\n\n# Calculate heavy users\nheavy_users = frequency_counts.get('Daily', 0) + frequency_counts.get('Multiple times per week', 0)\nprint(f\"\\n{'Heavy users (Daily + Multiple/week)':30s}: {heavy_users:3d} ({heavy_users/total_responses*100:5.1f}%)\")\nprint(\"=\" * 80)\n\n# Visualize\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Pie chart\ncolors = ['#2ecc71', '#27ae60', '#f39c12', '#e74c3c']\nax1.pie(frequency_counts.values, labels=frequency_counts.index, autopct='%1.1f%%',\n        colors=colors, startangle=90, textprops={'fontsize': 10, 'fontweight': 'bold'})\nax1.set_title('AI Tool Usage Frequency', fontsize=14, fontweight='bold')\n\n# Bar chart\nax2.barh(frequency_counts.index, frequency_counts.values, color=colors, alpha=0.8, edgecolor='black')\nax2.set_xlabel('Number of Respondents', fontsize=12, fontweight='bold')\nax2.set_title('AI Tool Usage Frequency Distribution', fontsize=14, fontweight='bold')\nfor i, v in enumerate(frequency_counts.values):\n    ax2.text(v + 1, i, f'{v} ({v/total_responses*100:.1f}%)', va='center', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\noutput_file = f'../outputs/survey-insights/usage_frequency_{date_suffix}.png'\nplt.savefig(output_file, dpi=300, bbox_inches='tight')\nplt.show()\nprint(f\"✓ Saved: {output_file}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comfort Level & Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analyze comfort levels\ncomfort_counts = survey_df[col_comfort].value_counts()\ncomfort_order = ['Beginner', 'Intermediate', 'Advanced', 'Expert']\ncomfort_counts = comfort_counts.reindex(comfort_order)\n\nprint(\"=\" * 80)\nprint(\"COMFORT LEVEL DISTRIBUTION\")\nprint(\"=\" * 80)\nfor level, count in comfort_counts.items():\n    print(f\"{level:15s}: {count:3d} ({count/total_responses*100:5.1f}%)\")\nprint(\"=\" * 80)\n\n# Calculate confidence scores\navg_understanding = survey_df[col_understanding].mean()\navg_risks = survey_df[col_risks].mean()\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"CONFIDENCE SCORES (1-5 scale)\")\nprint(\"=\" * 80)\nprint(f\"Understanding AI strengths/limitations: {avg_understanding:.2f}/5\")\nprint(f\"Understanding AI risks (security, PII):  {avg_risks:.2f}/5\")\nprint(\"=\" * 80)\n\n# Visualize\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# Comfort level bar chart\ncolors_comfort = ['#e74c3c', '#f39c12', '#2ecc71', '#27ae60']\naxes[0, 0].bar(comfort_counts.index, comfort_counts.values, color=colors_comfort, alpha=0.8, edgecolor='black')\naxes[0, 0].set_ylabel('Number of Respondents', fontsize=12, fontweight='bold')\naxes[0, 0].set_title('Comfort Level with AI Tools', fontsize=14, fontweight='bold')\nfor i, v in enumerate(comfort_counts.values):\n    axes[0, 0].text(i, v + 1, f'{v}\\n({v/total_responses*100:.1f}%)', ha='center', fontsize=10, fontweight='bold')\n\n# Understanding strengths/limitations\nunderstanding_counts = survey_df[col_understanding].value_counts().sort_index()\naxes[0, 1].bar(understanding_counts.index, understanding_counts.values, color='#3498db', alpha=0.8, edgecolor='black')\naxes[0, 1].set_xlabel('Confidence Score (1-5)', fontsize=12, fontweight='bold')\naxes[0, 1].set_ylabel('Number of Respondents', fontsize=12, fontweight='bold')\naxes[0, 1].set_title(f'Understanding AI Strengths/Limitations\\n(Average: {avg_understanding:.2f}/5)', \n                     fontsize=14, fontweight='bold')\nfor i, (score, count) in enumerate(understanding_counts.items()):\n    axes[0, 1].text(score, count + 1, f'{count}', ha='center', fontsize=10, fontweight='bold')\n\n# Understanding risks\nrisks_counts = survey_df[col_risks].value_counts().sort_index()\naxes[1, 0].bar(risks_counts.index, risks_counts.values, color='#e67e22', alpha=0.8, edgecolor='black')\naxes[1, 0].set_xlabel('Confidence Score (1-5)', fontsize=12, fontweight='bold')\naxes[1, 0].set_ylabel('Number of Respondents', fontsize=12, fontweight='bold')\naxes[1, 0].set_title(f'Understanding AI Risks (Security, PII)\\n(Average: {avg_risks:.2f}/5)', \n                     fontsize=14, fontweight='bold')\nfor i, (score, count) in enumerate(risks_counts.items()):\n    axes[1, 0].text(score, count + 1, f'{count}', ha='center', fontsize=10, fontweight='bold')\n\n# Comparison of confidence scores\ncategories = ['Understanding\\nStrengths/Limitations', 'Understanding\\nRisks']\nscores = [avg_understanding, avg_risks]\naxes[1, 1].bar(categories, scores, color=['#3498db', '#e67e22'], alpha=0.8, edgecolor='black')\naxes[1, 1].set_ylabel('Average Score (out of 5)', fontsize=12, fontweight='bold')\naxes[1, 1].set_ylim(0, 5)\naxes[1, 1].set_title('Average Confidence Scores', fontsize=14, fontweight='bold')\naxes[1, 1].axhline(y=3, color='red', linestyle='--', alpha=0.5, label='Baseline (3/5)')\nfor i, v in enumerate(scores):\n    axes[1, 1].text(i, v + 0.1, f'{v:.2f}', ha='center', fontsize=12, fontweight='bold')\naxes[1, 1].legend()\n\nplt.tight_layout()\noutput_file = f'../outputs/survey-insights/confidence_levels_{date_suffix}.png'\nplt.savefig(output_file, dpi=300, bbox_inches='tight')\nplt.show()\nprint(f\"✓ Saved: {output_file}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AI Use Contexts Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse multi-select contexts\n",
    "contexts_list = []\n",
    "for response in survey_df[col_contexts]:\n",
    "    if pd.notna(response):\n",
    "        contexts_list.extend([item.strip() for item in str(response).split(',')])\n",
    "\n",
    "# Focus on main categories (filter out partial splits)\n",
    "main_contexts = {\n",
    "    'Coding / debugging': 0,\n",
    "    'Writing tests': 0,\n",
    "    'Documentation / summarization': 0,\n",
    "    'Code review / validation': 0,\n",
    "    'Experimenting / prototyping': 0,\n",
    "    'Data processing': 0,\n",
    "    'Multi-step workflows': 0\n",
    "}\n",
    "\n",
    "for context in contexts_list:\n",
    "    for key in main_contexts.keys():\n",
    "        if key in context:\n",
    "            main_contexts[key] += 1\n",
    "            break\n",
    "\n",
    "# Also count \"Generative\" separately\n",
    "generative_count = sum(1 for c in contexts_list if 'Generative' in c or 'images' in c)\n",
    "main_contexts['Generative (images, docs, ideas)'] = generative_count\n",
    "\n",
    "contexts_df = pd.DataFrame(list(main_contexts.items()), columns=['Context', 'Count']).sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AI USE CONTEXTS (Top Categories)\")\n",
    "print(\"=\" * 80)\n",
    "for _, row in contexts_df.iterrows():\n",
    "    pct = row['Count'] / total_responses * 100\n",
    "    print(f\"{row['Context']:40s}: {row['Count']:3d} ({pct:5.1f}%)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "colors_contexts = plt.cm.viridis(np.linspace(0.3, 0.9, len(contexts_df)))\n",
    "bars = ax.barh(contexts_df['Context'], contexts_df['Count'], color=colors_contexts, alpha=0.8, edgecolor='black')\n",
    "ax.set_xlabel('Number of Respondents', fontsize=12, fontweight='bold')\n",
    "ax.set_title('AI Use Contexts (Multi-select)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, max(contexts_df['Count']) * 1.15)\n",
    "\n",
    "for i, (idx, row) in enumerate(contexts_df.iterrows()):\n",
    "    pct = row['Count'] / total_responses * 100\n",
    "    ax.text(row['Count'] + 2, i, f\"{row['Count']} ({pct:.1f}%)\", va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "output_file = f'../outputs/survey-insights/ai_use_contexts_{date_suffix}.png'\n",
    "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"✓ Saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Barriers to AI Adoption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse barriers\n",
    "barriers_list = []\n",
    "for response in survey_df[col_barriers]:\n",
    "    if pd.notna(response):\n",
    "        barriers_list.extend([item.strip() for item in str(response).split(',')])\n",
    "\n",
    "# Focus on main barriers\n",
    "main_barriers = {}\n",
    "barrier_keywords = [\n",
    "    \"I'm actually good\",\n",
    "    \"Lack of trust in outputs\",\n",
    "    \"Lack of knowledge\",\n",
    "    \"Lack of time\",\n",
    "    \"Lack of access to the right tools\",\n",
    "    \"No relevant use cases\"\n",
    "]\n",
    "\n",
    "for keyword in barrier_keywords:\n",
    "    main_barriers[keyword] = sum(1 for b in barriers_list if keyword in b)\n",
    "\n",
    "# Check for China/geographic issues\n",
    "china_issues = sum(1 for b in barriers_list if 'China' in b or 'Claude' in b or 'Anthropic' in b)\n",
    "if china_issues > 0:\n",
    "    main_barriers['Geographic/Tool access (China)'] = china_issues\n",
    "\n",
    "barriers_df = pd.DataFrame(list(main_barriers.items()), columns=['Barrier', 'Count']).sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BARRIERS TO AI ADOPTION\")\n",
    "print(\"=\" * 80)\n",
    "for _, row in barriers_df.iterrows():\n",
    "    pct = row['Count'] / total_responses * 100\n",
    "    print(f\"{row['Barrier']:40s}: {row['Count']:3d} ({pct:5.1f}%)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "colors_barriers = ['#2ecc71' if 'actually good' in b else '#e74c3c' if 'trust' in b.lower() else '#f39c12' \n",
    "                   for b in barriers_df['Barrier']]\n",
    "bars = ax.barh(barriers_df['Barrier'], barriers_df['Count'], color=colors_barriers, alpha=0.8, edgecolor='black')\n",
    "ax.set_xlabel('Number of Respondents', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Barriers to AI Adoption (Multi-select)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, max(barriers_df['Count']) * 1.15)\n",
    "\n",
    "for i, (idx, row) in enumerate(barriers_df.iterrows()):\n",
    "    pct = row['Count'] / total_responses * 100\n",
    "    ax.text(row['Count'] + 1, i, f\"{row['Count']} ({pct:.1f}%)\", va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "output_file = f'../outputs/survey-insights/barriers_{date_suffix}.png'\n",
    "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"✓ Saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Desired Growth Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse growth areas\n",
    "growth_list = []\n",
    "for response in survey_df[col_growth]:\n",
    "    if pd.notna(response):\n",
    "        growth_list.extend([item.strip() for item in str(response).split(',')])\n",
    "\n",
    "# Main growth areas (simplified names)\n",
    "growth_mapping = {\n",
    "    'Coding & debugging': 'Using AI for coding & debugging',\n",
    "    'AI-assisted testing': 'AI-assisted testing',\n",
    "    'Documentation & summarization': 'Documentation & summarization',\n",
    "    'Code review & validation': 'Code review & validation',\n",
    "    'Workflow automation': 'Workflow automation',\n",
    "    'Creative engineering tasks': 'AI for creative engineering tasks',\n",
    "    'Data analysis': 'AI-powered data analysis',\n",
    "    'Understanding AI models': 'Understanding AI model capabilities',\n",
    "    'Security & risk awareness': 'Security & risk awareness',\n",
    "    'Building AI features': 'Building AI-powered features',\n",
    "    'Mentoring others': 'Mentoring & teaching others'\n",
    "}\n",
    "\n",
    "growth_counts = {}\n",
    "for short_name, keyword in growth_mapping.items():\n",
    "    growth_counts[short_name] = sum(1 for g in growth_list if keyword in g)\n",
    "\n",
    "growth_df = pd.DataFrame(list(growth_counts.items()), columns=['Growth Area', 'Count']).sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DESIRED GROWTH AREAS (Top Priorities)\")\n",
    "print(\"=\" * 80)\n",
    "for _, row in growth_df.iterrows():\n",
    "    pct = row['Count'] / total_responses * 100\n",
    "    print(f\"{row['Growth Area']:40s}: {row['Count']:3d} ({pct:5.1f}%)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "colors_growth = plt.cm.plasma(np.linspace(0.2, 0.9, len(growth_df)))\n",
    "bars = ax.barh(growth_df['Growth Area'], growth_df['Count'], color=colors_growth, alpha=0.8, edgecolor='black')\n",
    "ax.set_xlabel('Number of Respondents', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Desired AI Skill Growth Areas (Next 3 Months)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, max(growth_df['Count']) * 1.15)\n",
    "\n",
    "for i, (idx, row) in enumerate(growth_df.iterrows()):\n",
    "    pct = row['Count'] / total_responses * 100\n",
    "    ax.text(row['Count'] + 2, i, f\"{row['Count']} ({pct:.1f}%)\", va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "output_file = f'../outputs/survey-insights/growth_areas_{date_suffix}.png'\n",
    "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"✓ Saved: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Notable Quotes & Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract interesting responses\n",
    "optional_responses = survey_df[col_optional].dropna()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"NOTABLE USE CASES ({len(optional_responses)} responses)\")\n",
    "print(\"=\" * 80)\n",
    "for i, response in enumerate(optional_responses.head(10), 1):\n",
    "    print(f\"\\n{i}. {response}\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key metrics\n",
    "total_respondents = len(survey_df)\n",
    "daily_users_pct = (frequency_counts.get('Daily', 0) / total_respondents * 100)\n",
    "heavy_users_pct = (heavy_users / total_respondents * 100)\n",
    "intermediate_pct = (comfort_counts.get('Intermediate', 0) / total_respondents * 100)\n",
    "advanced_plus_pct = ((comfort_counts.get('Advanced', 0) + comfort_counts.get('Expert', 0)) / total_respondents * 100)\n",
    "no_barriers_pct = (main_barriers.get(\"I'm actually good\", 0) / total_respondents * 100)\n",
    "trust_issues_pct = (main_barriers.get('Lack of trust in outputs', 0) / total_respondents * 100)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY INSIGHTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n📊 ADOPTION & ENGAGEMENT\")\n",
    "print(f\"  • Total survey responses: {total_respondents}\")\n",
    "print(f\"  • Daily users: {daily_users_pct:.1f}%\")\n",
    "print(f\"  • Heavy users (daily + multiple/week): {heavy_users_pct:.1f}%\")\n",
    "print(f\"  • Top use cases: Documentation ({contexts_df.iloc[0]['Count']}), Coding ({contexts_df.iloc[1]['Count']}), Testing ({contexts_df.iloc[2]['Count']})\")\n",
    "\n",
    "print(f\"\\n🎯 SKILL LEVELS & CONFIDENCE\")\n",
    "print(f\"  • Intermediate level: {intermediate_pct:.1f}% (largest group)\")\n",
    "print(f\"  • Advanced/Expert: {advanced_plus_pct:.1f}%\")\n",
    "print(f\"  • Avg understanding of AI limitations: {avg_understanding:.2f}/5\")\n",
    "print(f\"  • Avg understanding of AI risks: {avg_risks:.2f}/5\")\n",
    "\n",
    "print(f\"\\n🚧 BARRIERS & CHALLENGES\")\n",
    "print(f\"  • No barriers (learning well): {no_barriers_pct:.1f}%\")\n",
    "print(f\"  • Lack of trust in outputs: {trust_issues_pct:.1f}%\")\n",
    "print(f\"  • Geographic/tool access issues: {main_barriers.get('Geographic/Tool access (China)', 0)} mentions\")\n",
    "\n",
    "print(f\"\\n🚀 TOP GROWTH PRIORITIES\")\n",
    "for i, (idx, row) in enumerate(growth_df.head(3).iterrows(), 1):\n",
    "    print(f\"  {i}. {row['Growth Area']} ({row['Count']} responses)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Insights Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Export formatted text report\noutput_file_txt = f'../outputs/survey-insights/insights_summary_{date_suffix}.txt'\n\nwith open(output_file_txt, 'w') as f:\n    f.write(\"=\" * 80 + \"\\n\")\n    f.write(\"CSP AI USE AND CONFIDENCE SURVEY - INSIGHTS REPORT\\n\")\n    f.write(\"=\" * 80 + \"\\n\")\n    f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n    f.write(f\"Total Responses: {total_respondents}\\n\")\n    f.write(\"=\" * 80 + \"\\n\\n\")\n    \n    f.write(\"KEY INSIGHTS\\n\")\n    f.write(\"-\" * 80 + \"\\n\\n\")\n    \n    f.write(\"1. HIGH ADOPTION & ENGAGEMENT\\n\")\n    f.write(f\"   - {heavy_users_pct:.1f}% are heavy users (daily or multiple times per week)\\n\")\n    f.write(f\"   - {daily_users_pct:.1f}% use AI tools daily\\n\")\n    f.write(f\"   - Top use cases: Documentation, Coding/debugging, Writing tests\\n\\n\")\n    \n    f.write(\"2. SKILL LEVELS & CONFIDENCE GAPS\\n\")\n    f.write(f\"   - {intermediate_pct:.1f}% at Intermediate level (largest group)\\n\")\n    f.write(f\"   - {advanced_plus_pct:.1f}% at Advanced/Expert level\\n\")\n    f.write(f\"   - Average understanding of AI limitations: {avg_understanding:.2f}/5\\n\")\n    f.write(f\"   - Average understanding of AI risks: {avg_risks:.2f}/5\\n\")\n    f.write(f\"   - Opportunity: Move Intermediate → Advanced through targeted training\\n\\n\")\n    \n    f.write(\"3. BARRIERS TO ADOPTION\\n\")\n    f.write(f\"   - {no_barriers_pct:.1f}% report no barriers (learning well)\\n\")\n    f.write(f\"   - {trust_issues_pct:.1f}% lack trust in AI outputs\\n\")\n    f.write(f\"   - Geographic challenges: China-based engineers face Claude/Anthropic access issues\\n\\n\")\n    \n    f.write(\"4. TOP GROWTH PRIORITIES (Next 3 months)\\n\")\n    for i, (idx, row) in enumerate(growth_df.head(5).iterrows(), 1):\n        pct = row['Count'] / total_respondents * 100\n        f.write(f\"   {i}. {row['Growth Area']}: {row['Count']} responses ({pct:.1f}%)\\n\")\n    f.write(\"\\n\")\n    \n    f.write(\"=\" * 80 + \"\\n\")\n    f.write(\"RECOMMENDATIONS\\n\")\n    f.write(\"=\" * 80 + \"\\n\\n\")\n    \n    f.write(\"1. TRAINING & EDUCATION\\n\")\n    f.write(\"   - Create intermediate → advanced learning path\\n\")\n    f.write(\"   - Focus on: prompt engineering, validation strategies, understanding limitations\\n\")\n    f.write(\"   - Address trust issues through best practices and case studies\\n\\n\")\n    \n    f.write(\"2. TOOL ACCESS & INFRASTRUCTURE\\n\")\n    f.write(\"   - Resolve geographic access issues for China-based teams\\n\")\n    f.write(\"   - Ensure equitable tool access across all locations\\n\")\n    f.write(\"   - Streamline reimbursement processes\\n\\n\")\n    \n    f.write(\"3. SKILL DEVELOPMENT PROGRAMS\\n\")\n    f.write(\"   - Prioritize: Coding & debugging, Building AI features, Understanding models\\n\")\n    f.write(\"   - Create hands-on workshops and hackathons\\n\")\n    f.write(\"   - Establish mentorship programs (32 people interested)\\n\\n\")\n    \n    f.write(\"4. SECURITY & RISK AWARENESS\\n\")\n    f.write(f\"   - Risk understanding score: {avg_risks:.2f}/5 - needs improvement\\n\")\n    f.write(\"   - Mandatory training on PII/IP protection\\n\")\n    f.write(\"   - Clear guidelines for responsible AI use\\n\\n\")\n    \n    f.write(\"=\" * 80 + \"\\n\")\n\nprint(f\"✓ Saved: {output_file_txt}\")\n\n# Export HTML report (Google Docs compatible)\noutput_file_html = f'../outputs/survey-insights/insights_summary_{date_suffix}.html'\n\nwith open(output_file_html, 'w') as f:\n    f.write('<!DOCTYPE html>\\n<html>\\n<head>\\n')\n    f.write('<meta charset=\"UTF-8\">\\n')\n    f.write('<title>CSP AI Survey Insights Report</title>\\n')\n    f.write('<style>\\n')\n    f.write('body { font-family: Arial, sans-serif; line-height: 1.6; max-width: 800px; margin: 40px auto; padding: 20px; }\\n')\n    f.write('h1 { color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }\\n')\n    f.write('h2 { color: #34495e; margin-top: 30px; border-bottom: 2px solid #95a5a6; padding-bottom: 5px; }\\n')\n    f.write('h3 { color: #7f8c8d; margin-top: 20px; }\\n')\n    f.write('.metric { background: #ecf0f1; padding: 15px; margin: 10px 0; border-radius: 5px; }\\n')\n    f.write('.highlight { background: #fff3cd; padding: 10px; border-left: 4px solid #ffc107; margin: 10px 0; }\\n')\n    f.write('ul { line-height: 1.8; }\\n')\n    f.write('</style>\\n</head>\\n<body>\\n')\n    \n    f.write('<h1>CSP AI Use and Confidence Survey - Insights Report</h1>\\n')\n    f.write(f'<p><strong>Generated on:</strong> {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</p>\\n')\n    f.write(f'<p><strong>Total Responses:</strong> {total_respondents}</p>\\n')\n    \n    f.write('<h2>Key Insights</h2>\\n')\n    \n    f.write('<h3>1. High Adoption & Engagement</h3>\\n<ul>\\n')\n    f.write(f'<li><strong>{heavy_users_pct:.1f}%</strong> are heavy users (daily or multiple times per week)</li>\\n')\n    f.write(f'<li><strong>{daily_users_pct:.1f}%</strong> use AI tools daily</li>\\n')\n    f.write(f'<li>Top use cases: <strong>Documentation</strong>, <strong>Coding/debugging</strong>, <strong>Writing tests</strong></li>\\n')\n    f.write('</ul>\\n')\n    \n    f.write('<h3>2. Skill Levels & Confidence Gaps</h3>\\n<ul>\\n')\n    f.write(f'<li><strong>{intermediate_pct:.1f}%</strong> at Intermediate level (largest group)</li>\\n')\n    f.write(f'<li><strong>{advanced_plus_pct:.1f}%</strong> at Advanced/Expert level</li>\\n')\n    f.write(f'<li>Average understanding of AI limitations: <strong>{avg_understanding:.2f}/5</strong></li>\\n')\n    f.write(f'<li>Average understanding of AI risks: <strong>{avg_risks:.2f}/5</strong></li>\\n')\n    f.write('<li class=\"highlight\">Opportunity: Move Intermediate → Advanced through targeted training</li>\\n')\n    f.write('</ul>\\n')\n    \n    f.write('<h3>3. Barriers to Adoption</h3>\\n<ul>\\n')\n    f.write(f'<li><strong>{no_barriers_pct:.1f}%</strong> report no barriers (learning well)</li>\\n')\n    f.write(f'<li><strong>{trust_issues_pct:.1f}%</strong> lack trust in AI outputs</li>\\n')\n    f.write(f'<li class=\"highlight\">Geographic challenges: China-based engineers face Claude/Anthropic access issues</li>\\n')\n    f.write('</ul>\\n')\n    \n    f.write('<h3>4. Top Growth Priorities (Next 3 months)</h3>\\n<ol>\\n')\n    for i, (idx, row) in enumerate(growth_df.head(5).iterrows(), 1):\n        pct = row['Count'] / total_respondents * 100\n        f.write(f'<li><strong>{row[\"Growth Area\"]}</strong>: {row[\"Count\"]} responses ({pct:.1f}%)</li>\\n')\n    f.write('</ol>\\n')\n    \n    f.write('<h2>Recommendations</h2>\\n')\n    \n    f.write('<h3>1. Training & Education</h3>\\n<ul>\\n')\n    f.write('<li>Create intermediate → advanced learning path</li>\\n')\n    f.write('<li>Focus on: prompt engineering, validation strategies, understanding limitations</li>\\n')\n    f.write('<li>Address trust issues through best practices and case studies</li>\\n')\n    f.write('</ul>\\n')\n    \n    f.write('<h3>2. Tool Access & Infrastructure</h3>\\n<ul>\\n')\n    f.write('<li>Resolve geographic access issues for China-based teams</li>\\n')\n    f.write('<li>Ensure equitable tool access across all locations</li>\\n')\n    f.write('<li>Streamline reimbursement processes</li>\\n')\n    f.write('</ul>\\n')\n    \n    f.write('<h3>3. Skill Development Programs</h3>\\n<ul>\\n')\n    f.write('<li>Prioritize: Coding & debugging, Building AI features, Understanding models</li>\\n')\n    f.write('<li>Create hands-on workshops and hackathons</li>\\n')\n    f.write('<li>Establish mentorship programs (32 people interested)</li>\\n')\n    f.write('</ul>\\n')\n    \n    f.write('<h3>4. Security & Risk Awareness</h3>\\n<ul>\\n')\n    f.write(f'<li>Risk understanding score: <strong>{avg_risks:.2f}/5</strong> - needs improvement</li>\\n')\n    f.write('<li>Mandatory training on PII/IP protection</li>\\n')\n    f.write('<li>Clear guidelines for responsible AI use</li>\\n')\n    f.write('</ul>\\n')\n    \n    f.write('</body>\\n</html>')\n\nprint(f\"✓ Saved: {output_file_html}\")\nprint(\"  (Open in browser, then copy-paste into Google Docs)\")\n\n# Export CSV data tables\noutput_file_csv = f'../outputs/survey-insights/insights_data_{date_suffix}.csv'\ninsights_data = pd.DataFrame({\n    'Metric': [\n        'Total Responses',\n        'Daily Users %',\n        'Heavy Users %',\n        'Intermediate Level %',\n        'Advanced/Expert %',\n        'Avg Understanding Score',\n        'Avg Risk Awareness Score',\n        'No Barriers %',\n        'Trust Issues %'\n    ],\n    'Value': [\n        total_respondents,\n        round(daily_users_pct, 1),\n        round(heavy_users_pct, 1),\n        round(intermediate_pct, 1),\n        round(advanced_plus_pct, 1),\n        round(avg_understanding, 2),\n        round(avg_risks, 2),\n        round(no_barriers_pct, 1),\n        round(trust_issues_pct, 1)\n    ]\n})\ninsights_data.to_csv(output_file_csv, index=False)\nprint(f\"✓ Saved: {output_file_csv}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"ANALYSIS COMPLETE\")\nprint(\"=\" * 80)\nprint(\"\\nGenerated files:\")\nprint(f\"  - outputs/survey-insights/usage_frequency_{date_suffix}.png\")\nprint(f\"  - outputs/survey-insights/confidence_levels_{date_suffix}.png\")\nprint(f\"  - outputs/survey-insights/ai_use_contexts_{date_suffix}.png\")\nprint(f\"  - outputs/survey-insights/barriers_{date_suffix}.png\")\nprint(f\"  - outputs/survey-insights/growth_areas_{date_suffix}.png\")\nprint(f\"  - outputs/survey-insights/insights_summary_{date_suffix}.txt\")\nprint(f\"  - outputs/survey-insights/insights_summary_{date_suffix}.html (Google Docs compatible)\")\nprint(f\"  - outputs/survey-insights/insights_data_{date_suffix}.csv\")\nprint(\"=\" * 80)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}